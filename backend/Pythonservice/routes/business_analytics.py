"""
Business Analytics API Route
Endpoint Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u kinh doanh vÃ  Ä‘á» xuáº¥t chiáº¿n lÆ°á»£c báº±ng AI
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import google.generativeai as genai
import os
from datetime import datetime, timedelta
import json
from typing import Optional, Dict, Any, List
import chromadb
from groq import Groq
import requests

# Import services
from services.document_processing_service import get_document_processor
from services.analytics_rag_service import AnalyticsRAGService

router = APIRouter()

# Global analytics RAG service instance
analytics_rag_service = None

def set_analytics_rag_service(service: AnalyticsRAGService):
    """Set the global analytics RAG service instance"""
    global analytics_rag_service
    analytics_rag_service = service

# Helper functions for safe type conversion
def safe_decimal(value):
    """Safely convert value to float"""
    if value is None:
        return 0.0
    try:
        return float(value)
    except (ValueError, TypeError):
        return 0.0

def safe_int(value):
    """Safely convert value to int"""
    if value is None:
        return 0
    try:
        return int(value)
    except (ValueError, TypeError):
        return 0

def safe_str(value):
    """Safely convert value to string"""
    if value is None:
        return ""
    return str(value)

def sanitize_metadata(metadata_dict):
    """Sanitize metadata dictionary for ChromaDB compatibility"""
    sanitized = {}
    for key, value in metadata_dict.items():
        if isinstance(value, (str, int, float, bool)):
            # Ensure strings are not too long and don't contain null bytes
            if isinstance(value, str):
                value = value.replace('\x00', '').replace('\r', '').replace('\n', ' ')
                if len(value) > 10000:  # Limit string length
                    value = value[:10000] + '...'
            sanitized[key] = value
        else:
            # Convert other types to string
            sanitized[key] = str(value)
    return sanitized

# Configure Gemini API
GEMINI_API_KEY = os.getenv('GOOGLE_API_KEY')
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Configure Groq API
GROQ_API_KEY = os.getenv('GROQ_API_KEY')
groq_client = None
if GROQ_API_KEY:
    groq_client = Groq(api_key=GROQ_API_KEY)
    
# Cache for models
_cached_models = None
_models_cache_time = None

def resolve_spring_file_path(relative_path):
    """
    Resolve Ä‘Æ°á»ng dáº«n file tÆ°Æ¡ng Ä‘á»‘i tá»« Spring Service thÃ nh Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i
    
    Args:
        relative_path: ÄÆ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i tá»« Spring Service (vd: 'uploads/documents/file.xlsx')
        
    Returns:
        ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i hoáº·c None náº¿u khÃ´ng tÃ¬m tháº¥y
    """
    if not relative_path:
        return None
    
    # Náº¿u Ä‘Ã£ lÃ  Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i, tráº£ vá» luÃ´n
    if os.path.isabs(relative_path):
        return relative_path if os.path.exists(relative_path) else None
    
    # CÃ¡c Ä‘Æ°á»ng dáº«n cÃ³ thá»ƒ cÃ³ cá»§a Spring Service uploads
    possible_base_paths = [
        # ÄÆ°á»ng dáº«n tá»« thÆ° má»¥c Python service Ä‘áº¿n Spring service
        os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'SpringService', relative_path),
        # ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i dá»±a trÃªn cáº¥u trÃºc project
        os.path.join('/home/hv/DuAn/CSN/AI-Agent-for-Business/backend/SpringService', relative_path),
        # ÄÆ°á»ng dáº«n tá»« environment variable náº¿u cÃ³
        os.path.join(os.getenv('SPRING_UPLOAD_PATH', ''), relative_path) if os.getenv('SPRING_UPLOAD_PATH') else None,
    ]
    
    # Thá»­ tá»«ng Ä‘Æ°á»ng dáº«n cÃ³ thá»ƒ
    for base_path in possible_base_paths:
        if base_path and os.path.exists(base_path):
            print(f"[File Resolver] Found file at: {base_path}")
            return base_path
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y á»Ÿ cÃ¡c vá»‹ trÃ­ chuáº©n, thá»­ tÃ¬m trong thÆ° má»¥c hiá»‡n táº¡i
    current_dir = os.getcwd()
    fallback_path = os.path.join(current_dir, relative_path)
    if os.path.exists(fallback_path):
        print(f"[File Resolver] Found file at fallback location: {fallback_path}")
        return fallback_path
    
    print(f"[File Resolver] File not found at any location for: {relative_path}")
    return None

def get_available_models_from_apis():
    """Fetch available models from Gemini and Groq APIs"""
    global _cached_models, _models_cache_time
    import time
    
    # Cache for 1 hour
    if _cached_models and _models_cache_time and (time.time() - _models_cache_time) < 3600:
        return _cached_models
    
    models = []
    
    # Get Gemini models - chá»‰ giá»¯ Pro vÃ  Flash 2.5
    if GEMINI_API_KEY:
        try:
            gemini_models = genai.list_models()
            allowed_gemini = ['gemini-2.5-pro', 'gemini-2.5-flash']
            
            for m in gemini_models:
                if 'generateContent' in m.supported_generation_methods:
                    model_id = m.name.replace('models/', '')
                    
                    # Chá»‰ giá»¯ Pro vÃ  Flash 2.5
                    if model_id in allowed_gemini:
                        models.append({
                            'id': model_id,
                            'name': m.display_name,
                            'provider': 'Google',
                            'context_window': getattr(m, 'input_token_limit', 32768)
                        })
                        print(f"[Analytics] Added Gemini model: {model_id}")
            
            print(f"[Analytics] Loaded {len([m for m in models if m['provider'] == 'Google'])} Gemini models")
        except Exception as e:
            print(f"[Analytics] Error loading Gemini models: {e}")
    
    # Get Groq models
    if groq_client:
        try:
            models_response = groq_client.models.list()
            
            # List of keywords to exclude (non-chat models)
            excluded_keywords = ['whisper', 'distil-whisper', 'guard']
            
            groq_models = []
            for model in models_response.data:
                if hasattr(model, 'id') and model.id:
                    model_id_lower = model.id.lower()
                    
                    # Skip non-chat models
                    if any(keyword in model_id_lower for keyword in excluded_keywords):
                        print(f"[Analytics] Skipping excluded model: {model.id}")
                        continue
                    
                    # Only include active models
                    if not getattr(model, 'active', True):
                        print(f"[Analytics] Skipping inactive model: {model.id}")
                        continue
                    
                    context_window = getattr(model, 'context_window', 8192)
                    
                    groq_models.append({
                        'id': model.id,
                        'name': model.id,
                        'provider': 'Groq',
                        'context_window': context_window
                    })
                    print(f"[Analytics] Added Groq model: {model.id} (context: {context_window})")
            
            # Sort by name
            groq_models.sort(key=lambda x: x['name'])
            models.extend(groq_models)
            
            print(f"[Analytics] Loaded {len(groq_models)} Groq models")
        except Exception as e:
            print(f"[Analytics] Error loading Groq models: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("[Analytics] Groq client not initialized - check GROQ_API_KEY")
    
    # Sort by provider and name
    models.sort(key=lambda x: (x['provider'], x['name']))
    
    _cached_models = models
    _models_cache_time = time.time()
    
    return models

@router.get('/models')
async def get_available_models():
    """Láº¥y danh sÃ¡ch models AI cÃ³ sáºµn cho phÃ¢n tÃ­ch tá»« API"""
    models = get_available_models_from_apis()
    return {'success': True, 'models': models}

# ChromaDB client
chroma_client = None

def set_chroma_client(client):
    """Set ChromaDB client"""
    global chroma_client
    chroma_client = client

class AIInsightsRequest(BaseModel):
    type: Optional[str] = 'general'  # general, pricing, inventory, sales
    model: Optional[str] = 'llama-3.3-70b-versatile'  # AI model to use - default to Groq Llama 3.3 70B

def get_business_data():
    """Láº¥y dá»¯ liá»‡u kinh doanh tá»« ChromaDB"""
    try:
        if not chroma_client:
            return {'products': [], 'orders': [], 'categories': [], 'discounts': [], 'business_performance': [], 'users': [], 'documents': []}
        
        # Láº¥y collections tá»« ChromaDB
        # business_data: products, categories, business_performance, discounts
        # orders_analytics: orders
        try:
            business_collection = chroma_client.get_collection(name="business_data")
            orders_collection = chroma_client.get_collection(name="orders_analytics")
            revenue_collection = chroma_client.get_collection(name="revenue_overview")
        except Exception as e:
            print(f"Error getting collections: {e}")
            return {'products': [], 'orders': [], 'categories': [], 'discounts': [], 'business_performance': [], 'users': [], 'documents': [], 'revenue_overview': []}
        
        # Láº¥y táº¥t cáº£ dá»¯ liá»‡u tá»« collections (limit lá»›n Ä‘á»ƒ Ä‘áº£m báº£o láº¥y háº¿t)
        business_data = business_collection.get(include=['metadatas'], limit=10000)
        orders_data = orders_collection.get(include=['metadatas'], limit=10000)
        revenue_data = revenue_collection.get(include=['metadatas'], limit=10000)
        
        # Parse metadata tá»« business_collection theo data_type
        all_business_metadatas = business_data.get('metadatas', [])
        
        products = [m for m in all_business_metadatas if m.get('data_type') == 'product']
        categories = [m for m in all_business_metadatas if m.get('data_type') == 'category']
        discounts = [m for m in all_business_metadatas if m.get('data_type') == 'discount']
        business_performance = [m for m in all_business_metadatas if m.get('data_type') == 'business_performance']
        users = [m for m in all_business_metadatas if m.get('data_type') == 'user']
        documents = [m for m in all_business_metadatas if m.get('data_type') == 'document']
        
        # Parse orders tá»« orders_analytics collection  
        orders = orders_data.get('metadatas', [])
        
        # Parse revenue overview tá»« revenue_overview collection
        revenue_overview = revenue_data.get('metadatas', [])
        
        # Convert string fields back to proper types
        for product in products:
            if 'price' in product and isinstance(product['price'], str):
                try:
                    product['price'] = float(product['price'])
                except:
                    product['price'] = 0
            if 'quantity' in product and isinstance(product['quantity'], str):
                try:
                    product['quantity'] = int(product['quantity'])
                except:
                    product['quantity'] = 0
            if 'id' in product and isinstance(product['id'], str):
                try:
                    product['id'] = int(product['id'])
                except:
                    pass
        
        for order in orders:
            if 'totalAmount' in order and isinstance(order['totalAmount'], str):
                try:
                    order['totalAmount'] = float(order['totalAmount'])
                except:
                    order['totalAmount'] = 0
            if 'id' in order and isinstance(order['id'], str):
                try:
                    order['id'] = int(order['id'])
                except:
                    pass
        
        print(f"[Analytics] Loaded from ChromaDB: {len(products)} products, {len(orders)} orders, {len(categories)} categories, {len(discounts)} discounts, {len(business_performance)} business records, {len(users)} users, {len(documents)} documents")
        
        return {
            'products': products,
            'orders': orders,
            'categories': categories,
            'discounts': discounts,
            'business_performance': business_performance,
            'users': users,
            'documents': documents,
            'revenue_overview': revenue_overview
        }
    except Exception as e:
        print(f"Error fetching business data from ChromaDB: {e}")
        import traceback
        traceback.print_exc()
        return {
            'products': [],
            'orders': [],
            'categories': [],
            'discounts': [],
            'business_performance': [],
            'users': [],
            'documents': [],
            'revenue_overview': []
        }

def calculate_statistics(data):
    """TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ thá»‘ng kÃª"""
    products = data.get('products', [])
    orders = data.get('orders', [])
    categories = data.get('categories', [])
    revenue_overview = data.get('revenue_overview', [])
    
    # Thá»‘ng kÃª tá»•ng quan
    total_products = len(products)
    total_orders = len(orders)
    total_categories = len(categories)
    
    # Sá»­ dá»¥ng dá»¯ liá»‡u doanh thu tá»« revenue_overview náº¿u cÃ³, náº¿u khÃ´ng thÃ¬ tÃ­nh tá»« orders
    if revenue_overview:
        # Láº¥y dá»¯ liá»‡u tá»« revenue_overview collection
        revenue_data = revenue_overview[0] if revenue_overview else {}
        total_revenue = revenue_data.get('total_revenue', 0)
        monthly_revenue = revenue_data.get('monthly_revenue', 0)
        weekly_revenue = revenue_data.get('weekly_revenue', 0)
        daily_revenue = revenue_data.get('daily_revenue', 0)
    else:
        # Fallback: tÃ­nh tá»« orders data
        total_revenue = sum(order.get('totalAmount', 0) for order in orders)
        monthly_revenue = 0  # KhÃ´ng thá»ƒ tÃ­nh tá»« orders data
        weekly_revenue = 0
        daily_revenue = 0
    
    # TÃ­nh doanh thu theo tráº¡ng thÃ¡i
    revenue_by_status = {}
    orders_by_status = {}
    for order in orders:
        status = order.get('status', 'UNKNOWN')
        amount = order.get('totalAmount', 0)
        
        revenue_by_status[status] = revenue_by_status.get(status, 0) + amount
        orders_by_status[status] = orders_by_status.get(status, 0) + 1
    
    # Convert to array format for frontend
    revenue_by_status_array = [
        {'status': status, 'revenue': revenue}
        for status, revenue in revenue_by_status.items()
    ]
    orders_by_status_array = [
        {'status': status, 'count': count}
        for status, count in orders_by_status.items()
    ]
    
    # TÃ­nh sá»‘ lÆ°á»£ng Ä‘Ã£ bÃ¡n vÃ  doanh thu cho tá»«ng sáº£n pháº©m
    # Note: ChromaDB orders khÃ´ng chá»©a chi tiáº¿t items, nÃªn dÃ¹ng totalSold tá»« product metadata
    enriched_products = []
    for product in products:
        total_sold = product.get('totalSold', 0)
        if isinstance(total_sold, str):
            try:
                total_sold = int(total_sold)
            except:
                total_sold = 0
        
        price = product.get('price', 0)
        revenue = total_sold * price
        
        enriched_product = {
            **product,
            'stock': product.get('quantity', 0),  # Äá»•i quantity -> stock
            'total_sold': total_sold,
            'revenue': revenue
        }
        enriched_products.append(enriched_product)
    
    # Top sáº£n pháº©m bÃ¡n cháº¡y (theo total_sold vÃ  revenue)
    products_sorted = sorted(enriched_products, key=lambda x: (x.get('total_sold', 0), x.get('revenue', 0)), reverse=True)
    top_products = products_sorted
    
    # Sáº£n pháº©m sáº¯p háº¿t hÃ ng (stock < 20)
    low_stock_products = sorted(
        [p for p in enriched_products if p.get('stock', 0) < 20],
        key=lambda x: x.get('stock', 0)
    )
    
    # PhÃ¢n tÃ­ch theo danh má»¥c
    category_stats = {}
    for product in products:
        cat_id = product.get('categoryId')
        cat_name = product.get('categoryName', 'Unknown')
        
        if cat_name not in category_stats:
            category_stats[cat_name] = {
                'product_count': 0,
                'total_stock': 0,
                'avg_price': 0,
                'total_price': 0
            }
        
        category_stats[cat_name]['product_count'] += 1
        category_stats[cat_name]['total_stock'] += product.get('quantity', 0)
        category_stats[cat_name]['total_price'] += product.get('price', 0)
    
    # TÃ­nh giÃ¡ trung bÃ¬nh theo danh má»¥c
    for cat_name, stats in category_stats.items():
        if stats['product_count'] > 0:
            stats['avg_price'] = stats['total_price'] / stats['product_count']
    
    # PhÃ¢n tÃ­ch theo thá»i gian (7 ngÃ y gáº§n nháº¥t)
    now = datetime.now()
    last_7_days = now - timedelta(days=7)
    
    revenue_by_day = {}
    orders_by_day = {}
    
    for order in orders:
        created_at = order.get('createdAt', '')
        if created_at:
            try:
                order_date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                date_key = order_date.strftime('%Y-%m-%d')
                
                revenue_by_day[date_key] = revenue_by_day.get(date_key, 0) + order.get('totalAmount', 0)
                orders_by_day[date_key] = orders_by_day.get(date_key, 0) + 1
            except:
                pass
    
    # TÃ­nh available_stock cho tá»«ng sáº£n pháº©m
    for product in enriched_products:
        initial_quantity = product.get('quantity', 0)
        total_sold = product.get('totalSold', 0)
        product['available_stock'] = max(0, initial_quantity - total_sold)
    
    # PhÃ¢n tÃ­ch tá»“n kho chi tiáº¿t theo yÃªu cáº§u: â‰¥30, 10-29, 1-9, 0
    total_inventory_value = sum([p.get('price', 0) * p.get('available_stock', 0) for p in enriched_products])
    
    # Categorize products
    stock_good = [p for p in enriched_products if p.get('available_stock', 0) >= 30]
    stock_avg = [p for p in enriched_products if 10 <= p.get('available_stock', 0) < 30]
    stock_low = [p for p in enriched_products if 1 <= p.get('available_stock', 0) < 10]
    stock_out = [p for p in enriched_products if p.get('available_stock', 0) == 0]
    
    total_products_count = len(enriched_products) if enriched_products else 1  # Avoid division by zero
    
    inventory_table_data = {
        'good': {
            'count': len(stock_good),
            'value': sum([p.get('price', 0) * p.get('available_stock', 0) for p in stock_good]),
            'percent': (len(stock_good) / total_products_count) * 100
        },
        'average': {
            'count': len(stock_avg),
            'value': sum([p.get('price', 0) * p.get('available_stock', 0) for p in stock_avg]),
            'percent': (len(stock_avg) / total_products_count) * 100
        },
        'low': {
            'count': len(stock_low),
            'value': sum([p.get('price', 0) * p.get('available_stock', 0) for p in stock_low]),
            'percent': (len(stock_low) / total_products_count) * 100
        },
        'out': {
            'count': len(stock_out),
            'value': 0,
            'percent': (len(stock_out) / total_products_count) * 100
        }
    }
    
    inventory_turnover_ratio = total_revenue / total_inventory_value if total_inventory_value > 0 else 0
    out_of_stock_products = len(stock_out)
    
    inventory_analysis = {
        'critical_stock_products': stock_low,  # Tá»“n kho tháº¥p (1-9)
        'warning_stock_products': stock_avg,   # Tá»“n kho trung bÃ¬nh (10-29)
        'out_of_stock_products': stock_out,    # Háº¿t hÃ ng (0)
        'stock_distribution': {
            'well_stocked': {'count': len(stock_good), 'value': inventory_table_data['good']['value']},
            'medium_stock': {'count': len(stock_avg), 'value': inventory_table_data['average']['value']},
            'low_stock': {'count': len(stock_low), 'value': inventory_table_data['low']['value']},
            'out_of_stock': {'count': len(stock_out), 'value': 0}
        },
        'table_data': inventory_table_data
    }
    
    return {
        'overview': {
            'total_products': total_products,
            'total_orders': total_orders,
            'total_categories': total_categories,
            'total_revenue': total_revenue,
            'monthly_revenue': monthly_revenue,
            'weekly_revenue': weekly_revenue,
            'daily_revenue': daily_revenue,
            'avg_order_value': total_revenue / total_orders if total_orders > 0 else 0,
            'total_inventory_value': total_inventory_value,
            'out_of_stock_products': out_of_stock_products,
            'inventory_turnover_ratio': inventory_turnover_ratio
        },
        'revenue_by_status': revenue_by_status_array,
        'orders_by_status': orders_by_status_array,
        'top_products': top_products,
        'low_stock_products': sorted(stock_low, key=lambda x: x.get('available_stock', 0)),
        'category_stats': category_stats,
        'inventory_analysis': inventory_analysis,
        'revenue_by_day': revenue_by_day,
        'orders_by_day': orders_by_day
    }

@router.get('/data')
async def get_analytics_data():
    """Láº¥y dá»¯ liá»‡u phÃ¢n tÃ­ch thá»‘ng kÃª"""
    try:
        # Láº¥y dá»¯ liá»‡u tá»« ChromaDB
        business_data = get_business_data()
        
        # TÃ­nh toÃ¡n thá»‘ng kÃª
        statistics = calculate_statistics(business_data)
        
        return {
            'success': True,
            'data': statistics
        }
        
    except Exception as e:
        print(f"Error in analytics data: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@router.post('/ai-insights')
async def get_ai_insights(request: AIInsightsRequest):
    """Sá»­ dá»¥ng AI Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  Ä‘á» xuáº¥t chiáº¿n lÆ°á»£c kinh doanh vá»›i RAG tá»« documents"""
    try:
        # Láº¥y dá»¯ liá»‡u kinh doanh tá»« ChromaDB
        business_data = get_business_data()
        statistics = calculate_statistics(business_data)
        
        # ğŸ” SEARCH BUSINESS DOCUMENTS FOR RELEVANT INFORMATION
        document_context = ""
        if analytics_rag_service:
            try:
                # Search for document content related to the analysis type
                search_query = request.type
                doc_results = analytics_rag_service.search_business_data(
                    query=search_query,
                    n_results=5
                )
                
                if doc_results:
                    document_context = "\\n\\nğŸ“„ THÃ”NG TIN Tá»ª TÃ€I LIá»†U DOANH NGHIá»†P:\\n"
                    for i, doc in enumerate(doc_results, 1):
                        content = doc.get('content', '')[:1000]  # Limit content length
                        document_context += f"\\n--- TÃ i liá»‡u {i} ---\\n{content}\\n"
                    
                    print(f"[AI Insights] Found {len(doc_results)} relevant documents")
                else:
                    print("[AI Insights] No relevant documents found")
                    
            except Exception as e:
                print(f"[AI Insights] Error searching documents: {e}")
        
        # Táº¡o prompt cho AI dá»±a trÃªn loáº¡i phÃ¢n tÃ­ch + document context
        prompt = create_analysis_prompt(request.type, statistics, business_data, document_context)
        
        # Use the selected model from request
        model_name = request.model if request.model else 'llama-3.3-70b-versatile'
        print(f"[Analytics] Using AI model: {model_name}")
        
        # Determine provider based on model name - check if it's a Groq model
        groq_model_prefixes = [
            'llama', 'mixtral', 'gemma', 'openai/gpt-oss', 'moonshotai', 
            'meta-llama', 'qwen', 'groq', 'allam', 'playai'
        ]
        is_groq = any(prefix in model_name.lower() for prefix in groq_model_prefixes)
        
        print(f"[Analytics] Model: {model_name}, Provider: {'Groq' if is_groq else 'Gemini'}")
        
        if is_groq and groq_client:
            # Use Groq API
            print(f"[Analytics] Using Groq API")
            try:
                chat_completion = groq_client.chat.completions.create(
                    messages=[
                        {
                            "role": "user",
                            "content": prompt,
                        }
                    ],
                    model=model_name,
                    temperature=0.7,
                    max_tokens=8192,
                )
                ai_insights = chat_completion.choices[0].message.content
            except Exception as groq_error:
                print(f"[Analytics] Groq API error: {groq_error}")
                # Fallback to Gemini if Groq fails
                print(f"[Analytics] Fallback to Gemini API")
                try:
                    model = genai.GenerativeModel('gemini-2.5-flash')
                    response = model.generate_content(prompt)
                    ai_insights = response.text
                except Exception as gemini_error:
                    print(f"[Analytics] Gemini fallback also failed: {gemini_error}")
                    raise HTTPException(status_code=500, detail=f"Both Groq and Gemini APIs failed. Groq: {groq_error}, Gemini: {gemini_error}")
        else:
            # Use Gemini API
            print(f"[Analytics] Using Gemini API")
            try:
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)
                ai_insights = response.text
            except Exception as gemini_error:
                print(f"[Analytics] Gemini API error: {gemini_error}")
                raise HTTPException(status_code=500, detail=f"Gemini API error: {gemini_error}")
        
        return {
            'success': True,
            'insights': ai_insights,
            'statistics': statistics,
            'analysis_type': request.type
        }
        
    except Exception as e:
        print(f"Error in AI insights: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

def create_analysis_prompt(analysis_type, statistics, business_data, document_context=""):
    """Táº¡o prompt cho AI dá»±a trÃªn loáº¡i phÃ¢n tÃ­ch vÃ  thÃ´ng tin tá»« tÃ i liá»‡u"""
    
    overview = statistics.get('overview', {})
    revenue_by_status = statistics.get('revenue_by_status', [])
    orders_by_status = statistics.get('orders_by_status', [])
    category_stats = statistics.get('category_stats', {})
    low_stock_products = statistics.get('low_stock_products', [])
    top_products = statistics.get('top_products', [])
    
    # Láº¥y dá»¯ liá»‡u báº£ng phÃ¢n tÃ­ch tá»“n kho pre-calculated
    inventory_analysis = statistics.get('inventory_analysis', {})
    inv_table = inventory_analysis.get('table_data', {})
    
    # Create Markdown Table string explicitly
    inventory_table_md = f"""
| Loáº¡i | Sá»‘ lÆ°á»£ng SP | GiÃ¡ trá»‹ (VNÄ) | Tá»· lá»‡ % |
| :--- | :---: | :---: | :---: |
| ğŸŸ¢ Tá»‘t (â‰¥30 SP) | {inv_table.get('good', {}).get('count', 0)} | {inv_table.get('good', {}).get('value', 0):,.0f} | {inv_table.get('good', {}).get('percent', 0):.1f}% |
| ğŸŸ¡ Trung bÃ¬nh (10-29 SP) | {inv_table.get('average', {}).get('count', 0)} | {inv_table.get('average', {}).get('value', 0):,.0f} | {inv_table.get('average', {}).get('percent', 0):.1f}% |
| ğŸ”´ Tháº¥p (1-9 SP) | {inv_table.get('low', {}).get('count', 0)} | {inv_table.get('low', {}).get('value', 0):,.0f} | {inv_table.get('low', {}).get('percent', 0):.1f}% |
| âš« Háº¿t hÃ ng (0) | {inv_table.get('out', {}).get('count', 0)} | {inv_table.get('out', {}).get('value', 0):,.0f} | {inv_table.get('out', {}).get('percent', 0):.1f}% |
"""

    # Láº¥y thÃªm dá»¯ liá»‡u chi tiáº¿t
    products = business_data.get('products', [])
    orders = business_data.get('orders', [])
    categories = business_data.get('categories', [])
    discounts = business_data.get('discounts', [])
    business_performance = business_data.get('business_performance', [])
    
    # PhÃ¢n tÃ­ch sÃ¢u hÆ¡n
    total_inventory_value = overview.get('total_inventory_value', 0)
    avg_product_price = sum([p.get('price', 0) for p in products]) / len(products) if products else 0
    products_with_details = [p for p in products if p.get('has_details')]
    out_of_stock_count = overview.get('out_of_stock_products', 0)
    
    base_context = f"""
ğŸ¯ Báº N LÃ€ CHUYÃŠN GIA PHÃ‚N TÃCH KINH DOANH & CHIáº¾N LÆ¯á»¢C CAO Cáº¤P
Nhiá»‡m vá»¥: PhÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p vÃ  Ä‘Æ°a ra Insights chÃ­nh xÃ¡c.
QUAN TRá»ŒNG: TUYá»†T Äá»I KHÃ”NG Tá»° TÃNH TOÃN Láº I Sá» LIá»†U. HÃƒY Sá»¬ Dá»¤NG Báº¢NG Sá» LIá»†U ÄÃƒ ÄÆ¯á»¢C CUNG Cáº¤P DÆ¯á»šI ÄÃ‚Y.

ğŸ“Š 1ï¸âƒ£ ÄÃNH GIÃ TÃŒNH TRáº NG Tá»’N KHO HIá»†N Táº I (Dá»® LIá»†U CHÃNH XÃC):
{inventory_table_md}

ğŸ“Š Dá»® LIá»†U KINH DOANH Tá»”NG QUAN KHÃC:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¦ Sáº£n pháº©m:
   â€¢ Tá»•ng sá»‘: {overview.get('total_products', 0)} sáº£n pháº©m
   â€¢ CÃ³ thÃ´ng tin chi tiáº¿t: {len(products_with_details)} sáº£n pháº©m ({len(products_with_details)/len(products)*100:.1f}% náº¿u cÃ³ sáº£n pháº©m)
   â€¢ GiÃ¡ trung bÃ¬nh: {avg_product_price:,.0f} VNÄ
   â€¢ Tá»•ng giÃ¡ trá»‹ hÃ ng tá»“n: {total_inventory_value:,.0f} VNÄ
   â€¢ Sáº£n pháº©m háº¿t hÃ ng: {out_of_stock_count} sáº£n pháº©m
   â€¢ Sáº£n pháº©m sáº¯p háº¿t hÃ ng: {len(low_stock_products)}

ğŸ›’ ÄÆ¡n hÃ ng:
   â€¢ Tá»•ng sá»‘: {overview.get('total_orders', 0)} Ä‘Æ¡n
   â€¢ Tá»•ng doanh thu: {overview.get('total_revenue', 0):,.0f} VNÄ
   â€¢ GiÃ¡ trá»‹ TB/Ä‘Æ¡n: {overview.get('avg_order_value', 0):,.0f} VNÄ

ğŸ“ˆ PHÃ‚N TÃCH DOANH THU THEO TRáº NG THÃI:
{json.dumps(revenue_by_status, indent=2, ensure_ascii=False)}

ğŸ“‹ PHÃ‚N Bá» ÄÆ N HÃ€NG THEO TRáº NG THÃI:
{json.dumps(orders_by_status, indent=2, ensure_ascii=False)}

ğŸ·ï¸ THá»NG KÃŠ THEO DANH Má»¤C Sáº¢N PHáº¨M:
{json.dumps(category_stats, indent=2, ensure_ascii=False)}

â­ TOP 5 Sáº¢N PHáº¨M Ná»”I Báº¬T:
{json.dumps([{'tÃªn': p.get('name'), 'giÃ¡': f"{p.get('price', 0):,.0f} VNÄ", 'tá»“n_kho': p.get('available_stock', 0), 'Ä‘Ã£_bÃ¡n': p.get('total_sold', 0)} for p in top_products], indent=2, ensure_ascii=False)}

âš ï¸ Sáº¢N PHáº¨M Cáº¦N NHáº¬P HÃ€NG (Tá»“n kho < 10):
{json.dumps([{'tÃªn': p.get('name'), 'tá»“n_kho': p.get('available_stock', 0), 'giÃ¡': f"{p.get('price', 0):,.0f} VNÄ"} for p in low_stock_products], indent=2, ensure_ascii=False)}

ğŸ“Š PHÃ‚N TÃCH Tá»’N KHO CHI TIáº¾T:
   â€¢ Tá»· lá»‡ quay vÃ²ng hÃ ng tá»“n: {overview.get('inventory_turnover_ratio', 0):.2f}
   â€¢ Sáº£n pháº©m háº¿t hÃ ng: {out_of_stock_count}/{len(products)} ({out_of_stock_count/len(products)*100:.1f}% náº¿u cÃ³ sáº£n pháº©m)
   â€¢ GiÃ¡ trá»‹ hÃ ng tá»“n kho: {total_inventory_value:,.0f} VNÄ
   â€¢ Sáº£n pháº©m tá»“n kho tháº¥p: {len(low_stock_products)} sáº£n pháº©m

ğŸ’° THÃ”NG TIN KHUYáº¾N MÃƒI:
   â€¢ Tá»•ng sá»‘ chÆ°Æ¡ng trÃ¬nh: {len(discounts)}
   â€¢ Äang hoáº¡t Ä‘á»™ng: {len([d for d in discounts if d.get('status') == 'ACTIVE'])}

ğŸ¢ HIá»†U SUáº¤T NGÆ¯á»œI BÃN:
   â€¢ Tá»•ng sá»‘ ngÆ°á»i bÃ¡n: {len(business_performance)}
   â€¢ Tá»•ng doanh thu táº¥t cáº£: {sum([bp.get('revenue', 0) for bp in business_performance]):,.0f} VNÄ

{document_context}
"""

    # Format base_context with actual values
    inventory_analysis = statistics.get('inventory_analysis', {})
    
    # Replace placeholders in base_context
    base_context = base_context.replace('{overview.get(\'total_products\', 0)}', str(overview.get('total_products', 0)))
    base_context = base_context.replace('{len(products_with_details)}', str(len(products_with_details)))
    base_context = base_context.replace('{len(products)*100:.1f}', f"{len(products_with_details)/len(products)*100:.1f}" if products else '0.0')
    base_context = base_context.replace('{avg_product_price:,.0f}', f"{avg_product_price:,.0f}")
    base_context = base_context.replace('{total_inventory_value:,.0f}', f"{total_inventory_value:,.0f}")
    base_context = base_context.replace('{out_of_stock_count}', str(out_of_stock_count))
    base_context = base_context.replace('{len(low_stock_products)}', str(len(low_stock_products)))
    base_context = base_context.replace('{overview.get(\'inventory_turnover_ratio\', 0):.2f}', f"{overview.get('inventory_turnover_ratio', 0):.2f}")
    base_context = base_context.replace('{out_of_stock_count/len(products)*100:.1f}', f"{out_of_stock_count/len(products)*100:.1f}" if products else '0.0')
    base_context = base_context.replace('{total_inventory_value:,.0f}', f"{total_inventory_value:,.0f}")
    base_context = base_context.replace('{len(low_stock_products)}', str(len(low_stock_products)))
    
    # Replace JSON strings
    base_context = base_context.replace('{json.dumps(revenue_by_status, indent=2, ensure_ascii=False)}', json.dumps(revenue_by_status, indent=2, ensure_ascii=False))
    base_context = base_context.replace('{json.dumps(orders_by_status, indent=2, ensure_ascii=False)}', json.dumps(orders_by_status, indent=2, ensure_ascii=False))
    base_context = base_context.replace('{json.dumps(category_stats, indent=2, ensure_ascii=False)}', json.dumps(category_stats, indent=2, ensure_ascii=False))
    base_context = base_context.replace('{json.dumps([{\'tÃªn\': p.get(\'name\'), \'giÃ¡\': f"{p.get(\'price\', 0):,.0f} VNÄ", \'tá»“n_kho\': p.get(\'available_stock\', 0), \'Ä‘Ã£_bÃ¡n\': p.get(\'total_sold\', 0)} for p in top_products], indent=2, ensure_ascii=False)}', json.dumps([{'tÃªn': p.get('name'), 'giÃ¡': f"{p.get('price', 0):,.0f} VNÄ", 'tá»“n_kho': p.get('available_stock', 0), 'Ä‘Ã£_bÃ¡n': p.get('total_sold', 0)} for p in top_products], indent=2, ensure_ascii=False))
    base_context = base_context.replace('{json.dumps([{\'tÃªn\': p.get(\'name\'), \'tá»“n_kho\': p.get(\'available_stock\', 0), \'giÃ¡\': f"{p.get(\'price\', 0):,.0f} VNÄ"} for p in low_stock_products], indent=2, ensure_ascii=False)}', json.dumps([{'tÃªn': p.get('name'), 'tá»“n_kho': p.get('available_stock', 0), 'giÃ¡': f"{p.get('price', 0):,.0f} VNÄ"} for p in low_stock_products], indent=2, ensure_ascii=False))
    
    # Replace other placeholders
    base_context = base_context.replace('{len(discounts)}', str(len(discounts)))
    base_context = base_context.replace('{len([d for d in discounts if d.get(\'status\') == \'ACTIVE\'])}', str(len([d for d in discounts if d.get('status') == 'ACTIVE'])))
    base_context = base_context.replace('{len(business_performance)}', str(len(business_performance)))
    base_context = base_context.replace('{sum([bp.get(\'revenue\', 0) for bp in business_performance]):,.0f}', f"{sum([bp.get('revenue', 0) for bp in business_performance]):,.0f}")
    base_context = base_context.replace('{document_context}', document_context)

    if analysis_type == 'general':
        prompt = base_context + """

ğŸ¯ NHIá»†M Vá»¤: BÃO CÃO PHÃ‚N TÃCH KINH DOANH CHUYÃŠN NGHIá»†P & CHIáº¾N LÆ¯á»¢C TÄ‚NG TRÆ¯á»NG

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Cáº¤U TRÃšC BÃO CÃO YÃŠU Cáº¦U:

## ğŸ“Š EXECUTIVE SUMMARY (TÃ³m táº¯t Ä‘iá»u hÃ nh)
> Viáº¿t 1 Ä‘oáº¡n ngáº¯n gá»n (3-4 cÃ¢u) tÃ³m táº¯t tÃ¬nh hÃ¬nh kinh doanh hiá»‡n táº¡i, highlight 2-3 insights quan trá»ng nháº¥t vÃ  1-2 hÃ nh Ä‘á»™ng Æ°u tiÃªn cao nháº¥t.

---

## ğŸ“ˆ DASHBOARD CHÃNH - CHá»ˆ Sá» QUAN TRá»ŒNG

Táº¡o báº£ng KPIs vá»›i Ä‘Ã¡nh giÃ¡ vÃ  xu hÆ°á»›ng:

| Chá»‰ sá»‘ | GiÃ¡ trá»‹ hiá»‡n táº¡i | ÄÃ¡nh giÃ¡ | Xu hÆ°á»›ng | HÃ nh Ä‘á»™ng |
|--------|------------------|----------|----------|-----------|
| ğŸ’° Tá»•ng doanh thu | [X] VNÄ | ğŸŸ¢/ğŸŸ¡/ğŸ”´ | â†—ï¸/â†˜ï¸/â†’ | [Gá»£i Ã½ ngáº¯n] |
| ğŸ›’ Tá»•ng Ä‘Æ¡n hÃ ng | [X] Ä‘Æ¡n | ğŸŸ¢/ğŸŸ¡/ğŸ”´ | â†—ï¸/â†˜ï¸/â†’ | [Gá»£i Ã½ ngáº¯n] |
| ğŸ’µ GiÃ¡ trá»‹ TB/Ä‘Æ¡n (AOV) | [X] VNÄ | ğŸŸ¢/ğŸŸ¡/ğŸ”´ | â†—ï¸/â†˜ï¸/â†’ | [Gá»£i Ã½ ngáº¯n] |
| ğŸ“¦ Tá»· lá»‡ hÃ ng tá»“n khá»e | [X]% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ | â†—ï¸/â†˜ï¸/â†’ | [Gá»£i Ã½ ngáº¯n] |
| âš ï¸ Sáº£n pháº©m cáº§n nháº­p | [X] SP | ğŸŸ¢/ğŸŸ¡/ğŸ”´ | â†—ï¸/â†˜ï¸/â†’ | [Gá»£i Ã½ ngáº¯n] |
| ğŸ”„ Tá»· lá»‡ quay vÃ²ng hÃ ng | [X] láº§n | ğŸŸ¢/ğŸŸ¡/ğŸ”´ | â†—ï¸/â†˜ï¸/â†’ | [Gá»£i Ã½ ngáº¯n] |

**ChÃº thÃ­ch:** ğŸŸ¢ Tá»‘t | ğŸŸ¡ Cáº§n cáº£i thiá»‡n | ğŸ”´ Cáº£nh bÃ¡o | â†—ï¸ TÄƒng | â†˜ï¸ Giáº£m | â†’ á»”n Ä‘á»‹nh

---

## ğŸ¯ PHÃ‚N TÃCH SWOT CHUYÃŠN SÃ‚U

### ğŸ’ª ÄIá»‚M Máº NH (Strengths)
1. **[Äiá»ƒm máº¡nh 1]**: [MÃ´ táº£ chi tiáº¿t vá»›i sá»‘ liá»‡u cá»¥ thá»ƒ]
   - TÃ¡c Ä‘á»™ng: [Äá»‹nh lÆ°á»£ng impact]
   - CÃ¡ch táº­n dá»¥ng: [Gá»£i Ã½ cá»¥ thá»ƒ]

2. **[Äiá»ƒm máº¡nh 2]**: [MÃ´ táº£ chi tiáº¿t vá»›i sá»‘ liá»‡u cá»¥ thá»ƒ]
   - TÃ¡c Ä‘á»™ng: [Äá»‹nh lÆ°á»£ng impact]
   - CÃ¡ch táº­n dá»¥ng: [Gá»£i Ã½ cá»¥ thá»ƒ]

[Liá»‡t kÃª 3-5 Ä‘iá»ƒm máº¡nh]

### âš ï¸ ÄIá»‚M Yáº¾U (Weaknesses)
1. **[Äiá»ƒm yáº¿u 1]**: [MÃ´ táº£ chi tiáº¿t vá»›i sá»‘ liá»‡u cá»¥ thá»ƒ]
   - Rá»§i ro: [Äá»‹nh lÆ°á»£ng risk]
   - Giáº£i phÃ¡p: [HÃ nh Ä‘á»™ng cá»¥ thá»ƒ]

2. **[Äiá»ƒm yáº¿u 2]**: [MÃ´ táº£ chi tiáº¿t vá»›i sá»‘ liá»‡u cá»¥ thá»ƒ]
   - Rá»§i ro: [Äá»‹nh lÆ°á»£ng risk]
   - Giáº£i phÃ¡p: [HÃ nh Ä‘á»™ng cá»¥ thá»ƒ]

[Liá»‡t kÃª 3-5 Ä‘iá»ƒm yáº¿u]

### ğŸš€ CÆ  Há»˜I (Opportunities)
1. **[CÆ¡ há»™i 1]**: [MÃ´ táº£ cÆ¡ há»™i thá»‹ trÆ°á»ng/ná»™i bá»™]
   - Tiá»m nÄƒng: [Doanh thu/lá»£i nhuáº­n dá»± kiáº¿n]
   - CÃ¡ch khai thÃ¡c: [Chiáº¿n thuáº­t cá»¥ thá»ƒ]

[Liá»‡t kÃª 3-4 cÆ¡ há»™i]

### ğŸ›¡ï¸ THÃCH THá»¨C (Threats)
1. **[ThÃ¡ch thá»©c 1]**: [MÃ´ táº£ rá»§i ro/thÃ¡ch thá»©c]
   - Má»©c Ä‘á»™: Cao/Trung bÃ¬nh/Tháº¥p
   - PhÃ²ng ngá»«a: [Biá»‡n phÃ¡p cá»¥ thá»ƒ]

[Liá»‡t kÃª 2-3 thÃ¡ch thá»©c]

---

## ğŸ¯ CHIáº¾N LÆ¯á»¢C HÃ€NH Äá»˜NG Æ¯U TIÃŠN (Action Plan)

### Ma tráº­n Æ°u tiÃªn (Priority Matrix):

| HÃ nh Ä‘á»™ng | TÃ¡c Ä‘á»™ng | Äá»™ khÃ³ | Æ¯u tiÃªn | Timeline | Chi phÃ­ | ROI dá»± kiáº¿n |
|-----------|----------|--------|---------|----------|---------|-------------|
| [HÃ nh Ä‘á»™ng 1] | Cao/TB/Tháº¥p | Dá»…/TB/KhÃ³ | ğŸ”´ P0 | [X tuáº§n] | [Y] VNÄ | [Z]% |
| [HÃ nh Ä‘á»™ng 2] | Cao/TB/Tháº¥p | Dá»…/TB/KhÃ³ | ğŸŸ¡ P1 | [X tuáº§n] | [Y] VNÄ | [Z]% |
| [HÃ nh Ä‘á»™ng 3] | Cao/TB/Tháº¥p | Dá»…/TB/KhÃ³ | ğŸŸ¢ P2 | [X tuáº§n] | [Y] VNÄ | [Z]% |

**ChÃº thÃ­ch:** ğŸ”´ P0 = Kháº©n cáº¥p (lÃ m ngay) | ğŸŸ¡ P1 = Quan trá»ng (1-2 tuáº§n) | ğŸŸ¢ P2 = Cáº§n thiáº¿t (1 thÃ¡ng)

### ğŸ“‹ Chi tiáº¿t tá»«ng hÃ nh Ä‘á»™ng:

#### ğŸ”´ HÃ€NH Äá»˜NG Æ¯U TIÃŠN CAO (P0) - Thá»±c hiá»‡n ngay

**1. [TÃªn hÃ nh Ä‘á»™ng cá»¥ thá»ƒ]**
- **Má»¥c tiÃªu**: [Má»¥c tiÃªu SMART cá»¥ thá»ƒ]
- **LÃ½ do**: [Táº¡i sao cáº§n lÃ m ngay]
- **CÃ¡c bÆ°á»›c thá»±c hiá»‡n**:
  1. [BÆ°á»›c 1 cá»¥ thá»ƒ]
  2. [BÆ°á»›c 2 cá»¥ thá»ƒ]
  3. [BÆ°á»›c 3 cá»¥ thá»ƒ]
- **Nguá»“n lá»±c cáº§n**: [Con ngÆ°á»i, ngÃ¢n sÃ¡ch, cÃ´ng cá»¥]
- **KPI Ä‘o lÆ°á»ng**: [Chá»‰ sá»‘ cá»¥ thá»ƒ Ä‘á»ƒ Ä‘o thÃ nh cÃ´ng]
- **Káº¿t quáº£ ká»³ vá»ng**: [Sá»‘ liá»‡u cá»¥ thá»ƒ]

[Liá»‡t kÃª 2-3 hÃ nh Ä‘á»™ng P0]

#### ğŸŸ¡ HÃ€NH Äá»˜NG QUAN TRá»ŒNG (P1) - Thá»±c hiá»‡n trong 1-2 tuáº§n

**1. [TÃªn hÃ nh Ä‘á»™ng]**
- **Má»¥c tiÃªu**: [SMART goal]
- **CÃ¡c bÆ°á»›c**: [Liá»‡t kÃª ngáº¯n gá»n]
- **KPI**: [Chá»‰ sá»‘ Ä‘o lÆ°á»ng]
- **Káº¿t quáº£ ká»³ vá»ng**: [Sá»‘ liá»‡u]

[Liá»‡t kÃª 2-3 hÃ nh Ä‘á»™ng P1]

#### ğŸŸ¢ HÃ€NH Äá»˜NG Cáº¦N THIáº¾T (P2) - LÃªn káº¿ hoáº¡ch trong thÃ¡ng

**1. [TÃªn hÃ nh Ä‘á»™ng]**
- **Má»¥c tiÃªu**: [SMART goal]
- **Káº¿t quáº£ ká»³ vá»ng**: [Sá»‘ liá»‡u]

[Liá»‡t kÃª 2-3 hÃ nh Ä‘á»™ng P2]

---

## ğŸ“Š PHÃ‚N TÃCH THEO LÄ¨NH Vá»°C

### ğŸ’° DOANH THU & Lá»¢I NHUáº¬N
- **PhÃ¢n tÃ­ch hiá»‡n tráº¡ng**: [ÄÃ¡nh giÃ¡ chi tiáº¿t]
- **Danh má»¥c Ä‘Ã³ng gÃ³p nhiá»u nháº¥t**: [Top 3 vá»›i % Ä‘Ã³ng gÃ³p]
- **CÆ¡ há»™i tÄƒng trÆ°á»Ÿng**: [Gá»£i Ã½ cá»¥ thá»ƒ vá»›i sá»‘ liá»‡u]
- **HÃ nh Ä‘á»™ng Ä‘á» xuáº¥t**: [2-3 hÃ nh Ä‘á»™ng]

### ğŸ“¦ Tá»’N KHO & LOGISTICS
- **TÃ¬nh tráº¡ng tá»“n kho**: [ÄÃ¡nh giÃ¡ dá»±a trÃªn báº£ng phÃ¢n loáº¡i Ä‘Ã£ cung cáº¥p]
- **Váº¥n Ä‘á» cáº¥p bÃ¡ch**: [Sáº£n pháº©m háº¿t hÃ ng, tá»“n kho tháº¥p]
- **Tá»‘i Æ°u hÃ³a**: [Äá» xuáº¥t cá»¥ thá»ƒ]
- **HÃ nh Ä‘á»™ng Ä‘á» xuáº¥t**: [2-3 hÃ nh Ä‘á»™ng]

### ğŸ¯ MARKETING & BÃN HÃ€NG
- **Hiá»‡u quáº£ hiá»‡n táº¡i**: [ÄÃ¡nh giÃ¡ conversion, AOV]
- **Sáº£n pháº©m tiá»m nÄƒng**: [Top products cáº§n Ä‘áº©y máº¡nh]
- **Chiáº¿n dá»‹ch Ä‘á» xuáº¥t**: [2-3 chiáº¿n dá»‹ch cá»¥ thá»ƒ]
- **HÃ nh Ä‘á»™ng Ä‘á» xuáº¥t**: [2-3 hÃ nh Ä‘á»™ng]

### ğŸ‘¥ KHÃCH HÃ€NG & TRáº¢I NGHIá»†M
- **PhÃ¢n tÃ­ch hÃ nh vi**: [Insights tá»« dá»¯ liá»‡u Ä‘Æ¡n hÃ ng]
- **CÆ¡ há»™i tÄƒng retention**: [Gá»£i Ã½ cá»¥ thá»ƒ]
- **HÃ nh Ä‘á»™ng Ä‘á» xuáº¥t**: [2-3 hÃ nh Ä‘á»™ng]

---

## ğŸ—“ï¸ ROADMAP TRIá»‚N KHAI (Implementation Timeline)

### ğŸš€ TUáº¦N 1-2 (Quick Wins)
- [ ] [HÃ nh Ä‘á»™ng 1 - P0]
- [ ] [HÃ nh Ä‘á»™ng 2 - P0]
- [ ] [HÃ nh Ä‘á»™ng 3 - P0]
- **Má»¥c tiÃªu**: [Káº¿t quáº£ cá»¥ thá»ƒ ká»³ vá»ng]

### ğŸ“ˆ THÃNG 1 (Foundation)
- [ ] [HÃ nh Ä‘á»™ng 1 - P1]
- [ ] [HÃ nh Ä‘á»™ng 2 - P1]
- [ ] [HÃ nh Ä‘á»™ng 3 - P1]
- **Má»¥c tiÃªu**: [Káº¿t quáº£ cá»¥ thá»ƒ ká»³ vá»ng]

### ğŸ¯ THÃNG 2-3 (Growth)
- [ ] [HÃ nh Ä‘á»™ng 1 - P2]
- [ ] [HÃ nh Ä‘á»™ng 2 - P2]
- **Má»¥c tiÃªu**: [Káº¿t quáº£ cá»¥ thá»ƒ ká»³ vá»ng]

### ğŸš€ QUÃ 2-4 (Scale)
- [ ] [Chiáº¿n lÆ°á»£c dÃ i háº¡n 1]
- [ ] [Chiáº¿n lÆ°á»£c dÃ i háº¡n 2]
- **Má»¥c tiÃªu**: [Káº¿t quáº£ cá»¥ thá»ƒ ká»³ vá»ng]

---

## ğŸ“Š KPI DASHBOARD Äá»€ XUáº¤T THEO DÃ•I

### ğŸ“… Theo dÃµi HÃ€NG TUáº¦N:
1. **Doanh thu tuáº§n**: Target [X] VNÄ
2. **Sá»‘ Ä‘Æ¡n hÃ ng**: Target [Y] Ä‘Æ¡n
3. **AOV (GiÃ¡ trá»‹ TB/Ä‘Æ¡n)**: Target [Z] VNÄ
4. **Tá»· lá»‡ chuyá»ƒn Ä‘á»•i**: Target [W]%
5. **Sáº£n pháº©m háº¿t hÃ ng**: Alert náº¿u > [N] sáº£n pháº©m

### ğŸ“… Theo dÃµi HÃ€NG THÃNG:
1. **TÄƒng trÆ°á»Ÿng doanh thu MoM**: Target +[X]%
2. **Tá»· lá»‡ quay vÃ²ng hÃ ng tá»“n**: Target [Y] láº§n/thÃ¡ng
3. **Tá»· lá»‡ hÃ ng tá»“n khá»e máº¡nh**: Target > [Z]%
4. **Customer Retention Rate**: Target [W]%
5. **Gross Margin**: Target [V]%

### ğŸ¯ Má»¥c tiÃªu QUARTERLY:
- **TÄƒng trÆ°á»Ÿng doanh thu**: +[X]% so vá»›i quÃ½ trÆ°á»›c
- **Tá»‘i Æ°u chi phÃ­ váº­n hÃ nh**: Giáº£m [Y]%
- **Má»Ÿ rá»™ng danh má»¥c**: ThÃªm [Z] sáº£n pháº©m má»›i
- **TÄƒng customer base**: +[W] khÃ¡ch hÃ ng má»›i

---

## ğŸ’¡ Káº¾T LUáº¬N & KHUYáº¾N NGHá»Š CHIáº¾N LÆ¯á»¢C

### ğŸ¯ 3 Æ¯u tiÃªn hÃ ng Ä‘áº§u:
1. **[Æ¯u tiÃªn 1]**: [MÃ´ táº£ ngáº¯n gá»n táº¡i sao quan trá»ng]
2. **[Æ¯u tiÃªn 2]**: [MÃ´ táº£ ngáº¯n gá»n táº¡i sao quan trá»ng]
3. **[Æ¯u tiÃªn 3]**: [MÃ´ táº£ ngáº¯n gá»n táº¡i sao quan trá»ng]

### ğŸ“ˆ Dá»± bÃ¡o tÄƒng trÆ°á»Ÿng (náº¿u thá»±c hiá»‡n Ä‘áº§y Ä‘á»§):
- **Doanh thu**: TÄƒng [X]% trong 3 thÃ¡ng tá»›i
- **Lá»£i nhuáº­n**: TÄƒng [Y]% 
- **Hiá»‡u quáº£ váº­n hÃ nh**: Cáº£i thiá»‡n [Z]%
- **Sá»©c khá»e tá»“n kho**: Äáº¡t [W]% hÃ ng tá»“n khá»e máº¡nh

### âš ï¸ Rá»§i ro cáº§n lÆ°u Ã½:
1. [Rá»§i ro 1] - Biá»‡n phÃ¡p phÃ²ng ngá»«a: [...]
2. [Rá»§i ro 2] - Biá»‡n phÃ¡p phÃ²ng ngá»«a: [...]

---

âš¡ **YÃŠU Cáº¦U FORMAT:**
- Sá»­ dá»¥ng emoji phÃ¹ há»£p, báº£ng markdown chuyÃªn nghiá»‡p
- Sá»‘ liá»‡u Cá»¤ THá»‚ vá»›i Ä‘Æ¡n vá»‹ VNÄ, %, thá»i gian rÃµ rÃ ng
- Má»—i Ä‘á» xuáº¥t pháº£i cÃ³: Má»¥c tiÃªu + CÃ¡ch lÃ m + KPI Ä‘o lÆ°á»ng + Timeline
- Viáº¿t tiáº¿ng Viá»‡t chuyÃªn nghiá»‡p, sÃºc tÃ­ch, dá»… hiá»ƒu
- Äá»™ dÃ i: 1200-1800 tá»«
- Æ¯u tiÃªn ACTIONABLE insights hÆ¡n lÃ  mÃ´ táº£ chung chung
"""

    elif analysis_type == 'pricing':
        prompt = base_context + """

ğŸ’° NHIá»†M Vá»¤: PHÃ‚N TÃCH CHIáº¾N LÆ¯á»¢C GIÃ & Tá»I Æ¯U Lá»¢I NHUáº¬N

ğŸ“ YÃŠU Cáº¦U PHÃ‚N TÃCH:

## 1ï¸âƒ£ PHÃ‚N TÃCH GIÃ HIá»†N Táº I
- ÄÃ¡nh giÃ¡ má»©c giÃ¡ cá»§a tá»«ng danh má»¥c sáº£n pháº©m
- So sÃ¡nh giÃ¡ trung bÃ¬nh vá»›i thá»‹ trÆ°á»ng (náº¿u cÃ³ thÃ´ng tin)
- PhÃ¢n tÃ­ch khoáº£ng giÃ¡: tháº¥p, trung bÃ¬nh, cao
- Price elasticity: sáº£n pháº©m nÃ o nháº¡y cáº£m vá»›i giÃ¡?

## 2ï¸âƒ£ CÆ  Há»˜I TÄ‚NG GIÃ ğŸ“ˆ
Táº¡o báº£ng markdown:
| Sáº£n pháº©m/Danh má»¥c | GiÃ¡ hiá»‡n táº¡i | Äá» xuáº¥t | LÃ½ do | TÃ¡c Ä‘á»™ng dá»± kiáº¿n |
|-------------------|--------------|---------|-------|------------------|

### Äiá»u kiá»‡n Ä‘á»ƒ tÄƒng giÃ¡ thÃ nh cÃ´ng:
- [Liá»‡t kÃª 3-5 Ä‘iá»u kiá»‡n cá»¥ thá»ƒ]

## 3ï¸âƒ£ CÆ  Há»˜I GIáº¢M GIÃ/KHUYáº¾N MÃƒI ğŸ“‰
Táº¡o báº£ng markdown:
| Sáº£n pháº©m/Danh má»¥c | GiÃ¡ hiá»‡n táº¡i | Äá» xuáº¥t | Má»¥c tiÃªu | ROI dá»± kiáº¿n |
|-------------------|--------------|---------|----------|-------------|

## 4ï¸âƒ£ CHIáº¾N LÆ¯á»¢C COMBO & BUNDLE ğŸ
### Combo Ä‘á» xuáº¥t:
1. **[TÃªn combo]**: [Sáº£n pháº©m A] + [Sáº£n pháº©m B] khÃ¡c danh má»¥c (vd 1 Ä‘iá»‡n thoáº¡i +1 Ä‘á»“ng há»“)
   - GiÃ¡ láº»: [X] VNÄ
   - GiÃ¡ combo: [Y] VNÄ (Tiáº¿t kiá»‡m [Z]%)
   - LÃ½ do combo nÃ y háº¥p dáº«n: [...]
   - Má»¥c tiÃªu: tÄƒng AOV lÃªn [X]%

[Äá» xuáº¥t 3-5 combo]

## 5ï¸âƒ£ Lá»ŠCH KHUYáº¾N MÃƒI Äá»€ XUáº¤T ğŸ“…
Táº¡o báº£ng markdown:
| Thá»i Ä‘iá»ƒm | Loáº¡i KM | Sáº£n pháº©m | Má»©c giáº£m | Má»¥c tiÃªu | Budget |
|-----------|---------|----------|----------|----------|--------|

## 6ï¸âƒ£ CHIáº¾N THUáº¬T GIÃ TÃ‚M LÃ ğŸ§ 
- **Psychological Pricing**: GiÃ¡ láº» (999,000 thay vÃ¬ 1,000,000)
- **Anchor Pricing**: Hiá»ƒn thá»‹ giÃ¡ gá»‘c Ä‘á»ƒ táº¡o giÃ¡ trá»‹
- **Premium Pricing**: Sáº£n pháº©m cao cáº¥p Ä‘á»‹nh vá»‹ giÃ¡ cao
- **Loss Leader**: Sáº£n pháº©m thu hÃºt vá»›i giÃ¡ tháº¥p

## 7ï¸âƒ£ Dá»° ÃN TÄ‚NG DOANH THU VÃ€ Lá»¢I NHUáº¬N
- TÄƒng doanh thu dá»± kiáº¿n: **+[X]%**
- TÄƒng lá»£i nhuáº­n dá»± kiáº¿n: **+[Y]%**
- TÄƒng AOV dá»± kiáº¿n: **+[Z]%**
- Timeline thá»±c hiá»‡n: [3-6 thÃ¡ng]
- NgÃ¢n sÃ¡ch cáº§n: [X] VNÄ
- ROI expected: [Y]X

âš¡ Viáº¿t chi tiáº¿t vá»›i sá»‘ liá»‡u cá»¥ thá»ƒ, dá»… Ã¡p dá»¥ng ngay!
"""

    elif analysis_type == 'inventory':
        prompt = base_context + f"""

ğŸ“¦ NHIá»†M Vá»¤: PHÃ‚N TÃCH & Tá»I Æ¯U QUáº¢N LÃ Tá»’N KHO

ğŸ“ YÃŠU Cáº¦U PHÃ‚N TÃCH:

## 1ï¸âƒ£ ÄÃNH GIÃ TÃŒNH TRáº NG Tá»’N KHO HIá»†N Táº I
### ğŸ“Š PhÃ¢n loáº¡i tá»“n kho:
Táº¡o báº£ng markdown vá»›i dá»¯ liá»‡u thá»±c táº¿:
| Loáº¡i | Sá»‘ lÆ°á»£ng SP | GiÃ¡ trá»‹ | Tá»· lá»‡ % |
|------|-------------|---------|---------|
| ğŸŸ¢ Tá»‘t (â‰¥30 SP) | {inventory_analysis.get('stock_distribution', {}).get('well_stocked', {}).get('count', 0)} | {inventory_analysis.get('stock_distribution', {}).get('well_stocked', {}).get('value', 0):,.0f} VNÄ | {inventory_analysis.get('stock_distribution', {}).get('well_stocked', {}).get('count', 0)/overview.get('total_products', 1)*100:.1f}% |
| ğŸŸ¡ Trung bÃ¬nh (10-29) | {inventory_analysis.get('stock_distribution', {}).get('medium_stock', {}).get('count', 0)} | {inventory_analysis.get('stock_distribution', {}).get('medium_stock', {}).get('value', 0):,.0f} VNÄ | {inventory_analysis.get('stock_distribution', {}).get('medium_stock', {}).get('count', 0)/overview.get('total_products', 1)*100:.1f}% |
| ğŸ”´ Tháº¥p (1-9) | {inventory_analysis.get('stock_distribution', {}).get('low_stock', {}).get('count', 0)} | {inventory_analysis.get('stock_distribution', {}).get('low_stock', {}).get('value', 0):,.0f} VNÄ | {inventory_analysis.get('stock_distribution', {}).get('low_stock', {}).get('count', 0)/overview.get('total_products', 1)*100:.1f}% |
| âš« Háº¿t hÃ ng (0) | {inventory_analysis.get('stock_distribution', {}).get('out_of_stock', {}).get('count', 0)} | 0 VNÄ | {inventory_analysis.get('stock_distribution', {}).get('out_of_stock', {}).get('count', 0)/overview.get('total_products', 1)*100:.1f}% |

### ğŸ’° GiÃ¡ trá»‹ tá»“n kho:
- **Tá»•ng giÃ¡ trá»‹**: {overview.get('total_inventory_value', 0):,.0f} VNÄ
- **Tá»· lá»‡ quay vÃ²ng**: {overview.get('inventory_turnover_ratio', 0):.2f} (láº§n/nÄƒm)
- **Vá»‘n Ä‘Ã³ng bÄƒng** (hÃ ng tá»“n lÃ¢u): {inventory_analysis.get('stock_distribution', {}).get('well_stocked', {}).get('value', 0):,.0f} VNÄ
- **Kháº£ nÄƒng thanh khoáº£n**: {'Cao' if overview.get('inventory_turnover_ratio', 0) > 4 else 'Trung bÃ¬nh' if overview.get('inventory_turnover_ratio', 0) > 2 else 'Tháº¥p'}

## 2ï¸âƒ£ Æ¯U TIÃŠN NHáº¬P HÃ€NG NGAY âš¡
Táº¡o báº£ng markdown:
| STT | Sáº£n pháº©m | Tá»“n hiá»‡n táº¡i | BÃ¡n TB/ngÃ y | Háº¿t sau X ngÃ y | SL Ä‘á» xuáº¥t nháº­p |
|-----|----------|--------------|-------------|----------------|-----------------|

### ğŸ“‹ Káº¿ hoáº¡ch nháº­p hÃ ng chi tiáº¿t:
**TUáº¦N NÃ€Y (URGENT - Tá»“n kho 1-5):**
{json.dumps([{'tÃªn': p.get('name'), 'tá»“n_kho': p.get('available_stock', 0), 'giÃ¡': f"{p.get('price', 0):,.0f} VNÄ"} for p in inventory_analysis.get('critical_stock_products', [])], indent=2, ensure_ascii=False)}
- Tá»•ng vá»‘n cáº§n: {sum([p.get('price', 0) * max(50 - p.get('available_stock', 0), 0) for p in inventory_analysis.get('critical_stock_products', [])]):,.0f} VNÄ

**THÃNG NÃ€Y (Tá»“n kho 6-15):**
{json.dumps([{'tÃªn': p.get('name'), 'tá»“n_kho': p.get('available_stock', 0), 'giÃ¡': f"{p.get('price', 0):,.0f} VNÄ"} for p in inventory_analysis.get('warning_stock_products', [])], indent=2, ensure_ascii=False)}
- NgÃ¢n sÃ¡ch: {sum([p.get('price', 0) * max(30 - p.get('available_stock', 0), 0) for p in inventory_analysis.get('warning_stock_products', [])]):,.0f} VNÄ

## 3ï¸âƒ£ Xá»¬ LÃ HÃ€NG Tá»’N KHO LÃ‚U ğŸ—‘ï¸
Táº¡o báº£ng markdown:
| Sáº£n pháº©m | Tá»“n | GiÃ¡ trá»‹ | Thá»i gian tá»“n | Giáº£i phÃ¡p Ä‘á» xuáº¥t |
|----------|-----|---------|---------------|-------------------|

### Chiáº¿n lÆ°á»£c xá»­ lÃ½:
1. **Flash Sale Weekend**: Giáº£m 40-50% cho top [X] sáº£n pháº©m
2. **Bundle Deal**: Káº¿t há»£p vá»›i sáº£n pháº©m hot
3. **Clearance Sale**: Xá»­ lÃ½ tá»“n kho cÅ© vá»›i giáº£m giÃ¡ sÃ¢u
4. **Trade-in Program**: Thu cÅ© Ä‘á»•i má»›i

## 4ï¸âƒ£ CHIáº¾N LÆ¯á»¢C Tá»I Æ¯U Tá»’N KHO ğŸ¯
### A. PhÃ¢n loáº¡i ABC:
- **NhÃ³m A** (20% SP, 80% giÃ¡ trá»‹): [Liá»‡t kÃª sáº£n pháº©m chiáº¿n lÆ°á»£c]
- **NhÃ³m B** (30% SP, 15% giÃ¡ trá»‹): [Sáº£n pháº©m quan trá»ng]
- **NhÃ³m C** (50% SP, 5% giÃ¡ trá»‹): [Sáº£n pháº©m phá»¥]

### B. Cáº£i thiá»‡n váº­n hÃ nh:
1. **Há»‡ thá»‘ng quáº£n lÃ½ kho:**
   - Äá» xuáº¥t pháº§n má»m/cÃ´ng cá»¥ phÃ¹ há»£p
   - Barcode/QR scanning
   
2. **Quy trÃ¬nh kiá»ƒm kÃª:**
   - Táº§n suáº¥t: [HÃ ng tuáº§n/thÃ¡ng]
   - PhÆ°Æ¡ng phÃ¡p: [Cycle counting/Full inventory]
   
3. **Sáº¯p xáº¿p kho:**
   - Layout tá»‘i Æ°u theo ABC
   - FIFO/LIFO strategy

### C. ChÃ­nh sÃ¡ch an toÃ n kho:
- **Safety Stock**: [X] Ä‘Æ¡n vá»‹
- **Reorder Point**: Khi tá»“n <= [Y]
- **Lead Time**: [Z] ngÃ y
- **EOQ** (Economic Order Quantity): [TÃ­nh toÃ¡n]

## 5ï¸âƒ£ Káº¾ HOáº CH Dá»° TRÃ™ 3 THÃNG Tá»šI ğŸ“…
### ThÃ¡ng 1 (Hiá»‡n táº¡i):
- NgÃ¢n sÃ¡ch: [...] VNÄ
- Danh má»¥c Æ°u tiÃªn: [...]
- Sáº£n pháº©m cáº§n Ä‘áº©y máº¡nh: [...]

### ThÃ¡ng 2:
- MÃ¹a vá»¥/sá»± kiá»‡n: [...]
- Sáº£n pháº©m seasonal: [...]

### ThÃ¡ng 3:
- Chuáº©n bá»‹ cho: [...]
- Sáº£n pháº©m má»›i launch: [...]

## 6ï¸âƒ£ CHá»ˆ Sá» HIá»†U SUáº¤T KHO
TÃ­nh toÃ¡n vÃ  Ä‘Ã¡nh giÃ¡:
- **Inventory Turnover Ratio**: [...] láº§n/nÄƒm [Tá»‘t/TB/Cáº§n cáº£i thiá»‡n]
- **Days Sales of Inventory (DSI)**: [...] ngÃ y
- **Stockout Rate**: [...]% [Má»¥c tiÃªu: <5%]
- **Carrying Cost**: [...] VNÄ/thÃ¡ng
- **Fill Rate**: [...]% [Má»¥c tiÃªu: >95%]

âš¡ PhÃ¢n tÃ­ch chi tiáº¿t vá»›i sá»‘ liá»‡u cá»¥ thá»ƒ, káº¿ hoáº¡ch thá»±c thi rÃµ rÃ ng!
"""

    elif analysis_type == 'sales':
        prompt = base_context + """

ğŸš€ NHIá»†M Vá»¤: CHIáº¾N LÆ¯á»¢C TÄ‚NG TRÆ¯á»NG BÃN HÃ€NG & REVENUE OPTIMIZATION

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Cáº¤U TRÃšC BÃO CÃO YÃŠU Cáº¦U:

## ğŸ“Š EXECUTIVE SUMMARY - TÃŒNH HÃŒNH BÃN HÃ€NG
> TÃ³m táº¯t 3-4 cÃ¢u vá» hiá»‡n tráº¡ng doanh sá»‘, highlight 2-3 insights quan trá»ng nháº¥t vÃ  cÆ¡ há»™i tÄƒng trÆ°á»Ÿng lá»›n nháº¥t.

---

## ğŸ“ˆ SALES PERFORMANCE DASHBOARD

### Báº£ng chá»‰ sá»‘ bÃ¡n hÃ ng chÃ­nh:

| Chá»‰ sá»‘ | GiÃ¡ trá»‹ hiá»‡n táº¡i | Benchmark | Gap | CÆ¡ há»™i tÄƒng trÆ°á»Ÿng |
|--------|------------------|-----------|-----|---------------------|
| ğŸ’° Doanh thu/thÃ¡ng | [X] VNÄ | [Y] VNÄ | [Z]% | +[W]% náº¿u Ä‘áº¡t benchmark |
| ğŸ›’ Sá»‘ Ä‘Æ¡n hÃ ng | [X] Ä‘Æ¡n | [Y] Ä‘Æ¡n | [Z]% | +[W] Ä‘Æ¡n/thÃ¡ng |
| ğŸ’µ AOV (GiÃ¡ trá»‹ TB/Ä‘Æ¡n) | [X] VNÄ | [Y] VNÄ | [Z]% | +[W] VNÄ/Ä‘Æ¡n |
| ğŸ“Š Conversion Rate | [X]% | [Y]% | [Z]% | +[W]% conversion |
| ğŸ”„ Repeat Purchase Rate | [X]% | [Y]% | [Z]% | +[W]% retention |
| ğŸ‘¥ Customer Lifetime Value | [X] VNÄ | [Y] VNÄ | [Z]% | +[W] VNÄ/khÃ¡ch |

**Tá»•ng tiá»m nÄƒng tÄƒng trÆ°á»Ÿng**: +[X]% doanh thu náº¿u Ä‘áº¡t táº¥t cáº£ benchmarks

---

## ğŸ¯ PHÃ‚N TÃCH SALES FUNNEL CHI TIáº¾T

### Conversion Funnel Analysis:

```
ğŸ‘ï¸ Traffic (100%)
    â†“ [-X]% drop
ğŸ›ï¸ Product View ([Y]%)
    â†“ [-X]% drop  â† ÄIá»‚M Yáº¾U 1: Cáº£i thiá»‡n product pages
ğŸ›’ Add to Cart ([Y]%)
    â†“ [-X]% drop  â† ÄIá»‚M Yáº¾U 2: Cart abandonment cao
ğŸ’³ Checkout ([Y]%)
    â†“ [-X]% drop  â† ÄIá»‚M Yáº¾U 3: Friction trong thanh toÃ¡n
âœ… Purchase ([Y]%)
```

### Báº£ng phÃ¢n tÃ­ch tá»«ng giai Ä‘oáº¡n:

| Giai Ä‘oáº¡n | Conversion | Benchmark | Váº¥n Ä‘á» | Giáº£i phÃ¡p | Impact dá»± kiáº¿n |
|-----------|------------|-----------|--------|-----------|----------------|
| View â†’ Cart | [X]% | [Y]% | [...] | [...] | +[Z]% orders |
| Cart â†’ Checkout | [X]% | [Y]% | [...] | [...] | +[Z]% orders |
| Checkout â†’ Purchase | [X]% | [Y]% | [...] | [...] | +[Z]% orders |

---

## ğŸ‘¥ PHÃ‚N KHÃšC KHÃCH HÃ€NG & CHIáº¾N LÆ¯á»¢C

### Customer Segmentation Matrix:

| PhÃ¢n khÃºc | % KhÃ¡ch hÃ ng | % Doanh thu | AOV | Frequency | Äáº·c Ä‘iá»ƒm | Chiáº¿n lÆ°á»£c |
|-----------|--------------|-------------|-----|-----------|----------|------------|
| ğŸ’ VIP (High Value) | [X]% | [Y]% | [Z] VNÄ | [W] láº§n/thÃ¡ng | [...] | [...] |
| â­ Loyal (Regular) | [X]% | [Y]% | [Z] VNÄ | [W] láº§n/thÃ¡ng | [...] | [...] |
| ğŸŒ± New (First-time) | [X]% | [Y]% | [Z] VNÄ | [W] láº§n | [...] | [...] |
| ğŸ˜´ At-Risk (Churning) | [X]% | [Y]% | [Z] VNÄ | [W] láº§n | [...] | [...] |
| ğŸ’” Lost (Inactive) | [X]% | [Y]% | [Z] VNÄ | 0 | [...] | [...] |

### Chiáº¿n lÆ°á»£c cho tá»«ng phÃ¢n khÃºc:

#### ğŸ’ VIP Customers (Protect & Grow)
1. **VIP Loyalty Program**:
   - Exclusive perks: Early access, special pricing
   - Personal account manager
   - Birthday/anniversary gifts
   - **Target**: TÄƒng AOV +20%, Frequency +30%

2. **Upsell/Cross-sell Premium**:
   - Premium product recommendations
   - Bundle deals exclusive for VIP
   - **Expected**: +[X] VNÄ/khÃ¡ch/thÃ¡ng

#### â­ Loyal Customers (Maximize Value)
1. **Referral Program**: ThÆ°á»Ÿng [X] VNÄ cho má»—i giá»›i thiá»‡u thÃ nh cÃ´ng
2. **Subscription Model**: Giáº£m [Y]% cho Ä‘Äƒng kÃ½ Ä‘á»‹nh ká»³
3. **Target**: Chuyá»ƒn [Z]% lÃªn VIP tier

#### ğŸŒ± New Customers (Convert & Retain)
1. **Welcome Journey** (7 ngÃ y):
   - Day 0: Welcome email + 10% off next purchase
   - Day 2: Product education + use cases
   - Day 5: Social proof + reviews
   - Day 7: Urgency + limited offer
2. **First Purchase Incentive**: Free shipping + gift
3. **Target**: [X]% repeat purchase trong 30 ngÃ y

#### ğŸ˜´ At-Risk Customers (Win-back)
1. **Re-engagement Campaign**:
   - "We miss you" email vá»›i 15% discount
   - Survey: Táº¡i sao khÃ´ng mua ná»¯a?
   - Personalized offers dá»±a trÃªn lá»‹ch sá»­
2. **Target**: Win-back [X]% trong 60 ngÃ y

#### ğŸ’” Lost Customers (Reactivation)
1. **Win-back Campaign**: 20-30% discount + free shipping
2. **New product announcement**: "Look what's new"
3. **Target**: Reactivate [X]% trong 90 ngÃ y

---

## ğŸ¯ CHIáº¾N LÆ¯á»¢C TÄ‚NG AOV (Average Order Value)

### Má»¥c tiÃªu: TÄƒng AOV tá»« [X] VNÄ lÃªn [Y] VNÄ (+[Z]%)

#### A. Product Bundling Strategy

| Bundle Name | Products | GiÃ¡ láº» | GiÃ¡ bundle | Tiáº¿t kiá»‡m | Target Sales |
|-------------|----------|--------|------------|-----------|--------------|
| [Bundle 1] | [A + B + C] | [X] VNÄ | [Y] VNÄ | [Z]% | [W] bundles/thÃ¡ng |
| [Bundle 2] | [A + B] | [X] VNÄ | [Y] VNÄ | [Z]% | [W] bundles/thÃ¡ng |

**Äá» xuáº¥t 5-7 bundles cá»¥ thá»ƒ dá»±a trÃªn:**
- Sáº£n pháº©m thÆ°á»ng mua cÃ¹ng nhau
- Complementary products
- Seasonal bundles
- Gift sets

#### B. Upselling Tactics
1. **Product Page Upsells**:
   - "Customers also bought" section
   - "Upgrade to premium version" vá»›i so sÃ¡nh rÃµ rÃ ng
   - Limited-time upgrade offers

2. **Cart Upsells**:
   - "Add [Product X] for only [Y] VNÄ more"
   - Free shipping threshold: "ThÃªm [X] VNÄ Ä‘á»ƒ Ä‘Æ°á»£c free ship"
   - Volume discounts: "Mua 2 giáº£m 10%, mua 3 giáº£m 15%"

#### C. Cross-selling Strategy
1. **Intelligent Recommendations**:
   - AI-powered "You may also like"
   - "Complete the look/set"
   - Accessories & add-ons

2. **Post-purchase Cross-sell**:
   - Thank you page offers
   - Follow-up emails vá»›i related products

**Expected Impact**: TÄƒng AOV +[X]% = +[Y] VNÄ doanh thu/thÃ¡ng

---

## ğŸ“¢ MULTI-CHANNEL MARKETING PLAYBOOK

### A. PAID ADVERTISING STRATEGY

#### 1. Facebook & Instagram Ads

| Campaign Type | Budget/thÃ¡ng | Target Audience | Objective | Expected ROAS |
|---------------|--------------|-----------------|-----------|---------------|
| Prospecting | [X] VNÄ | Lookalike 1-3% | Acquisition | 3-4X |
| Retargeting - Cart | [X] VNÄ | Cart abandoners | Conversion | 5-7X |
| Retargeting - View | [X] VNÄ | Product viewers | Conversion | 4-5X |
| Engagement | [X] VNÄ | Page engagers | Awareness | 2-3X |

**Creative Strategy**:
- Video ads: Product demos, testimonials
- Carousel ads: Showcase bundles
- Collection ads: Category browsing
- Stories ads: Limited-time offers

#### 2. Google Ads Strategy

| Campaign Type | Budget/thÃ¡ng | Keywords | Expected CTR | Expected ROAS |
|---------------|--------------|----------|--------------|---------------|
| Search - Brand | [X] VNÄ | Brand terms | [Y]% | 8-10X |
| Search - Generic | [X] VNÄ | Product terms | [Y]% | 4-5X |
| Shopping | [X] VNÄ | Product feed | [Y]% | 5-6X |
| Display Remarketing | [X] VNÄ | Site visitors | [Y]% | 3-4X |

#### 3. TikTok Ads (if applicable)
- Spark Ads vá»›i UGC content
- In-Feed Ads vá»›i trending sounds
- Budget: [X] VNÄ/thÃ¡ng
- Target ROAS: 3-5X

**Total Marketing Budget**: [X] VNÄ/thÃ¡ng
**Expected Revenue**: [Y] VNÄ/thÃ¡ng
**Overall ROAS Target**: 4-5X

### B. ORGANIC MARKETING STRATEGY

#### 1. Content Marketing Calendar

| Week | Content Type | Topic | Platform | Goal |
|------|--------------|-------|----------|------|
| 1 | Blog post | [Topic] | Website | SEO traffic |
| 1 | Video | Product review | YouTube | Education |
| 1 | Infographic | [Topic] | Social | Engagement |
| 2 | ... | ... | ... | ... |

#### 2. Social Media Strategy
- **Facebook**: 5-7 posts/tuáº§n (mix: 40% educational, 30% promotional, 30% engagement)
- **Instagram**: Daily posts + 3-5 Stories/ngÃ y
- **TikTok**: 3-5 videos/tuáº§n (trending challenges, product demos)
- **Target**: TÄƒng followers +50%, engagement rate >5%

#### 3. Email Marketing Automation

**Flows cáº§n setup:**

1. **Welcome Series** (5 emails, 10 ngÃ y):
   - Email 1 (Day 0): Welcome + 10% discount code
   - Email 2 (Day 2): Brand story + bestsellers
   - Email 3 (Day 5): Educational content + use cases
   - Email 4 (Day 7): Social proof + reviews
   - Email 5 (Day 10): Last chance + urgency

2. **Abandoned Cart Recovery** (3 emails):
   - Email 1 (1 giá»): Gentle reminder
   - Email 2 (24 giá»): 5% discount incentive
   - Email 3 (48 giá»): 10% discount + free shipping

3. **Post-Purchase** (4 emails):
   - Email 1 (Ngay sau): Thank you + tracking
   - Email 2 (3 ngÃ y): How to use + tips
   - Email 3 (7 ngÃ y): Review request + incentive
   - Email 4 (14 ngÃ y): Cross-sell recommendations

4. **Win-back Campaign** (Inactive 60+ ngÃ y):
   - Email 1: "We miss you" + 15% off
   - Email 2: New arrivals showcase
   - Email 3: Last chance + 20% off

**Expected Email Performance**:
- Open rate: 25-30%
- Click rate: 3-5%
- Conversion rate: 2-3%
- Revenue from email: [X]% of total

---

## ğŸ PROMOTIONAL CALENDAR & CAMPAIGNS

### Quarterly Promotion Strategy:

| ThÃ¡ng | Campaign | Discount | Duration | Products | Budget | Expected Revenue |
|-------|----------|----------|----------|----------|--------|------------------|
| 1 | New Year Sale | 20-30% | 7 ngÃ y | All | [X] VNÄ | [Y] VNÄ |
| 1 | Flash Sale Friday | 40% | 24h | Selected | [X] VNÄ | [Y] VNÄ |
| 2 | Valentine's Day | 15% + Gift | 3 ngÃ y | Bundles | [X] VNÄ | [Y] VNÄ |
| 2 | Mid-month Madness | BOGO 50% | 48h | Slow movers | [X] VNÄ | [Y] VNÄ |
| 3 | Spring Collection | 10% | 14 ngÃ y | New arrivals | [X] VNÄ | [Y] VNÄ |
| 3 | Clearance Sale | 50-70% | 7 ngÃ y | Old stock | [X] VNÄ | [Y] VNÄ |

### Loyalty & Referral Programs:

**Loyalty Program Design**:
- Earn 1 point per 1,000 VNÄ spent
- Tiers: Bronze (0-999), Silver (1000-4999), Gold (5000+)
- Benefits per tier: [Liá»‡t kÃª cá»¥ thá»ƒ]
- Expected participation: [X]% customers

**Referral Program**:
- Referrer gets: [X] VNÄ credit
- Referee gets: [Y]% off first order
- Target: [Z] referrals/thÃ¡ng

---

## ğŸš€ CONVERSION RATE OPTIMIZATION (CRO)

### A. Website Optimization Checklist

#### Homepage:
- [ ] Clear value proposition above the fold
- [ ] Featured products/bestsellers prominently displayed
- [ ] Trust signals: Reviews, ratings, badges
- [ ] Mobile-optimized (>50% traffic lÃ  mobile)
- [ ] Page load time <3 seconds

#### Product Pages:
- [ ] High-quality images (5-7 photos + video)
- [ ] Detailed descriptions with benefits (not just features)
- [ ] Customer reviews & ratings visible
- [ ] Clear CTA button (contrasting color)
- [ ] Stock urgency ("Only X left!")
- [ ] Social proof ("Y people viewing this")
- [ ] Size guide/comparison chart
- [ ] Related products section

#### Cart & Checkout:
- [ ] Progress indicator (4 steps â†’ 1 page checkout)
- [ ] Guest checkout option
- [ ] Multiple payment methods (COD, card, e-wallet)
- [ ] Trust badges (SSL, secure payment)
- [ ] Free shipping threshold visible
- [ ] Exit-intent popup (cart abandonment)
- [ ] Save cart for later
- [ ] Mobile-optimized checkout

### B. A/B Testing Roadmap

| Test | Variant A | Variant B | Metric | Expected Lift |
|------|-----------|-----------|--------|---------------|
| CTA Button | "Mua ngay" | "ThÃªm vÃ o giá»" | CTR | +5-10% |
| Product Image | Lifestyle | White background | Conversion | +3-5% |
| Pricing Display | 999,000Ä‘ | 999.000Ä‘ | Conversion | +2-3% |
| Checkout Flow | Multi-step | One-page | Completion | +10-15% |

---

## ğŸ“Š GROWTH ROADMAP - TÄ‚NG TRÆ¯á»NG 50% TRONG 6 THÃNG

### ğŸ¯ Phase 1: THÃNG 1-2 (Foundation) - Target: +15% Revenue

#### Quick Wins (Tuáº§n 1-2):
1. **Setup Email Automation** (Impact: +5% revenue)
   - Abandoned cart recovery
   - Welcome series
   - Post-purchase flow
   - **Budget**: 0 VNÄ (sá»­ dá»¥ng tools cÃ³ sáºµn)
   - **Timeline**: 1 tuáº§n

2. **Optimize Top 10 Product Pages** (Impact: +3% conversion)
   - Add more images & videos
   - Improve descriptions
   - Add reviews
   - **Budget**: [X] VNÄ (photography)
   - **Timeline**: 1 tuáº§n

3. **Launch First Bundle Offers** (Impact: +10% AOV)
   - Create 3-5 bundles
   - Promote on homepage
   - **Budget**: 0 VNÄ
   - **Timeline**: 3 ngÃ y

#### Growth Initiatives (Tuáº§n 3-8):
4. **Facebook Ads Campaign** (Impact: +20% traffic)
   - Prospecting + Retargeting
   - **Budget**: [X] VNÄ/thÃ¡ng
   - **Expected ROAS**: 4X
   - **Timeline**: Ongoing

5. **Loyalty Program Launch** (Impact: +8% repeat rate)
   - Design tier structure
   - Integrate with website
   - **Budget**: [Y] VNÄ (setup)
   - **Timeline**: 2 tuáº§n

**Phase 1 KPIs**:
- Revenue: +15% ([X] VNÄ â†’ [Y] VNÄ)
- Orders: +12%
- AOV: +10%
- Conversion: +3%

### ğŸš€ Phase 2: THÃNG 3-4 (Acceleration) - Target: +20% Revenue

#### Initiatives:
6. **Google Ads Expansion** (Impact: +15% traffic)
7. **Referral Program Launch** (Impact: +10% new customers)
8. **Content Marketing** (Impact: +20% organic traffic)
9. **Influencer Partnerships** (Impact: +25% brand awareness)
10. **One-page Checkout** (Impact: +12% checkout conversion)

**Phase 2 KPIs**:
- Revenue: +20% cumulative
- New customers: +30%
- Organic traffic: +40%

### ğŸ¯ Phase 3: THÃNG 5-6 (Scale & Optimize) - Target: +15% Revenue

#### Initiatives:
11. **TikTok Ads** (Impact: +20% younger audience)
12. **Advanced Segmentation** (Impact: +15% email revenue)
13. **Subscription Model** (Impact: +25% predictable revenue)
14. **Mobile App** (Impact: +30% retention)
15. **Marketplace Expansion** (Shopee, Lazada, Tiki)

**Phase 3 KPIs**:
- Revenue: +50% cumulative (vs thÃ¡ng 0)
- Customer base: +60%
- Repeat rate: +40%

---

## ğŸ“Š KPI DASHBOARD & TRACKING

### Weekly Tracking:
1. **Revenue**: [X] VNÄ (Target: [Y] VNÄ)
2. **Orders**: [X] Ä‘Æ¡n (Target: [Y] Ä‘Æ¡n)
3. **AOV**: [X] VNÄ (Target: [Y] VNÄ)
4. **Conversion Rate**: [X]% (Target: [Y]%)
5. **Traffic**: [X] visitors (Target: [Y] visitors)

### Monthly Tracking:
1. **Revenue Growth MoM**: [X]% (Target: +8-10%/thÃ¡ng)
2. **Customer Acquisition**: [X] khÃ¡ch má»›i (Target: [Y])
3. **CAC (Customer Acquisition Cost)**: [X] VNÄ (Target: <[Y] VNÄ)
4. **LTV (Lifetime Value)**: [X] VNÄ (Target: >[Y] VNÄ)
5. **LTV:CAC Ratio**: [X]:1 (Target: >3:1)
6. **Repeat Purchase Rate**: [X]% (Target: [Y]%)
7. **Email Revenue %**: [X]% (Target: 20-30%)
8. **Paid Ads ROAS**: [X]X (Target: >4X)

### Quarterly Goals:
- **Revenue**: +[X]% vs quÃ½ trÆ°á»›c
- **Profit Margin**: [Y]% (Target: [Z]%)
- **Market Share**: [X]% (Target: +[Y]%)
- **Customer Satisfaction**: [X]% (Target: >90%)

---

## ğŸ’¡ Káº¾T LUáº¬N & HÃ€NH Äá»˜NG Æ¯U TIÃŠN

### ğŸ¯ Top 5 Priorities (LÃ m ngay tuáº§n nÃ y):
1. **[Action 1]**: [MÃ´ táº£ + Expected impact]
2. **[Action 2]**: [MÃ´ táº£ + Expected impact]
3. **[Action 3]**: [MÃ´ táº£ + Expected impact]
4. **[Action 4]**: [MÃ´ táº£ + Expected impact]
5. **[Action 5]**: [MÃ´ táº£ + Expected impact]

### ğŸ“ˆ Revenue Forecast (6 thÃ¡ng):
- **ThÃ¡ng 1-2**: [X] VNÄ (+15%)
- **ThÃ¡ng 3-4**: [Y] VNÄ (+35% cumulative)
- **ThÃ¡ng 5-6**: [Z] VNÄ (+50% cumulative)
- **Total Additional Revenue**: +[W] VNÄ

### ğŸ’° Investment Required:
- Marketing: [X] VNÄ
- Technology: [Y] VNÄ
- Content: [Z] VNÄ
- **Total**: [W] VNÄ
- **Expected ROI**: [V]X

### âš ï¸ Risk Mitigation:
1. **Risk**: [MÃ´ táº£] â†’ **Mitigation**: [Giáº£i phÃ¡p]
2. **Risk**: [MÃ´ táº£] â†’ **Mitigation**: [Giáº£i phÃ¡p]

---

âš¡ **YÃŠU Cáº¦U FORMAT:**
- Sá»‘ liá»‡u Cá»¤ THá»‚ vá»›i Ä‘Æ¡n vá»‹ VNÄ, %, timeline rÃµ rÃ ng
- Má»—i chiáº¿n lÆ°á»£c cÃ³: Má»¥c tiÃªu + CÃ¡ch lÃ m + Budget + Timeline + KPI + Expected ROI
- Æ¯u tiÃªn ACTIONABLE tactics cÃ³ thá»ƒ triá»ƒn khai ngay
- Äá»™ dÃ i: 1500-2000 tá»«
- Viáº¿t tiáº¿ng Viá»‡t chuyÃªn nghiá»‡p, dá»… hiá»ƒu, cÃ³ cáº¥u trÃºc
"""

    else:
        prompt = base_context + "\n\nPhÃ¢n tÃ­ch tá»•ng quan vÃ  Ä‘Æ°a ra Ä‘á» xuáº¥t."

    return prompt


@router.get("/chroma-data")
async def get_all_chroma_data():
    """
    Endpoint Ä‘á»ƒ hiá»ƒn thá»‹ táº¥t cáº£ dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trong Chroma DB instance chroma_analytics
    
    Returns:
        Dict chá»©a táº¥t cáº£ collections vÃ  dá»¯ liá»‡u cá»§a chÃºng
    """
    try:
        global chroma_client
        if chroma_client is None:
            return {"error": "ChromaDB client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o"}
        
        # Láº¥y táº¥t cáº£ collections
        collections = chroma_client.list_collections()
        
        result = {
            "instance_path": "./chroma_analytics",
            "total_collections": len(collections),
            "collections": {},
            "timestamp": datetime.now().isoformat()
        }
        
        # Duyá»‡t qua tá»«ng collection
        for collection in collections:
            collection_name = collection.name
            
            try:
                # Láº¥y táº¥t cáº£ documents - khÃ´ng cáº§n include vÃ¬ máº·c Ä‘á»‹nh Ä‘Ã£ cÃ³ ids, documents, metadatas
                all_data = collection.get()
                
                result["collections"][collection_name] = {
                    "metadata": collection.metadata,
                    "total_documents": len(all_data.get('ids', [])),
                    "documents": []
                }
                
                # Táº¡o danh sÃ¡ch documents vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin
                ids = all_data.get('ids', [])
                documents = all_data.get('documents', [])
                metadatas = all_data.get('metadatas', [])
                
                for i, doc_id in enumerate(ids):
                    doc_info = {
                        "id": doc_id,
                        "content": documents[i] if i < len(documents) else None,
                        "metadata": metadatas[i] if metadatas and i < len(metadatas) else None
                    }
                    result["collections"][collection_name]["documents"].append(doc_info)
                    
            except Exception as e:
                result["collections"][collection_name] = {
                    "error": f"KhÃ´ng thá»ƒ Ä‘á»c collection: {str(e)}",
                    "metadata": collection.metadata
                }
        
        print(f"[Chroma Data] Retrieved data from {len(collections)} collections")
        return result
        
    except Exception as e:
        return {"error": f"Lá»—i khi truy cáº­p Chroma DB: {str(e)}"}


@router.get("/chroma-stats")
async def get_chroma_stats():
    """
    Endpoint Ä‘á»ƒ láº¥y thá»‘ng kÃª nhanh vá» Chroma DB
    
    Returns:
        Dict chá»©a thá»‘ng kÃª tá»•ng quan
    """
    try:
        global chroma_client
        if chroma_client is None:
            return {"error": "ChromaDB client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o"}
        
        collections = chroma_client.list_collections()
        
        stats = {
            "instance_path": "./chroma_analytics",
            "total_collections": len(collections),
            "collections_stats": {},
            "total_documents": 0,
            "timestamp": datetime.now().isoformat()
        }
        
        for collection in collections:
            try:
                count = collection.count()
                stats["collections_stats"][collection.name] = {
                    "documents_count": count,
                    "metadata": collection.metadata
                }
                stats["total_documents"] += count
            except Exception as e:
                stats["collections_stats"][collection.name] = {
                    "error": str(e),
                    "metadata": collection.metadata
                }
        
        return stats
        
    except Exception as e:
        return {"error": f"Lá»—i khi láº¥y thá»‘ng kÃª Chroma DB: {str(e)}"}


class SyncDataRequest(BaseModel):
    """Request model for data synchronization"""
    spring_service_url: Optional[str] = None
    auth_token: str
    clear_existing: Optional[bool] = True


class ProcessDocumentRequest(BaseModel):
    """Request model for document processing"""
    file_path: str
    business_id: str
    business_username: str
    file_name: str
    file_type: str
    description: Optional[str] = None


@router.post("/process-document")
async def process_business_document(request: ProcessDocumentRequest):
    """
    Xá»­ lÃ½ tÃ i liá»‡u doanh nghiá»‡p vÃ  lÆ°u vÃ o ChromaDB collection riÃªng

    Args:
        request: ThÃ´ng tin tÃ i liá»‡u cáº§n xá»­ lÃ½

    Returns:
        Dict chá»©a káº¿t quáº£ xá»­ lÃ½
    """
    try:
        global chroma_client
        if chroma_client is None:
            raise HTTPException(status_code=500, detail="ChromaDB client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o")

        # Khá»Ÿi táº¡o document processor
        doc_processor = get_document_processor()

        # Extract text content tá»« file
        print(f"[Document Processing] Processing file: {request.file_path}")
        extracted_text, metadata = doc_processor.extract_text_from_file(
            request.file_path,
            request.file_type
        )

        if not metadata.get("extraction_success", False):
            raise HTTPException(
                status_code=400,
                detail=f"KhÃ´ng thá»ƒ xá»­ lÃ½ tÃ i liá»‡u: {metadata.get('error', 'Unknown error')}"
            )

        # Chuáº©n bá»‹ metadata cho ChromaDB
        doc_metadata = {
            "data_type": "document",
            "document_id": f"doc_{request.business_id}_{int(datetime.now().timestamp())}",
            "business_id": request.business_id,
            "business_username": request.business_username,
            "file_name": request.file_name,
            "file_type": request.file_type,
            "file_path": request.file_path,
            "description": request.description or "",
            "processed_at": datetime.now().isoformat(),
            "content_length": metadata.get("content_length", 0),
            "extraction_success": True
        }

        # ThÃªm metadata tá»« quÃ¡ trÃ¬nh processing náº¿u cÃ³
        if "sheets" in metadata:
            doc_metadata["excel_sheets"] = json.dumps(metadata["sheets"])
        if "columns" in metadata:
            doc_metadata["csv_columns"] = metadata["columns"]
        if "rows" in metadata:
            doc_metadata["data_rows"] = metadata["rows"]

        # Validate and sanitize metadata
        sanitized_metadata = sanitize_metadata(doc_metadata)

        # Táº¡o content Ä‘áº§y Ä‘á»§ vá»›i extracted text + metadata
        doc_content = f"""
DOCUMENT CONTENT:
{extracted_text}

---
METADATA:
Document ID: {doc_metadata["document_id"]}
Business: {request.business_username}
File Name: {request.file_name}
File Type: {request.file_type}
Description: {request.description or ""}
Processing Status: Success
Content Length: {len(extracted_text)} characters
Processed At: {doc_metadata["processed_at"]}
"""

        # LÆ°u vÃ o documents collection riÃªng biá»‡t
        analytics_rag_service = AnalyticsRAGService()
        result = analytics_rag_service.store_business_document(
            document_id=doc_metadata["document_id"],
            document_content=doc_content,
            metadata=sanitized_metadata
        )

        print(f"[Document Processing] Successfully processed and stored document: {doc_metadata['document_id']}")

        return {
            "success": True,
            "document_id": doc_metadata["document_id"],
            "content_length": len(extracted_text),
            "metadata": sanitized_metadata,
            "message": "TÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  lÆ°u thÃ nh cÃ´ng"
        }

    except Exception as e:
        print(f"[Document Processing] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Lá»—i xá»­ lÃ½ tÃ i liá»‡u: {str(e)}")


@router.post("/sync-from-spring")
async def sync_data_from_spring(request: SyncDataRequest):
    """
    Äá»“ng bá»™ dá»¯ liá»‡u tá»« Spring Service vÃ o ChromaDB
    
    Args:
        request: Chá»©a URL Spring Service, token xÃ¡c thá»±c vÃ  option xÃ³a dá»¯ liá»‡u cÅ©
        
    Returns:
        Dict chá»©a káº¿t quáº£ Ä‘á»“ng bá»™
    """
    try:
        global chroma_client
        if chroma_client is None:
            raise HTTPException(status_code=500, detail="ChromaDB client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o")
        
        # Láº¥y Spring Service URL tá»« biáº¿n mÃ´i trÆ°á»ng hoáº·c request
        spring_base_url = request.spring_service_url or os.getenv('SPRING_SERVICE_URL')
        if not spring_base_url:
            raise HTTPException(status_code=400, detail="SPRING_SERVICE_URL khÃ´ng Ä‘Æ°á»£c cáº¥u hÃ¬nh")
        
        # Láº¥y dá»¯ liá»‡u tá»« Spring Service
        headers = {
            "Authorization": f"Bearer {request.auth_token}",
            "Content-Type": "application/json"
        }
        
        spring_url = f"{spring_base_url}/admin/analytics/system-data"
        print(f"[Sync] Fetching data from: {spring_url}")
        
        response = requests.get(spring_url, headers=headers, timeout=30)
        
        if response.status_code != 200:
            raise HTTPException(
                status_code=response.status_code,
                detail=f"Failed to fetch data from Spring Service: {response.text}"
            )
        
        data = response.json()
        print(f"[Sync] Received data with {len(data.get('products', []))} products, {len(data.get('orders', []))} orders")
        
        sync_results = {
            "timestamp": datetime.now().isoformat(),
            "clear_existing": request.clear_existing,
            "products": {"total": 0, "with_details": 0, "success": 0, "errors": 0},
            "orders": {"total": 0, "success": 0, "errors": 0},
            "categories": {"total": 0, "success": 0, "errors": 0},
            "business_performance": {"total": 0, "success": 0, "errors": 0},
            "discounts": {"total": 0, "success": 0, "errors": 0},
            "users": {"total": 0, "success": 0, "errors": 0},
            "documents": {"total": 0, "success": 0, "errors": 0},
            "errors": []
        }
        
        # Khá»Ÿi táº¡o hoáº·c láº¥y cÃ¡c collections
        # Collection 1: business_data - chá»©a products, categories, business performance, discounts
        # Collection 2: orders_analytics - chá»©a orders
        # Collection 3: trends - chá»©a insights vÃ  trends (tÆ°Æ¡ng lai)
        # Collection 4: revenue_overview - chá»©a dá»¯ liá»‡u tá»•ng quan doanh thu vÃ  thá»‘ng kÃª há»‡ thá»‘ng
        # Collection 5: business_documents - chá»©a tÃ i liá»‡u doanh nghiá»‡p Ä‘Ã£ xá»­ lÃ½ cho RAG
        
        if request.clear_existing:
            print("[Sync] Clearing existing data...")
            try:
                # XÃ³a cÃ¡c collections cÅ©
                for collection_name in ["business_data", "orders_analytics", "trends", "revenue_overview", "business_documents"]:
                    try:
                        chroma_client.delete_collection(name=collection_name)
                        print(f"[Sync] Deleted old {collection_name} collection")
                    except:
                        pass
                
                # Táº¡o láº¡i cÃ¡c collections
                business_collection = chroma_client.create_collection(
                    name="business_data",
                    metadata={"description": "Products, categories, business performance, and discounts"}
                )
                orders_collection = chroma_client.create_collection(
                    name="orders_analytics",
                    metadata={"description": "Order data for analytics"}
                )
                trends_collection = chroma_client.create_collection(
                    name="trends",
                    metadata={"description": "Business trends and insights"}
                )
                revenue_collection = chroma_client.create_collection(
                    name="revenue_overview",
                    metadata={"description": "Revenue overview and system statistics"}
                )
                documents_collection = chroma_client.create_collection(
                    name="business_documents",
                    metadata={"description": "Business documents for RAG analysis"}
                )
                print("[Sync] Created new collections: business_data, orders_analytics, trends, revenue_overview, business_documents")
                
            except Exception as e:
                print(f"[Sync] Error clearing data: {e}")
                sync_results["errors"].append(f"Clear data error: {str(e)}")
                raise HTTPException(status_code=500, detail=f"Failed to clear collections: {str(e)}")
        else:
            # Láº¥y hoáº·c táº¡o collections náº¿u chÆ°a cÃ³
            print("[Sync] Getting or creating collections...")
            business_collection = chroma_client.get_or_create_collection(
                name="business_data",
                metadata={"description": "Products, categories, business performance, and discounts"}
            )
            orders_collection = chroma_client.get_or_create_collection(
                name="orders_analytics",
                metadata={"description": "Order data for analytics"}
            )
            trends_collection = chroma_client.get_or_create_collection(
                name="trends",
                metadata={"description": "Business trends and insights"}
            )
            revenue_collection = chroma_client.get_or_create_collection(
                name="revenue_overview",
                metadata={"description": "Revenue overview and system statistics"}
            )
            documents_collection = chroma_client.get_or_create_collection(
                name="business_documents",
                metadata={"description": "Business documents for RAG analysis"}
            )
            print("[Sync] Collections ready: business_data, orders_analytics, trends, revenue_overview, business_documents")
        
        # Äá»“ng bá»™ Products vá»›i details Ä‘áº§y Ä‘á»§
        if data.get('products'):
            sync_results["products"]["total"] = len(data['products'])
            print(f"[Sync] Syncing {len(data['products'])} products...")
            
            for product in data['products']:
                try:
                    product_id = str(product.get('id', ''))
                    has_details = bool(product.get('details'))
                    
                    if has_details:
                        sync_results["products"]["with_details"] += 1
                    
                    # Táº¡o product content vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin
                    product_content = f"""Product ID: {product.get('id')}
Name: {product.get('name', '')}
Description: {product.get('description', '')}
Price: {product.get('price', 0)} VND
Quantity: {product.get('quantity', 0)}
Status: {product.get('status', 'UNKNOWN')}
Category: {product.get('categoryName', '')}
Seller: {product.get('sellerUsername', '')}
"""
                    
                    # Parse details náº¿u cÃ³
                    details_text = ""
                    if product.get('details'):
                        try:
                            import json
                            details = json.loads(product['details']) if isinstance(product['details'], str) else product['details']
                            
                            if details:
                                details_text = "\nProduct Details:\n"
                                
                                # Basic details
                                if details.get('brand'):
                                    details_text += f"Brand: {details['brand']}\n"
                                if details.get('model'):
                                    details_text += f"Model: {details['model']}\n"
                                if details.get('color'):
                                    details_text += f"Color: {details['color']}\n"
                                if details.get('warranty'):
                                    details_text += f"Warranty: {details['warranty']}\n"
                                if details.get('storage'):
                                    details_text += f"Storage: {details['storage']}\n"
                                if details.get('type'):
                                    details_text += f"Type: {details['type']}\n"
                                
                                # Features
                                if details.get('features') and isinstance(details['features'], list):
                                    details_text += f"Features: {', '.join(details['features'])}\n"
                                
                                # Specifications
                                if details.get('specifications') and isinstance(details['specifications'], dict):
                                    details_text += "Specifications:\n"
                                    for key, value in details['specifications'].items():
                                        details_text += f"  {key}: {value}\n"
                                
                                # Connectivity
                                if details.get('connectivity') and isinstance(details['connectivity'], list):
                                    details_text += f"Connectivity: {', '.join(details['connectivity'])}\n"
                                
                                # Accessories
                                if details.get('accessories') and isinstance(details['accessories'], list):
                                    details_text += f"Accessories: {', '.join(details['accessories'])}\n"
                                
                                # Dimensions and Weight
                                if details.get('dimensions'):
                                    details_text += f"Dimensions: {details['dimensions']}\n"
                                if details.get('weight'):
                                    details_text += f"Weight: {details['weight']}\n"
                                
                                product_content += details_text
                                
                        except json.JSONDecodeError:
                            print(f"[Sync] Invalid JSON in product details for {product_id}")
                        except Exception as e:
                            print(f"[Sync] Error parsing product details for {product_id}: {e}")
                    
                    # Safe conversion cho metadata
                    price = product.get('price')
                    price_float = float(price) if price is not None else 0.0
                    
                    quantity = product.get('quantity')
                    quantity_int = int(quantity) if quantity is not None else 0
                    
                    total_sold = product.get('totalSold')
                    total_sold_int = int(total_sold) if total_sold is not None else 0
                    
                    total_revenue = product.get('totalRevenue')
                    total_revenue_float = float(total_revenue) if total_revenue is not None else 0.0
                    
                    # Prepare metadata vá»›i Äáº¦Y Äá»¦ táº¥t cáº£ cÃ¡c trÆ°á»ng tá»« DTO
                    product_metadata = {
                        "data_type": "product",
                        "product_id": product_id,
                        "name": product.get('name', ''),
                        "description": product.get('description', ''),
                        "category": product.get('categoryName', ''),
                        "category_id": str(product.get('categoryId', '')) if product.get('categoryId') else '',
                        "status": product.get('status', 'UNKNOWN'),
                        "price": price_float,
                        "quantity": quantity_int,
                        "seller": product.get('sellerUsername', ''),
                        "seller_id": str(product.get('sellerId', '')),
                        "total_sold": total_sold_int,
                        "total_revenue": total_revenue_float,
                        "image_urls": json.dumps(product.get('imageUrls', [])) if product.get('imageUrls') else '',
                        "created_at": product.get('createdAt', ''),
                        "updated_at": product.get('updatedAt', ''),
                        "has_details": has_details,
                        "stored_at": datetime.now().isoformat(),
                        "purpose": "analytics"
                    }
                    
                    # Add parsed details to metadata if available
                    if product.get('details'):
                        try:
                            import json
                            details = json.loads(product['details']) if isinstance(product['details'], str) else product['details']
                            if details:
                                # Store key details in metadata for easy filtering
                                if details.get('brand'):
                                    product_metadata['brand'] = details['brand']
                                if details.get('model'):
                                    product_metadata['model'] = details['model']
                                if details.get('color'):
                                    product_metadata['color'] = details['color']
                                if details.get('warranty'):
                                    product_metadata['warranty'] = details['warranty']
                                # Store full details as JSON string
                                product_metadata['details_json'] = json.dumps(details, ensure_ascii=False)
                        except:
                            pass
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_metadata = sanitize_metadata(product_metadata)
                    
                    # LÆ°u vÃ o collection
                    business_collection.upsert(
                        documents=[product_content],
                        metadatas=[sanitized_metadata],
                        ids=[f"product_{product_id}"]
                    )
                    
                    sync_results["products"]["success"] += 1
                    print(f"[Sync] Stored product {product_id} with details: {has_details}")
                    
                except Exception as e:
                    sync_results["products"]["errors"] += 1
                    error_msg = f"Product {product.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
                    print(f"[Sync] Error: {error_msg}")
                    import traceback
                    traceback.print_exc()
        
        # Äá»“ng bá»™ Orders
        if data.get('orders'):
            sync_results["orders"]["total"] = len(data['orders'])
            print(f"[Sync] Syncing {len(data['orders'])} orders...")
            
            for order in data['orders']:
                try:
                    order_id = str(order.get('id', ''))
                    
                    # Táº¡o ná»™i dung order
                    order_content = f"""
Order ID: {order.get('id')}
Customer: {order.get('customerName', '')}
Status: {order.get('status', '')}
Total Amount: {order.get('totalAmount', 0)} VND
Items Count: {order.get('totalItems', 0)}
Created: {order.get('createdAt', '')}
"""
                    
                    # Safe conversion vá»›i xá»­ lÃ½ null/None
                    total_amount = order.get('totalAmount')
                    total_amount_float = float(total_amount) if total_amount is not None else 0.0
                    
                    total_items = order.get('totalItems')
                    total_items_int = int(total_items) if total_items is not None else 0
                    
                    # LÆ°u order items náº¿u cÃ³
                    order_items = order.get('items', [])
                    items_detail = []
                    for item in order_items:
                        items_detail.append({
                            "product_id": str(item.get('productId', '')),
                            "product_name": item.get('productName', ''),
                            "quantity": int(item.get('quantity', 0)) if item.get('quantity') is not None else 0,
                            "price": float(item.get('price', 0)) if item.get('price') is not None else 0.0,
                            "subtotal": float(item.get('subtotal', 0)) if item.get('subtotal') is not None else 0.0
                        })
                    
                    order_metadata = {
                        "data_type": "order",
                        "order_id": order_id,
                        "customer_name": order.get('customerName', ''),
                        "customer_id": str(order.get('customerId', '')),
                        "status": order.get('status', ''),
                        "total_amount": total_amount_float,
                        "total_items": total_items_int,
                        "created_at": order.get('createdAt', ''),
                        "updated_at": order.get('updatedAt', ''),
                        "payment_method": order.get('paymentMethod', ''),
                        "shipping_address": order.get('shippingAddress', ''),
                        "items_json": json.dumps(items_detail, ensure_ascii=False),  # Store items as JSON string
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_order_metadata = sanitize_metadata(order_metadata)
                    
                    # LÆ°u vÃ o orders_analytics collection
                    orders_collection.upsert(
                        documents=[order_content],
                        metadatas=[sanitized_order_metadata],
                        ids=[f"order_{order_id}"]
                    )
                    
                    sync_results["orders"]["success"] += 1
                    
                except Exception as e:
                    sync_results["orders"]["errors"] += 1
                    error_msg = f"Order {order.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
                    print(f"[Sync] Error: {error_msg}")
        
        # Äá»“ng bá»™ Categories
        if data.get('categories'):
            sync_results["categories"]["total"] = len(data['categories'])
            print(f"[Sync] Syncing {len(data['categories'])} categories...")
            
            for category in data['categories']:
                try:
                    category_id = str(category.get('id', ''))
                    
                    category_content = f"""
Category ID: {category.get('id')}
Name: {category.get('name', '')}
Description: {category.get('description', '')}
Status: {category.get('status', '')}
Product Count: {category.get('productCount', 0)}
"""
                    
                    # Safe conversion
                    product_count = category.get('productCount')
                    product_count_int = int(product_count) if product_count is not None else 0
                    
                    category_metadata = {
                        "data_type": "category",
                        "category_id": category_id,
                        "name": category.get('name', ''),
                        "description": category.get('description', ''),
                        "status": category.get('status', ''),
                        "product_count": product_count_int,
                        "created_at": category.get('createdAt', ''),
                        "updated_at": category.get('updatedAt', ''),
                        "image_url": category.get('imageUrl', ''),
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_category_metadata = sanitize_metadata(category_metadata)
                    
                    # Use business_collection directly
                    business_collection.upsert(
                        documents=[category_content],
                        metadatas=[sanitized_category_metadata],
                        ids=[f"category_{category_id}"]
                    )
                    
                    sync_results["categories"]["success"] += 1
                    
                except Exception as e:
                    sync_results["categories"]["errors"] += 1
                    error_msg = f"Category {category.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # Äá»“ng bá»™ Business Performance
        if data.get('businessPerformance'):
            sync_results["business_performance"]["total"] = len(data['businessPerformance'])
            print(f"[Sync] Syncing {len(data['businessPerformance'])} business performance records...")
            
            for business in data['businessPerformance']:
                try:
                    business_id = str(business.get('businessId', ''))
                    
                    business_content = f"""
Business ID: {business.get('businessId')}
Username: {business.get('businessUsername', '')}
Total Products: {business.get('totalProducts', 0)}
Active Products: {business.get('activeProducts', 0)}
Total Orders: {business.get('totalOrders', 0)}
Revenue: {business.get('revenue', 0)} VND
Average Order Value: {business.get('averageOrderValue', 0)} VND
"""
                    
                    # Safe conversion cho business data
                    total_products = business.get('totalProducts')
                    total_products_int = int(total_products) if total_products is not None else 0
                    
                    active_products = business.get('activeProducts')
                    active_products_int = int(active_products) if active_products is not None else 0
                    
                    total_orders = business.get('totalOrders')
                    total_orders_int = int(total_orders) if total_orders is not None else 0
                    
                    revenue = business.get('revenue')
                    revenue_float = float(revenue) if revenue is not None else 0.0
                    
                    inventory_value = business.get('inventoryValue')
                    inventory_value_float = float(inventory_value) if inventory_value is not None else 0.0
                    
                    avg_order = business.get('averageOrderValue')
                    avg_order_float = float(avg_order) if avg_order is not None else 0.0
                    
                    business_metadata = {
                        "data_type": "business_performance",
                        "business_id": business_id,
                        "username": business.get('businessUsername', ''),
                        "total_products": total_products_int,
                        "active_products": active_products_int,
                        "inactive_products": safe_int(business.get('inactiveProducts')),
                        "total_orders": total_orders_int,
                        "completed_orders": safe_int(business.get('completedOrders')),
                        "revenue": revenue_float,
                        "inventory_value": inventory_value_float,
                        "average_order_value": avg_order_float,
                        "total_sold": safe_int(business.get('totalSold')),
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_business_metadata = sanitize_metadata(business_metadata)
                    
                    # Use business_collection directly
                    business_collection.upsert(
                        documents=[business_content],
                        metadatas=[sanitized_business_metadata],
                        ids=[f"business_{business_id}"]
                    )
                    
                    sync_results["business_performance"]["success"] += 1
                    
                except Exception as e:
                    sync_results["business_performance"]["errors"] += 1
                    error_msg = f"Business {business.get('businessId', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # Äá»“ng bá»™ Discounts
        if data.get('discounts'):
            sync_results["discounts"]["total"] = len(data['discounts'])
            print(f"[Sync] Syncing {len(data['discounts'])} discounts...")
            
            for discount in data['discounts']:
                try:
                    discount_id = str(discount.get('id', ''))
                    
                    discount_content = f"""
Discount ID: {discount.get('id')}
Code: {discount.get('code', '')}
Type: {discount.get('discountType', '')}
Value: {discount.get('discountValue', 0)}
Status: {discount.get('status', '')}
Usage Count: {discount.get('usageCount', 0)}
"""
                    
                    # Safe conversion cho discount data
                    discount_value = discount.get('discountValue')
                    discount_value_float = float(discount_value) if discount_value is not None else 0.0
                    
                    min_order = discount.get('minOrderValue')
                    min_order_float = float(min_order) if min_order is not None else 0.0
                    
                    max_discount = discount.get('maxDiscountAmount')
                    max_discount_float = float(max_discount) if max_discount is not None else 0.0
                    
                    usage_limit = discount.get('usageLimit')
                    usage_limit_int = int(usage_limit) if usage_limit is not None else 0
                    
                    used_count = discount.get('usedCount')
                    used_count_int = int(used_count) if used_count is not None else 0
                    
                    # Parse additional fields
                    total_savings = discount.get('totalSavings')
                    total_savings_float = float(total_savings) if total_savings is not None else 0.0
                    
                    usage_percentage = discount.get('usagePercentage')
                    usage_percentage_float = float(usage_percentage) if usage_percentage is not None else 0.0
                    
                    discount_metadata = {
                        "data_type": "discount",
                        "discount_id": discount_id,
                        "code": discount.get('code', ''),
                        "name": discount.get('name', ''),
                        "description": discount.get('description', ''),
                        "type": discount.get('discountType', ''),
                        "value": discount_value_float,
                        "min_order_value": min_order_float,
                        "max_discount_amount": max_discount_float,
                        "usage_limit": usage_limit_int,
                        "used_count": used_count_int,
                        "status": discount.get('status', ''),
                        "start_date": discount.get('startDate', ''),
                        "end_date": discount.get('endDate', ''),
                        "created_at": discount.get('createdAt', ''),
                        "created_by_username": discount.get('createdByUsername', ''),
                        "created_by_id": str(discount.get('createdById', '')) if discount.get('createdById') else '',
                        "is_valid": discount.get('isValid', False),
                        "is_expired": discount.get('isExpired', False),
                        "usage_limit_reached": discount.get('usageLimitReached', False),
                        "usage_percentage": usage_percentage_float,
                        "total_savings": total_savings_float,
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_discount_metadata = sanitize_metadata(discount_metadata)
                    
                    # Use business_collection directly
                    business_collection.upsert(
                        documents=[discount_content],
                        metadatas=[sanitized_discount_metadata],
                        ids=[f"discount_{discount_id}"]
                    )
                    
                    sync_results["discounts"]["success"] += 1
                    
                except Exception as e:
                    sync_results["discounts"]["errors"] += 1
                    error_msg = f"Discount {discount.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # Äá»“ng bá»™ Users (náº¿u cÃ³)
        if data.get('users'):
            sync_results["users"] = {"total": len(data['users']), "success": 0, "errors": 0}
            print(f"[Sync] Syncing {len(data['users'])} users...")
            
            for user in data['users']:
                try:
                    user_id = str(user.get('id', ''))
                    
                    user_content = f"""
User ID: {user.get('id')}
Username: {user.get('username', '')}
Email: {user.get('email', '')}
Role: {user.get('role', '')}
Status: {user.get('accountStatus', '')}
Phone: {user.get('phoneNumber', '')}
Address: {user.get('address', '')}
"""
                    
                    user_metadata = {
                        "data_type": "user",
                        "user_id": user_id,
                        "username": user.get('username', ''),
                        "email": user.get('email', ''),
                        "role": user.get('role', ''),
                        "account_status": user.get('accountStatus', ''),
                        "phone_number": user.get('phoneNumber', ''),
                        "address": user.get('address', ''),
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_user_metadata = sanitize_metadata(user_metadata)
                    
                    business_collection.upsert(
                        documents=[user_content],
                        metadatas=[sanitized_user_metadata],
                        ids=[f"user_{user_id}"]
                    )
                    
                    sync_results["users"]["success"] += 1
                    
                except Exception as e:
                    sync_results["users"]["errors"] += 1
                    error_msg = f"User {user.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # Äá»“ng bá»™ Business Documents (náº¿u cÃ³) - LÆ¯U VÃ€O COLLECTION RIÃŠNG BIá»†T
        if data.get('businessDocuments'):
            sync_results["documents"] = {"total": len(data['businessDocuments']), "success": 0, "errors": 0}
            print(f"[Sync] Syncing {len(data['businessDocuments'])} business documents...")
            
            # Táº¡o collection riÃªng cho documents náº¿u chÆ°a cÃ³
            try:
                documents_collection = chroma_client.get_or_create_collection(
                    name="business_documents",
                    metadata={"description": "Business documents for RAG analysis"}
                )
                print("[Sync] Documents collection ready")
            except Exception as e:
                print(f"[Sync] Error creating documents collection: {e}")
                sync_results["errors"].append(f"Documents collection error: {str(e)}")
                documents_collection = None
            
            for doc in data['businessDocuments']:
                try:
                    doc_id = str(doc.get('id', ''))
                    file_path = doc.get('filePath', '')
                    file_type = doc.get('fileType', '')
                    
                    # Resolve Ä‘Æ°á»ng dáº«n file tá»« Spring Service
                    resolved_file_path = resolve_spring_file_path(file_path)
                    print(f"[Sync] Original path: {file_path} -> Resolved path: {resolved_file_path}")
                    
                    # Khá»Ÿi táº¡o document processor
                    doc_processor = get_document_processor()
                    
                    # Extract text content tá»« file
                    extracted_text = ""
                    processing_metadata = {}
                    
                    if resolved_file_path and os.path.exists(resolved_file_path):
                        try:
                            extracted_text, processing_metadata = doc_processor.extract_text_from_file(
                                resolved_file_path, file_type
                            )
                            print(f"[Sync] Successfully extracted {len(extracted_text)} characters from {doc.get('fileName', '')}")
                        except Exception as extract_error:
                            print(f"[Sync] Error extracting text from {resolved_file_path}: {extract_error}")
                            # Fallback: táº¡o content tá»« metadata
                            extracted_text = f"Error extracting content from file: {str(extract_error)}"
                    else:
                        print(f"[Sync] File not found: {resolved_file_path} (original: {file_path})")
                        extracted_text = "File not found during sync process"
                    
                    # Táº¡o document content vá»›i text Ä‘Ã£ extract + metadata
                    file_size = doc.get('fileSize')
                    file_size_int = int(file_size) if file_size is not None else 0
                    
                    # Káº¿t há»£p extracted text vá»›i metadata Ä‘á»ƒ táº¡o content Ä‘áº§y Ä‘á»§
                    doc_content = f"""
DOCUMENT CONTENT:
{extracted_text}

---
METADATA:
Document ID: {doc.get('id')}
Business: {doc.get('businessUsername', '')}
File Name: {doc.get('fileName', '')}
File Type: {doc.get('fileType', '')}
Description: {doc.get('description', '')}
Size: {file_size_int} bytes
Uploaded: {doc.get('uploadedAt', '')}
Processing Status: {'Success' if processing_metadata.get('extraction_success') else 'Failed'}
Content Length: {len(extracted_text)} characters
"""
                    
                    doc_metadata = {
                        "data_type": "document",
                        "document_id": doc_id,
                        "business_id": str(doc.get('businessId', '')) if doc.get('businessId') else '',
                        "business_username": doc.get('businessUsername', ''),
                        "file_name": doc.get('fileName', ''),
                        "file_type": doc.get('fileType', ''),
                        "file_path_original": doc.get('filePath', ''),  # ÄÆ°á»ng dáº«n gá»‘c tá»« Spring
                        "file_path_resolved": resolved_file_path or '',  # ÄÆ°á»ng dáº«n Ä‘Ã£ resolve
                        "file_size": file_size_int,
                        "description": doc.get('description', ''),
                        "uploaded_at": doc.get('uploadedAt', ''),
                        "stored_at": datetime.now().isoformat(),
                        "extraction_success": processing_metadata.get('extraction_success', False),
                        "content_length": len(extracted_text),
                        "processing_timestamp": processing_metadata.get('processing_timestamp', datetime.now().isoformat())
                    }
                    
                    # ThÃªm metadata tá»« quÃ¡ trÃ¬nh processing náº¿u cÃ³
                    if "sheets" in processing_metadata:
                        doc_metadata["excel_sheets"] = json.dumps(processing_metadata["sheets"])
                    if "columns" in processing_metadata:
                        doc_metadata["csv_columns"] = processing_metadata["columns"]
                    if "rows" in processing_metadata:
                        doc_metadata["data_rows"] = processing_metadata["rows"]
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_doc_metadata = sanitize_metadata(doc_metadata)
                    
                    # LÆ°u vÃ o collection riÃªng biá»‡t cho documents
                    if documents_collection:
                        documents_collection.upsert(
                            documents=[doc_content],
                            metadatas=[sanitized_doc_metadata],
                            ids=[f"document_{doc_id}"]
                        )
                        print(f"[Sync] Stored document {doc_id} in separate collection")
                    else:
                        # Fallback: lÆ°u vÃ o business_collection náº¿u khÃ´ng táº¡o Ä‘Æ°á»£c collection riÃªng
                        business_collection.upsert(
                            documents=[doc_content],
                            metadatas=[sanitized_doc_metadata],
                            ids=[f"document_{doc_id}"]
                        )
                        print(f"[Sync] Fallback: Stored document {doc_id} in business collection")
                    
                    sync_results["documents"]["success"] += 1
                    
                except Exception as e:
                    sync_results["documents"]["errors"] += 1
                    error_msg = f"Document {doc.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # ThÃªm revenue overview tá»« data gá»‘c
        sync_results["revenue_overview"] = {
            "total_revenue": safe_decimal(data.get('totalRevenue')),
            "monthly_revenue": safe_decimal(data.get('monthlyRevenue')),
            "weekly_revenue": safe_decimal(data.get('weeklyRevenue')),
            "daily_revenue": safe_decimal(data.get('dailyRevenue')),
        }
        
        # LÆ°u revenue overview vÃ o ChromaDB Ä‘á»ƒ AI cÃ³ thá»ƒ truy váº¥n
        try:
            revenue_content = f"""
Revenue Overview - System Statistics
Total Revenue: {sync_results["revenue_overview"]["total_revenue"]} VND
Monthly Revenue: {sync_results["revenue_overview"]["monthly_revenue"]} VND
Weekly Revenue: {sync_results["revenue_overview"]["weekly_revenue"]} VND
Daily Revenue: {sync_results["revenue_overview"]["daily_revenue"]} VND
Last Updated: {datetime.now().isoformat()}
"""
            
            revenue_metadata = {
                "data_type": "revenue_overview",
                "total_revenue": sync_results["revenue_overview"]["total_revenue"],
                "monthly_revenue": sync_results["revenue_overview"]["monthly_revenue"],
                "weekly_revenue": sync_results["revenue_overview"]["weekly_revenue"],
                "daily_revenue": sync_results["revenue_overview"]["daily_revenue"],
                "stored_at": datetime.now().isoformat(),
                "purpose": "analytics"
            }
            
            # Validate and sanitize metadata
            sanitized_revenue_metadata = sanitize_metadata(revenue_metadata)
            
            revenue_collection.upsert(
                documents=[revenue_content],
                metadatas=[sanitized_revenue_metadata],
                ids=["revenue_overview_system"]
            )
            
            print("[Sync] Stored revenue overview in ChromaDB")
            
        except Exception as e:
            print(f"[Sync] Error storing revenue overview: {str(e)}")
            sync_results["errors"].append(f"Revenue overview storage error: {str(e)}")
        
        # ThÃªm top selling products tá»« data gá»‘c
        if data.get('topSellingProducts'):
            sync_results["top_selling_products"] = [
                {
                    "product_id": str(p.get('productId', '')),
                    "product_name": p.get('productName', ''),
                    "total_sold": safe_int(p.get('totalSold')),
                    "revenue": safe_decimal(p.get('revenue'))
                }
                for p in data.get('topSellingProducts', [])[:10]
            ]
        
        # ThÃªm low stock products tá»« data gá»‘c
        if data.get('lowStockProducts'):
            sync_results["low_stock_products"] = [
                {
                    "product_id": str(p.get('productId', '')),
                    "product_name": p.get('productName', ''),
                    "quantity": safe_int(p.get('quantity')),
                    "category": p.get('categoryName', '')
                }
                for p in data.get('lowStockProducts', [])
            ]
        
        # Táº¡o summary
        total_success = (
            sync_results["products"]["success"] +
            sync_results["orders"]["success"] +
            sync_results["categories"]["success"] +
            sync_results["business_performance"]["success"] +
            sync_results["discounts"]["success"] +
            sync_results.get("users", {}).get("success", 0) +
            sync_results.get("documents", {}).get("success", 0)
        )
        
        total_errors = (
            sync_results["products"]["errors"] +
            sync_results["orders"]["errors"] +
            sync_results["categories"]["errors"] +
            sync_results["business_performance"]["errors"] +
            sync_results["discounts"]["errors"] +
            sync_results.get("users", {}).get("errors", 0) +
            sync_results.get("documents", {}).get("errors", 0)
        )
        
        sync_results["summary"] = {
            "total_success": total_success,
            "total_errors": total_errors,
            "success_rate": f"{(total_success / (total_success + total_errors) * 100):.2f}%" if (total_success + total_errors) > 0 else "0%",
            "total_users": safe_int(data.get('totalUsers')),
            "total_customers": safe_int(data.get('totalCustomers')),
            "total_business_users": safe_int(data.get('totalBusinessUsers')),
            "total_products": safe_int(data.get('totalProducts')),
            "active_products": safe_int(data.get('activeProducts')),
            "total_orders": safe_int(data.get('totalOrders')),
            "delivered_orders": safe_int(data.get('deliveredOrders')),
            "pending_orders": safe_int(data.get('pendingOrders'))
        }
        
        print(f"[Sync] Completed: {total_success} success, {total_errors} errors")
        
        return sync_results
        
    except requests.RequestException as e:
        raise HTTPException(status_code=500, detail=f"Error connecting to Spring Service: {str(e)}")
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Sync error: {str(e)}")


@router.post("/clear-chroma")
async def clear_chroma_data():
    """
    Clear all data from ChromaDB collections
    """
    try:
        print("[ClearChroma] Starting ChromaDB data clearing process...")

        # Get ChromaDB client
        global chroma_client
        if chroma_client is None:
            raise HTTPException(status_code=500, detail="ChromaDB client not initialized")

        # Get all collections
        collections = chroma_client.list_collections()
        print(f"[ClearChroma] Found {len(collections)} collections to clear")

        cleared_collections = []
        errors = []

        for collection in collections:
            try:
                collection_name = collection.name
                print(f"[ClearChroma] Clearing collection: {collection_name}")

                # Delete the entire collection
                chroma_client.delete_collection(name=collection_name)

                cleared_collections.append(collection_name)
                print(f"[ClearChroma] Successfully cleared collection: {collection_name}")

            except Exception as e:
                error_msg = f"Error clearing collection {collection.name}: {str(e)}"
                print(f"[ClearChroma] {error_msg}")
                errors.append(error_msg)

        result = {
            "success": True,
            "cleared_collections": cleared_collections,
            "errors": errors,
            "total_cleared": len(cleared_collections),
            "total_errors": len(errors)
        }

        print(f"[ClearChroma] Clearing completed. Cleared: {len(cleared_collections)}, Errors: {len(errors)}")

        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Failed to clear ChromaDB data: {str(e)}")


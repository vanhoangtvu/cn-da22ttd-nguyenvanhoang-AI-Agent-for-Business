"""
Business Analytics API Route
Endpoint Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u kinh doanh vÃ  Ä‘á» xuáº¥t chiáº¿n lÆ°á»£c báº±ng AI
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import google.generativeai as genai
import os
from datetime import datetime, timedelta
import json
from typing import Optional, Dict, Any, List
import chromadb
from groq import Groq
import requests

# Import services
from services.document_processing_service import get_document_processor
from services.analytics_rag_service import AnalyticsRAGService

router = APIRouter()

# Global analytics RAG service instance
analytics_rag_service = None

def set_analytics_rag_service(service: AnalyticsRAGService):
    """Set the global analytics RAG service instance"""
    global analytics_rag_service
    analytics_rag_service = service

# Helper functions for safe type conversion
def safe_decimal(value):
    """Safely convert value to float"""
    if value is None:
        return 0.0
    try:
        return float(value)
    except (ValueError, TypeError):
        return 0.0

def safe_int(value):
    """Safely convert value to int"""
    if value is None:
        return 0
    try:
        return int(value)
    except (ValueError, TypeError):
        return 0

def safe_str(value):
    """Safely convert value to string"""
    if value is None:
        return ""
    return str(value)

def sanitize_metadata(metadata_dict):
    """Sanitize metadata dictionary for ChromaDB compatibility"""
    sanitized = {}
    for key, value in metadata_dict.items():
        if isinstance(value, (str, int, float, bool)):
            # Ensure strings are not too long and don't contain null bytes
            if isinstance(value, str):
                value = value.replace('\x00', '').replace('\r', '').replace('\n', ' ')
                if len(value) > 10000:  # Limit string length
                    value = value[:10000] + '...'
            sanitized[key] = value
        else:
            # Convert other types to string
            sanitized[key] = str(value)
    return sanitized

# Configure Gemini API
GEMINI_API_KEY = os.getenv('GOOGLE_API_KEY')
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Configure Groq API
GROQ_API_KEY = os.getenv('GROQ_API_KEY')
groq_client = None
if GROQ_API_KEY:
    groq_client = Groq(api_key=GROQ_API_KEY)

# Cache for models
_cached_models = None
_models_cache_time = None

def resolve_spring_file_path(relative_path):
    """
    Resolve Ä‘Æ°á»ng dáº«n file tÆ°Æ¡ng Ä‘á»‘i tá»« Spring Service thÃ nh Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i
    
    Args:
        relative_path: ÄÆ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i tá»« Spring Service (vd: 'uploads/documents/file.xlsx')
        
    Returns:
        ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i hoáº·c None náº¿u khÃ´ng tÃ¬m tháº¥y
    """
    if not relative_path:
        return None
    
    # Náº¿u Ä‘Ã£ lÃ  Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i, tráº£ vá» luÃ´n
    if os.path.isabs(relative_path):
        return relative_path if os.path.exists(relative_path) else None
    
    # CÃ¡c Ä‘Æ°á»ng dáº«n cÃ³ thá»ƒ cÃ³ cá»§a Spring Service uploads
    possible_base_paths = [
        # ÄÆ°á»ng dáº«n tá»« thÆ° má»¥c Python service Ä‘áº¿n Spring service
        os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'SpringService', relative_path),
        # ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i dá»±a trÃªn cáº¥u trÃºc project
        os.path.join('/home/hv/DuAn/CSN/AI-Agent-for-Business/backend/SpringService', relative_path),
        # ÄÆ°á»ng dáº«n tá»« environment variable náº¿u cÃ³
        os.path.join(os.getenv('SPRING_UPLOAD_PATH', ''), relative_path) if os.getenv('SPRING_UPLOAD_PATH') else None,
    ]
    
    # Thá»­ tá»«ng Ä‘Æ°á»ng dáº«n cÃ³ thá»ƒ
    for base_path in possible_base_paths:
        if base_path and os.path.exists(base_path):
            print(f"[File Resolver] Found file at: {base_path}")
            return base_path
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y á»Ÿ cÃ¡c vá»‹ trÃ­ chuáº©n, thá»­ tÃ¬m trong thÆ° má»¥c hiá»‡n táº¡i
    current_dir = os.getcwd()
    fallback_path = os.path.join(current_dir, relative_path)
    if os.path.exists(fallback_path):
        print(f"[File Resolver] Found file at fallback location: {fallback_path}")
        return fallback_path
    
    print(f"[File Resolver] File not found at any location for: {relative_path}")
    return None

def get_available_models_from_apis():
    """Fetch available models from Gemini and Groq APIs"""
    global _cached_models, _models_cache_time
    import time
    
    # Cache for 1 hour
    if _cached_models and _models_cache_time and (time.time() - _models_cache_time) < 3600:
        return _cached_models
    
    models = []
    
    # Get Gemini models - chá»‰ giá»¯ Pro vÃ  Flash 2.5
    if GEMINI_API_KEY:
        try:
            gemini_models = genai.list_models()
            allowed_gemini = ['gemini-2.5-pro', 'gemini-2.5-flash']
            
            for m in gemini_models:
                if 'generateContent' in m.supported_generation_methods:
                    model_id = m.name.replace('models/', '')
                    
                    # Chá»‰ giá»¯ Pro vÃ  Flash 2.5
                    if model_id in allowed_gemini:
                        models.append({
                            'id': model_id,
                            'name': m.display_name,
                            'provider': 'Google',
                            'context_window': getattr(m, 'input_token_limit', 32768)
                        })
                        print(f"[Analytics] Added Gemini model: {model_id}")
            
            print(f"[Analytics] Loaded {len([m for m in models if m['provider'] == 'Google'])} Gemini models")
        except Exception as e:
            print(f"[Analytics] Error loading Gemini models: {e}")
    
    # Get Groq models
    if groq_client:
        try:
            models_response = groq_client.models.list()
            
            # List of keywords to exclude (non-chat models)
            excluded_keywords = ['whisper', 'distil-whisper', 'guard']
            
            groq_models = []
            for model in models_response.data:
                if hasattr(model, 'id') and model.id:
                    model_id_lower = model.id.lower()
                    
                    # Skip non-chat models
                    if any(keyword in model_id_lower for keyword in excluded_keywords):
                        print(f"[Analytics] Skipping excluded model: {model.id}")
                        continue
                    
                    # Only include active models
                    if not getattr(model, 'active', True):
                        print(f"[Analytics] Skipping inactive model: {model.id}")
                        continue
                    
                    context_window = getattr(model, 'context_window', 8192)
                    
                    groq_models.append({
                        'id': model.id,
                        'name': model.id,
                        'provider': 'Groq',
                        'context_window': context_window
                    })
                    print(f"[Analytics] Added Groq model: {model.id} (context: {context_window})")
            
            # Sort by name
            groq_models.sort(key=lambda x: x['name'])
            models.extend(groq_models)
            
            print(f"[Analytics] Loaded {len(groq_models)} Groq models")
        except Exception as e:
            print(f"[Analytics] Error loading Groq models: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("[Analytics] Groq client not initialized - check GROQ_API_KEY")
    
    # Sort by provider and name
    models.sort(key=lambda x: (x['provider'], x['name']))
    
    _cached_models = models
    _models_cache_time = time.time()
    
    return models

@router.get('/models')
async def get_available_models():
    """Láº¥y danh sÃ¡ch models AI cÃ³ sáºµn cho phÃ¢n tÃ­ch tá»« API"""
    models = get_available_models_from_apis()
    return {'success': True, 'models': models}

# ChromaDB client
chroma_client = None

def set_chroma_client(client):
    """Set ChromaDB client"""
    global chroma_client
    chroma_client = client

class AIInsightsRequest(BaseModel):
    type: Optional[str] = 'general'  # general, pricing, inventory, sales
    model: Optional[str] = 'llama-3.3-70b-versatile'  # AI model to use - default to Groq Llama 3.3 70B

def get_business_data():
    """Láº¥y dá»¯ liá»‡u kinh doanh tá»« ChromaDB"""
    try:
        if not chroma_client:
            return {'products': [], 'orders': [], 'categories': [], 'discounts': [], 'business_performance': [], 'users': [], 'documents': []}
        
        # Láº¥y collections tá»« ChromaDB
        # business_data: products, categories, business_performance, discounts
        # orders_analytics: orders
        try:
            business_collection = chroma_client.get_collection(name="business_data")
            orders_collection = chroma_client.get_collection(name="orders_analytics")
            revenue_collection = chroma_client.get_collection(name="revenue_overview")
        except Exception as e:
            print(f"Error getting collections: {e}")
            return {'products': [], 'orders': [], 'categories': [], 'discounts': [], 'business_performance': [], 'users': [], 'documents': [], 'revenue_overview': []}
        
        # Láº¥y táº¥t cáº£ dá»¯ liá»‡u tá»« collections
        business_data = business_collection.get(include=['metadatas'])
        orders_data = orders_collection.get(include=['metadatas'])
        revenue_data = revenue_collection.get(include=['metadatas'])
        
        # Parse metadata tá»« business_collection theo data_type
        all_business_metadatas = business_data.get('metadatas', [])
        
        products = [m for m in all_business_metadatas if m.get('data_type') == 'product']
        categories = [m for m in all_business_metadatas if m.get('data_type') == 'category']
        discounts = [m for m in all_business_metadatas if m.get('data_type') == 'discount']
        business_performance = [m for m in all_business_metadatas if m.get('data_type') == 'business_performance']
        users = [m for m in all_business_metadatas if m.get('data_type') == 'user']
        documents = [m for m in all_business_metadatas if m.get('data_type') == 'document']
        
        # Parse orders tá»« orders_analytics collection  
        orders = orders_data.get('metadatas', [])
        
        # Parse revenue overview tá»« revenue_overview collection
        revenue_overview = revenue_data.get('metadatas', [])
        
        # Convert string fields back to proper types
        for product in products:
            if 'price' in product and isinstance(product['price'], str):
                try:
                    product['price'] = float(product['price'])
                except:
                    product['price'] = 0
            if 'quantity' in product and isinstance(product['quantity'], str):
                try:
                    product['quantity'] = int(product['quantity'])
                except:
                    product['quantity'] = 0
            if 'id' in product and isinstance(product['id'], str):
                try:
                    product['id'] = int(product['id'])
                except:
                    pass
        
        for order in orders:
            if 'totalAmount' in order and isinstance(order['totalAmount'], str):
                try:
                    order['totalAmount'] = float(order['totalAmount'])
                except:
                    order['totalAmount'] = 0
            if 'id' in order and isinstance(order['id'], str):
                try:
                    order['id'] = int(order['id'])
                except:
                    pass
        
        print(f"[Analytics] Loaded from ChromaDB: {len(products)} products, {len(orders)} orders, {len(categories)} categories, {len(discounts)} discounts, {len(business_performance)} business records, {len(users)} users, {len(documents)} documents")
        
        return {
            'products': products,
            'orders': orders,
            'categories': categories,
            'discounts': discounts,
            'business_performance': business_performance,
            'users': users,
            'documents': documents,
            'revenue_overview': revenue_overview
        }
    except Exception as e:
        print(f"Error fetching business data from ChromaDB: {e}")
        import traceback
        traceback.print_exc()
        return {
            'products': [],
            'orders': [],
            'categories': [],
            'discounts': [],
            'business_performance': [],
            'users': [],
            'documents': [],
            'revenue_overview': []
        }

def calculate_statistics(data):
    """TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ thá»‘ng kÃª"""
    products = data.get('products', [])
    orders = data.get('orders', [])
    categories = data.get('categories', [])
    revenue_overview = data.get('revenue_overview', [])
    
    # Thá»‘ng kÃª tá»•ng quan
    total_products = len(products)
    total_orders = len(orders)
    total_categories = len(categories)
    
    # Sá»­ dá»¥ng dá»¯ liá»‡u doanh thu tá»« revenue_overview náº¿u cÃ³, náº¿u khÃ´ng thÃ¬ tÃ­nh tá»« orders
    if revenue_overview:
        # Láº¥y dá»¯ liá»‡u tá»« revenue_overview collection
        revenue_data = revenue_overview[0] if revenue_overview else {}
        total_revenue = revenue_data.get('total_revenue', 0)
        monthly_revenue = revenue_data.get('monthly_revenue', 0)
        weekly_revenue = revenue_data.get('weekly_revenue', 0)
        daily_revenue = revenue_data.get('daily_revenue', 0)
    else:
        # Fallback: tÃ­nh tá»« orders data
        total_revenue = sum(order.get('totalAmount', 0) for order in orders)
        monthly_revenue = 0  # KhÃ´ng thá»ƒ tÃ­nh tá»« orders data
        weekly_revenue = 0
        daily_revenue = 0
    
    # TÃ­nh doanh thu theo tráº¡ng thÃ¡i
    revenue_by_status = {}
    orders_by_status = {}
    for order in orders:
        status = order.get('status', 'UNKNOWN')
        amount = order.get('totalAmount', 0)
        
        revenue_by_status[status] = revenue_by_status.get(status, 0) + amount
        orders_by_status[status] = orders_by_status.get(status, 0) + 1
    
    # Convert to array format for frontend
    revenue_by_status_array = [
        {'status': status, 'revenue': revenue}
        for status, revenue in revenue_by_status.items()
    ]
    orders_by_status_array = [
        {'status': status, 'count': count}
        for status, count in orders_by_status.items()
    ]
    
    # TÃ­nh sá»‘ lÆ°á»£ng Ä‘Ã£ bÃ¡n vÃ  doanh thu cho tá»«ng sáº£n pháº©m
    # Note: ChromaDB orders khÃ´ng chá»©a chi tiáº¿t items, nÃªn dÃ¹ng totalSold tá»« product metadata
    enriched_products = []
    for product in products:
        total_sold = product.get('totalSold', 0)
        if isinstance(total_sold, str):
            try:
                total_sold = int(total_sold)
            except:
                total_sold = 0
        
        price = product.get('price', 0)
        revenue = total_sold * price
        
        enriched_product = {
            **product,
            'stock': product.get('quantity', 0),  # Äá»•i quantity -> stock
            'total_sold': total_sold,
            'revenue': revenue
        }
        enriched_products.append(enriched_product)
    
    # Top sáº£n pháº©m bÃ¡n cháº¡y (theo total_sold vÃ  revenue)
    products_sorted = sorted(enriched_products, key=lambda x: (x.get('total_sold', 0), x.get('revenue', 0)), reverse=True)
    top_products = products_sorted[:10]
    
    # Sáº£n pháº©m sáº¯p háº¿t hÃ ng (stock < 20)
    low_stock_products = sorted(
        [p for p in enriched_products if p.get('stock', 0) < 20],
        key=lambda x: x.get('stock', 0)
    )[:10]
    
    # PhÃ¢n tÃ­ch theo danh má»¥c
    category_stats = {}
    for product in products:
        cat_id = product.get('categoryId')
        cat_name = product.get('categoryName', 'Unknown')
        
        if cat_name not in category_stats:
            category_stats[cat_name] = {
                'product_count': 0,
                'total_stock': 0,
                'avg_price': 0,
                'total_price': 0
            }
        
        category_stats[cat_name]['product_count'] += 1
        category_stats[cat_name]['total_stock'] += product.get('quantity', 0)
        category_stats[cat_name]['total_price'] += product.get('price', 0)
    
    # TÃ­nh giÃ¡ trung bÃ¬nh theo danh má»¥c
    for cat_name, stats in category_stats.items():
        if stats['product_count'] > 0:
            stats['avg_price'] = stats['total_price'] / stats['product_count']
    
    # PhÃ¢n tÃ­ch theo thá»i gian (7 ngÃ y gáº§n nháº¥t)
    now = datetime.now()
    last_7_days = now - timedelta(days=7)
    
    revenue_by_day = {}
    orders_by_day = {}
    
    for order in orders:
        created_at = order.get('createdAt', '')
        if created_at:
            try:
                order_date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                date_key = order_date.strftime('%Y-%m-%d')
                
                revenue_by_day[date_key] = revenue_by_day.get(date_key, 0) + order.get('totalAmount', 0)
                orders_by_day[date_key] = orders_by_day.get(date_key, 0) + 1
            except:
                pass
    
    return {
        'overview': {
            'total_products': total_products,
            'total_orders': total_orders,
            'total_categories': total_categories,
            'total_revenue': total_revenue,
            'monthly_revenue': monthly_revenue,
            'weekly_revenue': weekly_revenue,
            'daily_revenue': daily_revenue,
            'avg_order_value': total_revenue / total_orders if total_orders > 0 else 0
        },
        'revenue_by_status': revenue_by_status_array,
        'orders_by_status': orders_by_status_array,
        'top_products': top_products,
        'low_stock_products': low_stock_products,
        'category_stats': category_stats,
        'revenue_by_day': revenue_by_day,
        'orders_by_day': orders_by_day
    }

@router.get('/data')
async def get_analytics_data():
    """Láº¥y dá»¯ liá»‡u phÃ¢n tÃ­ch thá»‘ng kÃª"""
    try:
        # Láº¥y dá»¯ liá»‡u tá»« ChromaDB
        business_data = get_business_data()
        
        # TÃ­nh toÃ¡n thá»‘ng kÃª
        statistics = calculate_statistics(business_data)
        
        return {
            'success': True,
            'data': statistics
        }
        
    except Exception as e:
        print(f"Error in analytics data: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@router.post('/ai-insights')
async def get_ai_insights(request: AIInsightsRequest):
    """Sá»­ dá»¥ng AI Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  Ä‘á» xuáº¥t chiáº¿n lÆ°á»£c kinh doanh vá»›i RAG tá»« documents"""
    try:
        # Láº¥y dá»¯ liá»‡u kinh doanh tá»« ChromaDB
        business_data = get_business_data()
        statistics = calculate_statistics(business_data)
        
        # ğŸ” SEARCH BUSINESS DOCUMENTS FOR RELEVANT INFORMATION
        document_context = ""
        if analytics_rag_service:
            try:
                # Search for document content related to the analysis type
                search_query = request.type
                doc_results = analytics_rag_service.search_business_data(
                    query=search_query,
                    n_results=5
                )
                
                if doc_results:
                    document_context = "\\n\\nğŸ“„ THÃ”NG TIN Tá»ª TÃ€I LIá»†U DOANH NGHIá»†P:\\n"
                    for i, doc in enumerate(doc_results, 1):
                        content = doc.get('content', '')[:1000]  # Limit content length
                        document_context += f"\\n--- TÃ i liá»‡u {i} ---\\n{content}\\n"
                    
                    print(f"[AI Insights] Found {len(doc_results)} relevant documents")
                else:
                    print("[AI Insights] No relevant documents found")
                    
            except Exception as e:
                print(f"[AI Insights] Error searching documents: {e}")
        
        # Táº¡o prompt cho AI dá»±a trÃªn loáº¡i phÃ¢n tÃ­ch + document context
        prompt = create_analysis_prompt(request.type, statistics, business_data, document_context)
        
        # Use the selected model from request
        model_name = request.model if request.model else 'llama-3.3-70b-versatile'
        print(f"[Analytics] Using AI model: {model_name}")
        
        # Determine provider based on model name - check if it's a Groq model
        groq_model_prefixes = [
            'llama', 'mixtral', 'gemma', 'openai/gpt-oss', 'moonshotai', 
            'meta-llama', 'qwen', 'groq', 'allam', 'playai'
        ]
        is_groq = any(prefix in model_name.lower() for prefix in groq_model_prefixes)
        
        print(f"[Analytics] Model: {model_name}, Provider: {'Groq' if is_groq else 'Gemini'}")
        
        if is_groq and groq_client:
            # Use Groq API
            print(f"[Analytics] Using Groq API")
            try:
                chat_completion = groq_client.chat.completions.create(
                    messages=[
                        {
                            "role": "user",
                            "content": prompt,
                        }
                    ],
                    model=model_name,
                    temperature=0.7,
                    max_tokens=2048,
                )
                ai_insights = chat_completion.choices[0].message.content
            except Exception as groq_error:
                print(f"[Analytics] Groq API error: {groq_error}")
                # Fallback to Gemini if Groq fails
                print(f"[Analytics] Fallback to Gemini API")
                try:
                    model = genai.GenerativeModel('gemini-2.5-flash')
                    response = model.generate_content(prompt)
                    ai_insights = response.text
                except Exception as gemini_error:
                    print(f"[Analytics] Gemini fallback also failed: {gemini_error}")
                    raise HTTPException(status_code=500, detail=f"Both Groq and Gemini APIs failed. Groq: {groq_error}, Gemini: {gemini_error}")
        else:
            # Use Gemini API
            print(f"[Analytics] Using Gemini API")
            try:
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)
                ai_insights = response.text
            except Exception as gemini_error:
                print(f"[Analytics] Gemini API error: {gemini_error}")
                raise HTTPException(status_code=500, detail=f"Gemini API error: {gemini_error}")
        
        return {
            'success': True,
            'insights': ai_insights,
            'statistics': statistics,
            'analysis_type': request.type
        }
        
    except Exception as e:
        print(f"Error in AI insights: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

def create_analysis_prompt(analysis_type, statistics, business_data, document_context=""):
    """Táº¡o prompt cho AI dá»±a trÃªn loáº¡i phÃ¢n tÃ­ch vÃ  thÃ´ng tin tá»« tÃ i liá»‡u"""
    
    overview = statistics.get('overview', {})
    revenue_by_status = statistics.get('revenue_by_status', [])
    orders_by_status = statistics.get('orders_by_status', [])
    category_stats = statistics.get('category_stats', {})
    low_stock_products = statistics.get('low_stock_products', [])
    top_products = statistics.get('top_products', [])
    
    # Láº¥y thÃªm dá»¯ liá»‡u chi tiáº¿t
    products = business_data.get('products', [])
    orders = business_data.get('orders', [])
    categories = business_data.get('categories', [])
    discounts = business_data.get('discounts', [])
    business_performance = business_data.get('business_performance', [])
    
    # PhÃ¢n tÃ­ch sÃ¢u hÆ¡n
    total_inventory_value = sum([p.get('price', 0) * p.get('quantity', 0) for p in products])
    avg_product_price = sum([p.get('price', 0) for p in products]) / len(products) if products else 0
    products_with_details = [p for p in products if p.get('has_details')]
    
    base_context = f"""
ğŸ¯ Báº N LÃ€ CHUYÃŠN GIA PHÃ‚N TÃCH KINH DOANH & CHIáº¾N LÆ¯á»¢C CAO Cáº¤P

ğŸ“Š Dá»® LIá»†U KINH DOANH Tá»”NG QUAN:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¦ Sáº£n pháº©m:
   â€¢ Tá»•ng sá»‘: {overview.get('total_products', 0)} sáº£n pháº©m
   â€¢ CÃ³ thÃ´ng tin chi tiáº¿t: {len(products_with_details)} sáº£n pháº©m ({len(products_with_details)/len(products)*100:.1f}% náº¿u cÃ³ sáº£n pháº©m)
   â€¢ GiÃ¡ trung bÃ¬nh: {avg_product_price:,.0f} VNÄ
   â€¢ Tá»•ng giÃ¡ trá»‹ hÃ ng tá»“n: {total_inventory_value:,.0f} VNÄ
   â€¢ Sáº£n pháº©m sáº¯p háº¿t hÃ ng: {len(low_stock_products)}

ğŸ›’ ÄÆ¡n hÃ ng:
   â€¢ Tá»•ng sá»‘: {overview.get('total_orders', 0)} Ä‘Æ¡n
   â€¢ Tá»•ng doanh thu: {overview.get('total_revenue', 0):,.0f} VNÄ
   â€¢ GiÃ¡ trá»‹ TB/Ä‘Æ¡n: {overview.get('avg_order_value', 0):,.0f} VNÄ

ğŸ“ˆ PHÃ‚N TÃCH DOANH THU THEO TRáº NG THÃI:
{json.dumps(revenue_by_status, indent=2, ensure_ascii=False)}

ğŸ“‹ PHÃ‚N Bá» ÄÆ N HÃ€NG THEO TRáº NG THÃI:
{json.dumps(orders_by_status, indent=2, ensure_ascii=False)}

ğŸ·ï¸ THá»NG KÃŠ THEO DANH Má»¤C Sáº¢N PHáº¨M:
{json.dumps(category_stats, indent=2, ensure_ascii=False)}

â­ TOP 5 Sáº¢N PHáº¨M Ná»”I Báº¬T:
{json.dumps([{'tÃªn': p.get('name'), 'giÃ¡': f"{p.get('price', 0):,.0f} VNÄ", 'tá»“n_kho': p.get('quantity', 0), 'Ä‘Ã£_bÃ¡n': p.get('total_sold', 0)} for p in top_products[:5]], indent=2, ensure_ascii=False)}

âš ï¸ Sáº¢N PHáº¨M Cáº¦N NHáº¬P HÃ€NG (Tá»“n kho < 10):
{json.dumps([{'tÃªn': p.get('name'), 'tá»“n_kho': p.get('quantity', 0), 'giÃ¡': f"{p.get('price', 0):,.0f} VNÄ"} for p in low_stock_products[:10]], indent=2, ensure_ascii=False)}

ğŸ’° THÃ”NG TIN KHUYáº¾N MÃƒI:
   â€¢ Tá»•ng sá»‘ chÆ°Æ¡ng trÃ¬nh: {len(discounts)}
   â€¢ Äang hoáº¡t Ä‘á»™ng: {len([d for d in discounts if d.get('status') == 'ACTIVE'])}

ğŸ¢ HIá»†U SUáº¤T NGÆ¯á»œI BÃN:
   â€¢ Tá»•ng sá»‘ ngÆ°á»i bÃ¡n: {len(business_performance)}
   â€¢ Tá»•ng doanh thu táº¥t cáº£: {sum([bp.get('revenue', 0) for bp in business_performance]):,.0f} VNÄ

{document_context}
"""

    if analysis_type == 'general':
        prompt = base_context + """

ğŸ¯ NHIá»†M Vá»¤: PHÃ‚N TÃCH Tá»”NG QUAN TOÃ€N DIá»†N & Äá»€ XUáº¤T CHIáº¾N LÆ¯á»¢C KINH DOANH

ğŸ“ YÃŠU Cáº¦U PHÃ‚N TÃCH:

## 1ï¸âƒ£ TÃŒNH HÃŒNH KINH DOANH HIá»†N Táº I
- ÄÃ¡nh giÃ¡ tá»•ng quan vá» doanh thu, Ä‘Æ¡n hÃ ng, sáº£n pháº©m
- PhÃ¢n tÃ­ch xu hÆ°á»›ng tÄƒng/giáº£m (náº¿u cÃ³ dá»¯ liá»‡u theo thá»i gian)
- So sÃ¡nh vá»›i cÃ¡c chá»‰ sá»‘ trung bÃ¬nh ngÃ nh (náº¿u Ã¡p dá»¥ng)

## 2ï¸âƒ£ ÄIá»‚M Máº NH & Lá»¢I THáº¾ Cáº NH TRANH
- Nhá»¯ng Ä‘iá»ƒm ná»•i báº­t trong hoáº¡t Ä‘á»™ng kinh doanh
- Sáº£n pháº©m/danh má»¥c cÃ³ hiá»‡u suáº¥t tá»‘t
- CÆ¡ há»™i Ä‘á»ƒ khai thÃ¡c vÃ  phÃ¡t triá»ƒn

## 3ï¸âƒ£ THÃCH THá»¨C & Váº¤N Äá»€ Cáº¦N GIáº¢I QUYáº¾T
- Äiá»ƒm yáº¿u trong váº­n hÃ nh hiá»‡n táº¡i
- Rá»§i ro tiá»m áº©n cáº§n lÆ°u Ã½
- Nhá»¯ng rÃ o cáº£n cáº§n vÆ°á»£t qua

## 4ï¸âƒ£ Äá»€ XUáº¤T CHIáº¾N LÆ¯á»¢C Cá»¤ THá»‚ (7-10 HÃ€NH Äá»˜NG)
### ğŸ“ˆ TÄƒng trÆ°á»Ÿng doanh thu:
- [Äá» xuáº¥t 2-3 hÃ nh Ä‘á»™ng cá»¥ thá»ƒ vá»›i sá»‘ liá»‡u]

### ğŸ’° Tá»‘i Æ°u lá»£i nhuáº­n:
- [Äá» xuáº¥t 2-3 hÃ nh Ä‘á»™ng cá»¥ thá»ƒ vá»›i sá»‘ liá»‡u]

### ğŸ“¦ Quáº£n lÃ½ tá»“n kho:
- [Äá» xuáº¥t 2-3 hÃ nh Ä‘á»™ng cá»¥ thá»ƒ vá»›i sá»‘ liá»‡u]

### ğŸ¯ Marketing & KhÃ¡ch hÃ ng:
- [Äá» xuáº¥t 2-3 hÃ nh Ä‘á»™ng cá»¥ thá»ƒ vá»›i sá»‘ liá»‡u]

## 5ï¸âƒ£ Dá»° BÃO & Káº¾ HOáº CH PHÃT TRIá»‚N
- Xu hÆ°á»›ng thá»‹ trÆ°á»ng sáº¯p tá»›i
- CÆ¡ há»™i má»Ÿ rá»™ng kinh doanh
- Roadmap ngáº¯n háº¡n (1-3 thÃ¡ng) vÃ  dÃ i háº¡n (6-12 thÃ¡ng)

## 6ï¸âƒ£ CHá»ˆ Sá» KPI Äá»€ XUáº¤T THEO DÃ•I
- [Liá»‡t kÃª 5-7 KPIs quan trá»ng cáº§n monitor hÃ ng tuáº§n/thÃ¡ng]

âš¡ FORMAT YÃŠU Cáº¦U:
- Sá»­ dá»¥ng emoji phÃ¹ há»£p Ä‘á»ƒ lÃ m ná»•i báº­t cÃ¡c pháº§n
- DÃ¹ng báº£ng markdown, bullet points, headings rÃµ rÃ ng
- Sá»‘ liá»‡u cá»¥ thá»ƒ vá»›i Ä‘Æ¡n vá»‹ VNÄ, % rÃµ rÃ ng
- Viáº¿t tiáº¿ng Viá»‡t chuyÃªn nghiá»‡p, dá»… hiá»ƒu
- Äá»™ dÃ i: 800-1200 tá»«
- Chia sections rÃµ rÃ ng vá»›i headings H2, H3
"""

    elif analysis_type == 'pricing':
        prompt = base_context + """

ğŸ’° NHIá»†M Vá»¤: PHÃ‚N TÃCH CHIáº¾N LÆ¯á»¢C GIÃ & Tá»I Æ¯U Lá»¢I NHUáº¬N

ğŸ“ YÃŠU Cáº¦U PHÃ‚N TÃCH:

## 1ï¸âƒ£ PHÃ‚N TÃCH GIÃ HIá»†N Táº I
- ÄÃ¡nh giÃ¡ má»©c giÃ¡ cá»§a tá»«ng danh má»¥c sáº£n pháº©m
- So sÃ¡nh giÃ¡ trung bÃ¬nh vá»›i thá»‹ trÆ°á»ng (náº¿u cÃ³ thÃ´ng tin)
- PhÃ¢n tÃ­ch khoáº£ng giÃ¡: tháº¥p, trung bÃ¬nh, cao
- Price elasticity: sáº£n pháº©m nÃ o nháº¡y cáº£m vá»›i giÃ¡?

## 2ï¸âƒ£ CÆ  Há»˜I TÄ‚NG GIÃ ğŸ“ˆ
Táº¡o báº£ng markdown:
| Sáº£n pháº©m/Danh má»¥c | GiÃ¡ hiá»‡n táº¡i | Äá» xuáº¥t | LÃ½ do | TÃ¡c Ä‘á»™ng dá»± kiáº¿n |
|-------------------|--------------|---------|-------|------------------|

### Äiá»u kiá»‡n Ä‘á»ƒ tÄƒng giÃ¡ thÃ nh cÃ´ng:
- [Liá»‡t kÃª 3-5 Ä‘iá»u kiá»‡n cá»¥ thá»ƒ]

## 3ï¸âƒ£ CÆ  Há»˜I GIáº¢M GIÃ/KHUYáº¾N MÃƒI ğŸ“‰
Táº¡o báº£ng markdown:
| Sáº£n pháº©m/Danh má»¥c | GiÃ¡ hiá»‡n táº¡i | Äá» xuáº¥t | Má»¥c tiÃªu | ROI dá»± kiáº¿n |
|-------------------|--------------|---------|----------|-------------|

## 4ï¸âƒ£ CHIáº¾N LÆ¯á»¢C COMBO & BUNDLE ğŸ
### Combo Ä‘á» xuáº¥t:
1. **[TÃªn combo]**: [Sáº£n pháº©m A] + [Sáº£n pháº©m B]
   - GiÃ¡ láº»: [X] VNÄ
   - GiÃ¡ combo: [Y] VNÄ (Tiáº¿t kiá»‡m [Z]%)
   - LÃ½ do combo nÃ y háº¥p dáº«n: [...]
   - Má»¥c tiÃªu: tÄƒng AOV lÃªn [X]%

[Äá» xuáº¥t 3-5 combo]

## 5ï¸âƒ£ Lá»ŠCH KHUYáº¾N MÃƒI Äá»€ XUáº¤T ğŸ“…
Táº¡o báº£ng markdown:
| Thá»i Ä‘iá»ƒm | Loáº¡i KM | Sáº£n pháº©m | Má»©c giáº£m | Má»¥c tiÃªu | Budget |
|-----------|---------|----------|----------|----------|--------|

## 6ï¸âƒ£ CHIáº¾N THUáº¬T GIÃ TÃ‚M LÃ ğŸ§ 
- **Psychological Pricing**: GiÃ¡ láº» (999,000 thay vÃ¬ 1,000,000)
- **Anchor Pricing**: Hiá»ƒn thá»‹ giÃ¡ gá»‘c Ä‘á»ƒ táº¡o giÃ¡ trá»‹
- **Premium Pricing**: Sáº£n pháº©m cao cáº¥p Ä‘á»‹nh vá»‹ giÃ¡ cao
- **Loss Leader**: Sáº£n pháº©m thu hÃºt vá»›i giÃ¡ tháº¥p

## 7ï¸âƒ£ Dá»° ÃN TÄ‚NG DOANH THU VÃ€ Lá»¢I NHUáº¬N
- TÄƒng doanh thu dá»± kiáº¿n: **+[X]%**
- TÄƒng lá»£i nhuáº­n dá»± kiáº¿n: **+[Y]%**
- TÄƒng AOV dá»± kiáº¿n: **+[Z]%**
- Timeline thá»±c hiá»‡n: [3-6 thÃ¡ng]
- NgÃ¢n sÃ¡ch cáº§n: [X] VNÄ
- ROI expected: [Y]X

âš¡ Viáº¿t chi tiáº¿t vá»›i sá»‘ liá»‡u cá»¥ thá»ƒ, dá»… Ã¡p dá»¥ng ngay!
"""

    elif analysis_type == 'inventory':
        prompt = base_context + """

ğŸ“¦ NHIá»†M Vá»¤: PHÃ‚N TÃCH & Tá»I Æ¯U QUáº¢N LÃ Tá»’N KHO

ğŸ“ YÃŠU Cáº¦U PHÃ‚N TÃCH:

## 1ï¸âƒ£ ÄÃNH GIÃ TÃŒNH TRáº NG Tá»’N KHO HIá»†N Táº I
### ğŸ“Š PhÃ¢n loáº¡i tá»“n kho:
Táº¡o báº£ng markdown:
| Loáº¡i | Sá»‘ lÆ°á»£ng SP | GiÃ¡ trá»‹ | Tá»· lá»‡ % |
|------|-------------|---------|---------|
| ğŸŸ¢ Tá»‘t (>30 SP) | | VNÄ | % |
| ğŸŸ¡ Trung bÃ¬nh (10-30) | | VNÄ | % |
| ğŸ”´ Tháº¥p (<10) | | VNÄ | % |
| âš« Háº¿t hÃ ng (0) | | 0 VNÄ | % |

### ğŸ’° GiÃ¡ trá»‹ tá»“n kho:
- **Tá»•ng giÃ¡ trá»‹**: [...] VNÄ
- **Vá»‘n Ä‘Ã³ng bÄƒng** (hÃ ng tá»“n lÃ¢u): [...] VNÄ
- **Kháº£ nÄƒng thanh khoáº£n**: [Cao/Trung bÃ¬nh/Tháº¥p]

## 2ï¸âƒ£ Æ¯U TIÃŠN NHáº¬P HÃ€NG NGAY âš¡
Táº¡o báº£ng markdown:
| STT | Sáº£n pháº©m | Tá»“n hiá»‡n táº¡i | BÃ¡n TB/ngÃ y | Háº¿t sau X ngÃ y | SL Ä‘á» xuáº¥t nháº­p |
|-----|----------|--------------|-------------|----------------|-----------------|

### ğŸ“‹ Káº¿ hoáº¡ch nháº­p hÃ ng chi tiáº¿t:
**TUáº¦N NÃ€Y (URGENT):**
- [Danh sÃ¡ch 5-10 sáº£n pháº©m cáº§n nháº­p gáº¥p]
- Tá»•ng vá»‘n cáº§n: [...] VNÄ

**THÃNG NÃ€Y:**
- [Káº¿ hoáº¡ch dá»± trÃ¹ tá»•ng thá»ƒ]
- NgÃ¢n sÃ¡ch: [...] VNÄ

## 3ï¸âƒ£ Xá»¬ LÃ HÃ€NG Tá»’N KHO LÃ‚U ğŸ—‘ï¸
Táº¡o báº£ng markdown:
| Sáº£n pháº©m | Tá»“n | GiÃ¡ trá»‹ | Thá»i gian tá»“n | Giáº£i phÃ¡p Ä‘á» xuáº¥t |
|----------|-----|---------|---------------|-------------------|

### Chiáº¿n lÆ°á»£c xá»­ lÃ½:
1. **Flash Sale Weekend**: Giáº£m 40-50% cho top [X] sáº£n pháº©m
2. **Bundle Deal**: Káº¿t há»£p vá»›i sáº£n pháº©m hot
3. **Gift with Purchase**: Táº·ng kÃ¨m khi mua sáº£n pháº©m khÃ¡c

## 4ï¸âƒ£ Tá»I Æ¯U HÃ“A QUY TRÃŒNH KHO ğŸ¯
### A. PhÃ¢n loáº¡i ABC:
- **NhÃ³m A** (20% SP, 80% giÃ¡ trá»‹): [Liá»‡t kÃª sáº£n pháº©m chiáº¿n lÆ°á»£c]
- **NhÃ³m B** (30% SP, 15% giÃ¡ trá»‹): [Sáº£n pháº©m quan trá»ng]
- **NhÃ³m C** (50% SP, 5% giÃ¡ trá»‹): [Sáº£n pháº©m phá»¥]

### B. Cáº£i thiá»‡n váº­n hÃ nh:
1. **Há»‡ thá»‘ng quáº£n lÃ½ kho:**
   - Äá» xuáº¥t pháº§n má»m/cÃ´ng cá»¥ phÃ¹ há»£p
   - Barcode/QR scanning
   
2. **Quy trÃ¬nh kiá»ƒm kÃª:**
   - Táº§n suáº¥t: [HÃ ng tuáº§n/thÃ¡ng]
   - PhÆ°Æ¡ng phÃ¡p: [Cycle counting/Full inventory]
   
3. **Sáº¯p xáº¿p kho:**
   - Layout tá»‘i Æ°u theo ABC
   - FIFO/LIFO strategy

### C. ChÃ­nh sÃ¡ch an toÃ n kho:
- **Safety Stock**: [X] Ä‘Æ¡n vá»‹
- **Reorder Point**: Khi tá»“n <= [Y]
- **Lead Time**: [Z] ngÃ y
- **EOQ** (Economic Order Quantity): [TÃ­nh toÃ¡n]

## 5ï¸âƒ£ Káº¾ HOáº CH Dá»° TRÃ™ 3 THÃNG Tá»šI ğŸ“…
### ThÃ¡ng 1 (Hiá»‡n táº¡i):
- NgÃ¢n sÃ¡ch: [...] VNÄ
- Danh má»¥c Æ°u tiÃªn: [...]
- Sáº£n pháº©m cáº§n Ä‘áº©y máº¡nh: [...]

### ThÃ¡ng 2:
- MÃ¹a vá»¥/sá»± kiá»‡n: [...]
- Sáº£n pháº©m seasonal: [...]

### ThÃ¡ng 3:
- Chuáº©n bá»‹ cho: [...]
- Sáº£n pháº©m má»›i launch: [...]

## 6ï¸âƒ£ CHá»ˆ Sá» HIá»†U SUáº¤T KHO
TÃ­nh toÃ¡n vÃ  Ä‘Ã¡nh giÃ¡:
- **Inventory Turnover Ratio**: [...] láº§n/nÄƒm [Tá»‘t/TB/Cáº§n cáº£i thiá»‡n]
- **Days Sales of Inventory (DSI)**: [...] ngÃ y
- **Stockout Rate**: [...]% [Má»¥c tiÃªu: <5%]
- **Carrying Cost**: [...] VNÄ/thÃ¡ng
- **Fill Rate**: [...]% [Má»¥c tiÃªu: >95%]

âš¡ PhÃ¢n tÃ­ch chi tiáº¿t vá»›i sá»‘ liá»‡u cá»¥ thá»ƒ, káº¿ hoáº¡ch thá»±c thi rÃµ rÃ ng!
"""

    elif analysis_type == 'sales':
        prompt = base_context + """

ğŸš€ NHIá»†M Vá»¤: PHÃ‚N TÃCH DOANH Sá» & CHIáº¾N LÆ¯á»¢C TÄ‚NG TRÆ¯á»NG

ğŸ“ YÃŠU Cáº¦U PHÃ‚N TÃCH:

## 1ï¸âƒ£ PHÃ‚N TÃCH HIá»†U SUáº¤T BÃN HÃ€NG
### ğŸ“ˆ Doanh sá»‘ theo danh má»¥c:
Táº¡o báº£ng markdown:
| Danh má»¥c | Doanh thu | Sá»‘ Ä‘Æ¡n | AOV | % Tá»•ng DT | Xu hÆ°á»›ng |
|----------|-----------|--------|-----|-----------|----------|

### â­ Top 5 Performers:
1. **[Sáº£n pháº©m 1]**: [...] VNÄ
   - LÃ½ do thÃ nh cÃ´ng: [...]
   - Insight: [...]
   
[Tiáº¿p tá»¥c cho 4 sáº£n pháº©m khÃ¡c]

### âš ï¸ Bottom 5 - Cáº§n cáº£i thiá»‡n:
- [Danh sÃ¡ch sáº£n pháº©m bÃ¡n kÃ©m vá»›i phÃ¢n tÃ­ch lÃ½ do]

## 2ï¸âƒ£ PHÃ‚N TÃCH KHÃCH HÃ€NG ğŸ‘¥
### HÃ nh vi mua hÃ ng:
- **Average Order Value**: [...] VNÄ
- **Purchase Frequency**: [...] láº§n/khÃ¡ch/thÃ¡ng
- **Customer Retention Rate**: [...]%
- **Repeat Customer Rate**: [...]%

### PhÃ¢n khÃºc khÃ¡ch hÃ ng:
Táº¡o báº£ng markdown:
| PhÃ¢n khÃºc | % KH | Doanh thu | AOV | Äáº·c Ä‘iá»ƒm & HÃ nh vi |
|-----------|------|-----------|-----|---------------------|

## 3ï¸âƒ£ CHIáº¾N LÆ¯á»¢C MARKETING TÃCH Há»¢P ğŸ“¢
### A. Content Marketing:
1. **Blog/SEO Content**:
   - [3-5 chá»§ Ä‘á» hot cÃ³ potential traffic cao]
   - Target keywords: [...]
   
2. **Video Marketing**:
   - Product reviews
   - How-to guides
   - Behind the scenes
   
3. **Social Media Strategy**:
   - Platform: Facebook, Instagram, TikTok
   - Content calendar: [Mix content types]

### B. Paid Advertising Campaign:
Táº¡o báº£ng markdown:
| KÃªnh | Budget/thÃ¡ng | Target Audience | Objective | ROAS dá»± kiáº¿n |
|------|--------------|-----------------|-----------|--------------|

### C. Email Marketing Flows:
1. **Welcome Series** (3-5 emails):
   - Day 0: Welcome + 10% discount
   - Day 3: Product education
   - Day 7: Testimonials + urgency
   
2. **Cart Abandonment**:
   - 1h: Reminder
   - 24h: 5% discount
   - 48h: Free shipping
   
3. **Post-Purchase**:
   - Thank you + tracking
   - Review request
   - Cross-sell recommendations

### D. ChÆ°Æ¡ng trÃ¬nh Khuyáº¿n mÃ£i:
1. **Flash Sales**: [Timing + Products + Discount]
2. **Loyalty Program**: [Points system design]
3. **Referral Program**: [Incentive structure]

## 4ï¸âƒ£ Cáº¢I THIá»†N TRáº¢I NGHIá»†M KHÃCH HÃ€NG ğŸŒŸ
### A. Pre-Purchase:
- [ ] Tá»‘i Æ°u product pages (images, description, specs)
- [ ] Live chat/chatbot 24/7
- [ ] Customer reviews prominent
- [ ] Product comparison tool
- [ ] AR/Virtual try-on (if applicable)

### B. Purchase Process:
- [ ] One-page checkout (giáº£m friction)
- [ ] Multiple payment options
- [ ] Guest checkout
- [ ] Real-time shipping calculator
- [ ] Mobile-optimized

### C. Post-Purchase:
- [ ] Order confirmation + tracking link
- [ ] Proactive customer service
- [ ] Easy returns/exchanges
- [ ] Review incentives
- [ ] Loyalty rewards

## 5ï¸âƒ£ ROADMAP TÄ‚NG TRÆ¯á»NG 30% ğŸ¯
### Phase 1: ThÃ¡ng 1-2 (Foundation) - Má»¥c tiÃªu +10%
**Quick Wins:**
- [3-5 hÃ nh Ä‘á»™ng vá»›i impact cao, effort tháº¥p]
- Budget: [...] VNÄ
- Expected ROI: [...]X

**KPIs theo dÃµi:**
- Traffic: +[X]%
- Conversion rate: +[Y]%
- AOV: +[Z]%

### Phase 2: ThÃ¡ng 3-4 (Acceleration) - Má»¥c tiÃªu +10%
**Growth Initiatives:**
- [3-5 chiáº¿n lÆ°á»£c tÄƒng trÆ°á»Ÿng máº¡nh]
- Budget: [...] VNÄ
- Expected ROI: [...]X

### Phase 3: ThÃ¡ng 5-6 (Scale) - Má»¥c tiÃªu +10%
**Scale & Optimize:**
- [3-5 hÃ nh Ä‘á»™ng scale vÃ  tá»‘i Æ°u]
- Budget: [...] VNÄ
- Expected ROI: [...]X

## 6ï¸âƒ£ DASHBOARD KPIs Cáº¦N THEO DÃ•I ğŸ“Š
### Sales Metrics:
- **Revenue Growth**: [...]%/thÃ¡ng (Target: 30%/6 thÃ¡ng)
- **Conversion Rate**: [...]% (Target: +20%)
- **Average Order Value**: [...] VNÄ (Target: +15%)
- **Customer Acquisition Cost**: [...] VNÄ (Target: giáº£m 10%)
- **Customer Lifetime Value**: [...] VNÄ (Target: tÄƒng 25%)

### Marketing Metrics:
- **Website Traffic**: [...]/thÃ¡ng (Target: +50%)
- **Engagement Rate**: [...]% (Target: >5%)
- **ROAS**: [...]X (Target: >3X)
- **Email Open Rate**: [...]% (Target: >20%)
- **Social Media Followers**: [...] (Target: +100%)

### Operational Metrics:
- **Order Fulfillment Time**: [...] giá» (Target: <24h)
- **Customer Satisfaction**: [...]% (Target: >90%)
- **Return Rate**: [...]% (Target: <5%)

âš¡ PhÃ¢n tÃ­ch thá»±c táº¿, chiáº¿n lÆ°á»£c chi tiáº¿t, roadmap rÃµ rÃ ng, dá»… triá»ƒn khai ngay!
"""

    else:
        prompt = base_context + "\n\nPhÃ¢n tÃ­ch tá»•ng quan vÃ  Ä‘Æ°a ra Ä‘á» xuáº¥t."

    return prompt


@router.get("/chroma-data")
async def get_all_chroma_data():
    """
    Endpoint Ä‘á»ƒ hiá»ƒn thá»‹ táº¥t cáº£ dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trong Chroma DB instance chroma_analytics
    
    Returns:
        Dict chá»©a táº¥t cáº£ collections vÃ  dá»¯ liá»‡u cá»§a chÃºng
    """
    try:
        global chroma_client
        if chroma_client is None:
            return {"error": "ChromaDB client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o"}
        
        # Láº¥y táº¥t cáº£ collections
        collections = chroma_client.list_collections()
        
        result = {
            "instance_path": "./chroma_analytics",
            "total_collections": len(collections),
            "collections": {},
            "timestamp": datetime.now().isoformat()
        }
        
        # Duyá»‡t qua tá»«ng collection
        for collection in collections:
            collection_name = collection.name
            
            try:
                # Láº¥y táº¥t cáº£ documents - khÃ´ng cáº§n include vÃ¬ máº·c Ä‘á»‹nh Ä‘Ã£ cÃ³ ids, documents, metadatas
                all_data = collection.get()
                
                result["collections"][collection_name] = {
                    "metadata": collection.metadata,
                    "total_documents": len(all_data.get('ids', [])),
                    "documents": []
                }
                
                # Táº¡o danh sÃ¡ch documents vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin
                ids = all_data.get('ids', [])
                documents = all_data.get('documents', [])
                metadatas = all_data.get('metadatas', [])
                
                for i, doc_id in enumerate(ids):
                    doc_info = {
                        "id": doc_id,
                        "content": documents[i] if i < len(documents) else None,
                        "metadata": metadatas[i] if metadatas and i < len(metadatas) else None
                    }
                    result["collections"][collection_name]["documents"].append(doc_info)
                    
            except Exception as e:
                result["collections"][collection_name] = {
                    "error": f"KhÃ´ng thá»ƒ Ä‘á»c collection: {str(e)}",
                    "metadata": collection.metadata
                }
        
        print(f"[Chroma Data] Retrieved data from {len(collections)} collections")
        return result
        
    except Exception as e:
        return {"error": f"Lá»—i khi truy cáº­p Chroma DB: {str(e)}"}


@router.get("/chroma-stats")
async def get_chroma_stats():
    """
    Endpoint Ä‘á»ƒ láº¥y thá»‘ng kÃª nhanh vá» Chroma DB
    
    Returns:
        Dict chá»©a thá»‘ng kÃª tá»•ng quan
    """
    try:
        global chroma_client
        if chroma_client is None:
            return {"error": "ChromaDB client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o"}
        
        collections = chroma_client.list_collections()
        
        stats = {
            "instance_path": "./chroma_analytics",
            "total_collections": len(collections),
            "collections_stats": {},
            "total_documents": 0,
            "timestamp": datetime.now().isoformat()
        }
        
        for collection in collections:
            try:
                count = collection.count()
                stats["collections_stats"][collection.name] = {
                    "documents_count": count,
                    "metadata": collection.metadata
                }
                stats["total_documents"] += count
            except Exception as e:
                stats["collections_stats"][collection.name] = {
                    "error": str(e),
                    "metadata": collection.metadata
                }
        
        return stats
        
    except Exception as e:
        return {"error": f"Lá»—i khi láº¥y thá»‘ng kÃª Chroma DB: {str(e)}"}


class SyncDataRequest(BaseModel):
    """Request model for data synchronization"""
    spring_service_url: Optional[str] = None
    auth_token: str
    clear_existing: Optional[bool] = True


class ProcessDocumentRequest(BaseModel):
    """Request model for document processing"""
    file_path: str
    business_id: str
    business_username: str
    file_name: str
    file_type: str
    description: Optional[str] = None


@router.post("/process-document")
async def process_business_document(request: ProcessDocumentRequest):
    """
    Xá»­ lÃ½ tÃ i liá»‡u doanh nghiá»‡p vÃ  lÆ°u vÃ o ChromaDB collection riÃªng

    Args:
        request: ThÃ´ng tin tÃ i liá»‡u cáº§n xá»­ lÃ½

    Returns:
        Dict chá»©a káº¿t quáº£ xá»­ lÃ½
    """
    try:
        global chroma_client
        if chroma_client is None:
            raise HTTPException(status_code=500, detail="ChromaDB client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o")

        # Khá»Ÿi táº¡o document processor
        doc_processor = get_document_processor()

        # Extract text content tá»« file
        print(f"[Document Processing] Processing file: {request.file_path}")
        extracted_text, metadata = doc_processor.extract_text_from_file(
            request.file_path,
            request.file_type
        )

        if not metadata.get("extraction_success", False):
            raise HTTPException(
                status_code=400,
                detail=f"KhÃ´ng thá»ƒ xá»­ lÃ½ tÃ i liá»‡u: {metadata.get('error', 'Unknown error')}"
            )

        # Chuáº©n bá»‹ metadata cho ChromaDB
        doc_metadata = {
            "data_type": "document",
            "document_id": f"doc_{request.business_id}_{int(datetime.now().timestamp())}",
            "business_id": request.business_id,
            "business_username": request.business_username,
            "file_name": request.file_name,
            "file_type": request.file_type,
            "file_path": request.file_path,
            "description": request.description or "",
            "processed_at": datetime.now().isoformat(),
            "content_length": metadata.get("content_length", 0),
            "extraction_success": True
        }

        # ThÃªm metadata tá»« quÃ¡ trÃ¬nh processing náº¿u cÃ³
        if "sheets" in metadata:
            doc_metadata["excel_sheets"] = json.dumps(metadata["sheets"])
        if "columns" in metadata:
            doc_metadata["csv_columns"] = metadata["columns"]
        if "rows" in metadata:
            doc_metadata["data_rows"] = metadata["rows"]

        # Validate and sanitize metadata
        sanitized_metadata = sanitize_metadata(doc_metadata)

        # Táº¡o content Ä‘áº§y Ä‘á»§ vá»›i extracted text + metadata
        doc_content = f"""
DOCUMENT CONTENT:
{extracted_text}

---
METADATA:
Document ID: {doc_metadata["document_id"]}
Business: {request.business_username}
File Name: {request.file_name}
File Type: {request.file_type}
Description: {request.description or ""}
Processing Status: Success
Content Length: {len(extracted_text)} characters
Processed At: {doc_metadata["processed_at"]}
"""

        # LÆ°u vÃ o documents collection riÃªng biá»‡t
        analytics_rag_service = AnalyticsRAGService()
        result = analytics_rag_service.store_business_document(
            document_id=doc_metadata["document_id"],
            document_content=doc_content,
            metadata=sanitized_metadata
        )

        print(f"[Document Processing] Successfully processed and stored document: {doc_metadata['document_id']}")

        return {
            "success": True,
            "document_id": doc_metadata["document_id"],
            "content_length": len(extracted_text),
            "metadata": sanitized_metadata,
            "message": "TÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  lÆ°u thÃ nh cÃ´ng"
        }

    except Exception as e:
        print(f"[Document Processing] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Lá»—i xá»­ lÃ½ tÃ i liá»‡u: {str(e)}")


@router.post("/sync-from-spring")
async def sync_data_from_spring(request: SyncDataRequest):
    """
    Äá»“ng bá»™ dá»¯ liá»‡u tá»« Spring Service vÃ o ChromaDB
    
    Args:
        request: Chá»©a URL Spring Service, token xÃ¡c thá»±c vÃ  option xÃ³a dá»¯ liá»‡u cÅ©
        
    Returns:
        Dict chá»©a káº¿t quáº£ Ä‘á»“ng bá»™
    """
    try:
        global chroma_client
        if chroma_client is None:
            raise HTTPException(status_code=500, detail="ChromaDB client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o")
        
        # Láº¥y Spring Service URL tá»« biáº¿n mÃ´i trÆ°á»ng hoáº·c request
        spring_base_url = request.spring_service_url or os.getenv('SPRING_SERVICE_URL', 'http://localhost:8089/api/v1')
        
        # Láº¥y dá»¯ liá»‡u tá»« Spring Service
        headers = {
            "Authorization": f"Bearer {request.auth_token}",
            "Content-Type": "application/json"
        }
        
        spring_url = f"{spring_base_url}/admin/analytics/system-data"
        print(f"[Sync] Fetching data from: {spring_url}")
        
        response = requests.get(spring_url, headers=headers, timeout=30)
        
        if response.status_code != 200:
            raise HTTPException(
                status_code=response.status_code,
                detail=f"Failed to fetch data from Spring Service: {response.text}"
            )
        
        data = response.json()
        print(f"[Sync] Received data with {len(data.get('products', []))} products, {len(data.get('orders', []))} orders")
        
        sync_results = {
            "timestamp": datetime.now().isoformat(),
            "clear_existing": request.clear_existing,
            "products": {"total": 0, "with_details": 0, "success": 0, "errors": 0},
            "orders": {"total": 0, "success": 0, "errors": 0},
            "categories": {"total": 0, "success": 0, "errors": 0},
            "business_performance": {"total": 0, "success": 0, "errors": 0},
            "discounts": {"total": 0, "success": 0, "errors": 0},
            "users": {"total": 0, "success": 0, "errors": 0},
            "documents": {"total": 0, "success": 0, "errors": 0},
            "errors": []
        }
        
        # Khá»Ÿi táº¡o hoáº·c láº¥y cÃ¡c collections
        # Collection 1: business_data - chá»©a products, categories, business performance, discounts
        # Collection 2: orders_analytics - chá»©a orders
        # Collection 3: trends - chá»©a insights vÃ  trends (tÆ°Æ¡ng lai)
        # Collection 4: revenue_overview - chá»©a dá»¯ liá»‡u tá»•ng quan doanh thu vÃ  thá»‘ng kÃª há»‡ thá»‘ng
        # Collection 5: business_documents - chá»©a tÃ i liá»‡u doanh nghiá»‡p Ä‘Ã£ xá»­ lÃ½ cho RAG
        
        if request.clear_existing:
            print("[Sync] Clearing existing data...")
            try:
                # XÃ³a cÃ¡c collections cÅ©
                for collection_name in ["business_data", "orders_analytics", "trends", "revenue_overview", "business_documents"]:
                    try:
                        chroma_client.delete_collection(name=collection_name)
                        print(f"[Sync] Deleted old {collection_name} collection")
                    except:
                        pass
                
                # Táº¡o láº¡i cÃ¡c collections
                business_collection = chroma_client.create_collection(
                    name="business_data",
                    metadata={"description": "Products, categories, business performance, and discounts"}
                )
                orders_collection = chroma_client.create_collection(
                    name="orders_analytics",
                    metadata={"description": "Order data for analytics"}
                )
                trends_collection = chroma_client.create_collection(
                    name="trends",
                    metadata={"description": "Business trends and insights"}
                )
                revenue_collection = chroma_client.create_collection(
                    name="revenue_overview",
                    metadata={"description": "Revenue overview and system statistics"}
                )
                documents_collection = chroma_client.create_collection(
                    name="business_documents",
                    metadata={"description": "Business documents for RAG analysis"}
                )
                print("[Sync] Created new collections: business_data, orders_analytics, trends, revenue_overview, business_documents")
                
            except Exception as e:
                print(f"[Sync] Error clearing data: {e}")
                sync_results["errors"].append(f"Clear data error: {str(e)}")
                raise HTTPException(status_code=500, detail=f"Failed to clear collections: {str(e)}")
        else:
            # Láº¥y hoáº·c táº¡o collections náº¿u chÆ°a cÃ³
            print("[Sync] Getting or creating collections...")
            business_collection = chroma_client.get_or_create_collection(
                name="business_data",
                metadata={"description": "Products, categories, business performance, and discounts"}
            )
            orders_collection = chroma_client.get_or_create_collection(
                name="orders_analytics",
                metadata={"description": "Order data for analytics"}
            )
            trends_collection = chroma_client.get_or_create_collection(
                name="trends",
                metadata={"description": "Business trends and insights"}
            )
            revenue_collection = chroma_client.get_or_create_collection(
                name="revenue_overview",
                metadata={"description": "Revenue overview and system statistics"}
            )
            documents_collection = chroma_client.get_or_create_collection(
                name="business_documents",
                metadata={"description": "Business documents for RAG analysis"}
            )
            print("[Sync] Collections ready: business_data, orders_analytics, trends, revenue_overview, business_documents")
        
        # Äá»“ng bá»™ Products vá»›i details Ä‘áº§y Ä‘á»§
        if data.get('products'):
            sync_results["products"]["total"] = len(data['products'])
            print(f"[Sync] Syncing {len(data['products'])} products...")
            
            for product in data['products']:
                try:
                    product_id = str(product.get('id', ''))
                    has_details = bool(product.get('details'))
                    
                    if has_details:
                        sync_results["products"]["with_details"] += 1
                    
                    # Táº¡o product content vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin
                    product_content = f"""Product ID: {product.get('id')}
Name: {product.get('name', '')}
Description: {product.get('description', '')}
Price: {product.get('price', 0)} VND
Quantity: {product.get('quantity', 0)}
Status: {product.get('status', 'UNKNOWN')}
Category: {product.get('categoryName', '')}
Seller: {product.get('sellerUsername', '')}
"""
                    
                    # Parse details náº¿u cÃ³
                    details_text = ""
                    if product.get('details'):
                        try:
                            import json
                            details = json.loads(product['details']) if isinstance(product['details'], str) else product['details']
                            
                            if details:
                                details_text = "\nProduct Details:\n"
                                
                                # Basic details
                                if details.get('brand'):
                                    details_text += f"Brand: {details['brand']}\n"
                                if details.get('model'):
                                    details_text += f"Model: {details['model']}\n"
                                if details.get('color'):
                                    details_text += f"Color: {details['color']}\n"
                                if details.get('warranty'):
                                    details_text += f"Warranty: {details['warranty']}\n"
                                if details.get('storage'):
                                    details_text += f"Storage: {details['storage']}\n"
                                if details.get('type'):
                                    details_text += f"Type: {details['type']}\n"
                                
                                # Features
                                if details.get('features') and isinstance(details['features'], list):
                                    details_text += f"Features: {', '.join(details['features'])}\n"
                                
                                # Specifications
                                if details.get('specifications') and isinstance(details['specifications'], dict):
                                    details_text += "Specifications:\n"
                                    for key, value in details['specifications'].items():
                                        details_text += f"  {key}: {value}\n"
                                
                                # Connectivity
                                if details.get('connectivity') and isinstance(details['connectivity'], list):
                                    details_text += f"Connectivity: {', '.join(details['connectivity'])}\n"
                                
                                # Accessories
                                if details.get('accessories') and isinstance(details['accessories'], list):
                                    details_text += f"Accessories: {', '.join(details['accessories'])}\n"
                                
                                # Dimensions and Weight
                                if details.get('dimensions'):
                                    details_text += f"Dimensions: {details['dimensions']}\n"
                                if details.get('weight'):
                                    details_text += f"Weight: {details['weight']}\n"
                                
                                product_content += details_text
                                
                        except json.JSONDecodeError:
                            print(f"[Sync] Invalid JSON in product details for {product_id}")
                        except Exception as e:
                            print(f"[Sync] Error parsing product details for {product_id}: {e}")
                    
                    # Safe conversion cho metadata
                    price = product.get('price')
                    price_float = float(price) if price is not None else 0.0
                    
                    quantity = product.get('quantity')
                    quantity_int = int(quantity) if quantity is not None else 0
                    
                    total_sold = product.get('totalSold')
                    total_sold_int = int(total_sold) if total_sold is not None else 0
                    
                    total_revenue = product.get('totalRevenue')
                    total_revenue_float = float(total_revenue) if total_revenue is not None else 0.0
                    
                    # Prepare metadata vá»›i Äáº¦Y Äá»¦ táº¥t cáº£ cÃ¡c trÆ°á»ng tá»« DTO
                    product_metadata = {
                        "data_type": "product",
                        "product_id": product_id,
                        "name": product.get('name', ''),
                        "description": product.get('description', ''),
                        "category": product.get('categoryName', ''),
                        "category_id": str(product.get('categoryId', '')) if product.get('categoryId') else '',
                        "status": product.get('status', 'UNKNOWN'),
                        "price": price_float,
                        "quantity": quantity_int,
                        "seller": product.get('sellerUsername', ''),
                        "seller_id": str(product.get('sellerId', '')),
                        "total_sold": total_sold_int,
                        "total_revenue": total_revenue_float,
                        "image_urls": json.dumps(product.get('imageUrls', [])) if product.get('imageUrls') else '',
                        "created_at": product.get('createdAt', ''),
                        "updated_at": product.get('updatedAt', ''),
                        "has_details": has_details,
                        "stored_at": datetime.now().isoformat(),
                        "purpose": "analytics"
                    }
                    
                    # Add parsed details to metadata if available
                    if product.get('details'):
                        try:
                            import json
                            details = json.loads(product['details']) if isinstance(product['details'], str) else product['details']
                            if details:
                                # Store key details in metadata for easy filtering
                                if details.get('brand'):
                                    product_metadata['brand'] = details['brand']
                                if details.get('model'):
                                    product_metadata['model'] = details['model']
                                if details.get('color'):
                                    product_metadata['color'] = details['color']
                                if details.get('warranty'):
                                    product_metadata['warranty'] = details['warranty']
                                # Store full details as JSON string
                                product_metadata['details_json'] = json.dumps(details, ensure_ascii=False)
                        except:
                            pass
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_metadata = sanitize_metadata(product_metadata)
                    
                    # LÆ°u vÃ o collection
                    business_collection.upsert(
                        documents=[product_content],
                        metadatas=[sanitized_metadata],
                        ids=[f"product_{product_id}"]
                    )
                    
                    sync_results["products"]["success"] += 1
                    print(f"[Sync] Stored product {product_id} with details: {has_details}")
                    
                except Exception as e:
                    sync_results["products"]["errors"] += 1
                    error_msg = f"Product {product.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
                    print(f"[Sync] Error: {error_msg}")
                    import traceback
                    traceback.print_exc()
        
        # Äá»“ng bá»™ Orders
        if data.get('orders'):
            sync_results["orders"]["total"] = len(data['orders'])
            print(f"[Sync] Syncing {len(data['orders'])} orders...")
            
            for order in data['orders']:
                try:
                    order_id = str(order.get('id', ''))
                    
                    # Táº¡o ná»™i dung order
                    order_content = f"""
Order ID: {order.get('id')}
Customer: {order.get('customerName', '')}
Status: {order.get('status', '')}
Total Amount: {order.get('totalAmount', 0)} VND
Items Count: {order.get('totalItems', 0)}
Created: {order.get('createdAt', '')}
"""
                    
                    # Safe conversion vá»›i xá»­ lÃ½ null/None
                    total_amount = order.get('totalAmount')
                    total_amount_float = float(total_amount) if total_amount is not None else 0.0
                    
                    total_items = order.get('totalItems')
                    total_items_int = int(total_items) if total_items is not None else 0
                    
                    # LÆ°u order items náº¿u cÃ³
                    order_items = order.get('items', [])
                    items_detail = []
                    for item in order_items:
                        items_detail.append({
                            "product_id": str(item.get('productId', '')),
                            "product_name": item.get('productName', ''),
                            "quantity": int(item.get('quantity', 0)) if item.get('quantity') is not None else 0,
                            "price": float(item.get('price', 0)) if item.get('price') is not None else 0.0,
                            "subtotal": float(item.get('subtotal', 0)) if item.get('subtotal') is not None else 0.0
                        })
                    
                    order_metadata = {
                        "data_type": "order",
                        "order_id": order_id,
                        "customer_name": order.get('customerName', ''),
                        "customer_id": str(order.get('customerId', '')),
                        "status": order.get('status', ''),
                        "total_amount": total_amount_float,
                        "total_items": total_items_int,
                        "created_at": order.get('createdAt', ''),
                        "updated_at": order.get('updatedAt', ''),
                        "payment_method": order.get('paymentMethod', ''),
                        "shipping_address": order.get('shippingAddress', ''),
                        "items_json": json.dumps(items_detail, ensure_ascii=False),  # Store items as JSON string
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_order_metadata = sanitize_metadata(order_metadata)
                    
                    # LÆ°u vÃ o orders_analytics collection
                    orders_collection.upsert(
                        documents=[order_content],
                        metadatas=[sanitized_order_metadata],
                        ids=[f"order_{order_id}"]
                    )
                    
                    sync_results["orders"]["success"] += 1
                    
                except Exception as e:
                    sync_results["orders"]["errors"] += 1
                    error_msg = f"Order {order.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
                    print(f"[Sync] Error: {error_msg}")
        
        # Äá»“ng bá»™ Categories
        if data.get('categories'):
            sync_results["categories"]["total"] = len(data['categories'])
            print(f"[Sync] Syncing {len(data['categories'])} categories...")
            
            for category in data['categories']:
                try:
                    category_id = str(category.get('id', ''))
                    
                    category_content = f"""
Category ID: {category.get('id')}
Name: {category.get('name', '')}
Description: {category.get('description', '')}
Status: {category.get('status', '')}
Product Count: {category.get('productCount', 0)}
"""
                    
                    # Safe conversion
                    product_count = category.get('productCount')
                    product_count_int = int(product_count) if product_count is not None else 0
                    
                    category_metadata = {
                        "data_type": "category",
                        "category_id": category_id,
                        "name": category.get('name', ''),
                        "description": category.get('description', ''),
                        "status": category.get('status', ''),
                        "product_count": product_count_int,
                        "created_at": category.get('createdAt', ''),
                        "updated_at": category.get('updatedAt', ''),
                        "image_url": category.get('imageUrl', ''),
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_category_metadata = sanitize_metadata(category_metadata)
                    
                    # Use business_collection directly
                    business_collection.upsert(
                        documents=[category_content],
                        metadatas=[sanitized_category_metadata],
                        ids=[f"category_{category_id}"]
                    )
                    
                    sync_results["categories"]["success"] += 1
                    
                except Exception as e:
                    sync_results["categories"]["errors"] += 1
                    error_msg = f"Category {category.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # Äá»“ng bá»™ Business Performance
        if data.get('businessPerformance'):
            sync_results["business_performance"]["total"] = len(data['businessPerformance'])
            print(f"[Sync] Syncing {len(data['businessPerformance'])} business performance records...")
            
            for business in data['businessPerformance']:
                try:
                    business_id = str(business.get('businessId', ''))
                    
                    business_content = f"""
Business ID: {business.get('businessId')}
Username: {business.get('businessUsername', '')}
Total Products: {business.get('totalProducts', 0)}
Active Products: {business.get('activeProducts', 0)}
Total Orders: {business.get('totalOrders', 0)}
Revenue: {business.get('revenue', 0)} VND
Average Order Value: {business.get('averageOrderValue', 0)} VND
"""
                    
                    # Safe conversion cho business data
                    total_products = business.get('totalProducts')
                    total_products_int = int(total_products) if total_products is not None else 0
                    
                    active_products = business.get('activeProducts')
                    active_products_int = int(active_products) if active_products is not None else 0
                    
                    total_orders = business.get('totalOrders')
                    total_orders_int = int(total_orders) if total_orders is not None else 0
                    
                    revenue = business.get('revenue')
                    revenue_float = float(revenue) if revenue is not None else 0.0
                    
                    inventory_value = business.get('inventoryValue')
                    inventory_value_float = float(inventory_value) if inventory_value is not None else 0.0
                    
                    avg_order = business.get('averageOrderValue')
                    avg_order_float = float(avg_order) if avg_order is not None else 0.0
                    
                    business_metadata = {
                        "data_type": "business_performance",
                        "business_id": business_id,
                        "username": business.get('businessUsername', ''),
                        "total_products": total_products_int,
                        "active_products": active_products_int,
                        "inactive_products": safe_int(business.get('inactiveProducts')),
                        "total_orders": total_orders_int,
                        "completed_orders": safe_int(business.get('completedOrders')),
                        "revenue": revenue_float,
                        "inventory_value": inventory_value_float,
                        "average_order_value": avg_order_float,
                        "total_sold": safe_int(business.get('totalSold')),
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_business_metadata = sanitize_metadata(business_metadata)
                    
                    # Use business_collection directly
                    business_collection.upsert(
                        documents=[business_content],
                        metadatas=[sanitized_business_metadata],
                        ids=[f"business_{business_id}"]
                    )
                    
                    sync_results["business_performance"]["success"] += 1
                    
                except Exception as e:
                    sync_results["business_performance"]["errors"] += 1
                    error_msg = f"Business {business.get('businessId', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # Äá»“ng bá»™ Discounts
        if data.get('discounts'):
            sync_results["discounts"]["total"] = len(data['discounts'])
            print(f"[Sync] Syncing {len(data['discounts'])} discounts...")
            
            for discount in data['discounts']:
                try:
                    discount_id = str(discount.get('id', ''))
                    
                    discount_content = f"""
Discount ID: {discount.get('id')}
Code: {discount.get('code', '')}
Type: {discount.get('discountType', '')}
Value: {discount.get('discountValue', 0)}
Status: {discount.get('status', '')}
Usage Count: {discount.get('usageCount', 0)}
"""
                    
                    # Safe conversion cho discount data
                    discount_value = discount.get('discountValue')
                    discount_value_float = float(discount_value) if discount_value is not None else 0.0
                    
                    min_order = discount.get('minOrderValue')
                    min_order_float = float(min_order) if min_order is not None else 0.0
                    
                    max_discount = discount.get('maxDiscountAmount')
                    max_discount_float = float(max_discount) if max_discount is not None else 0.0
                    
                    usage_limit = discount.get('usageLimit')
                    usage_limit_int = int(usage_limit) if usage_limit is not None else 0
                    
                    used_count = discount.get('usedCount')
                    used_count_int = int(used_count) if used_count is not None else 0
                    
                    # Parse additional fields
                    total_savings = discount.get('totalSavings')
                    total_savings_float = float(total_savings) if total_savings is not None else 0.0
                    
                    usage_percentage = discount.get('usagePercentage')
                    usage_percentage_float = float(usage_percentage) if usage_percentage is not None else 0.0
                    
                    discount_metadata = {
                        "data_type": "discount",
                        "discount_id": discount_id,
                        "code": discount.get('code', ''),
                        "name": discount.get('name', ''),
                        "description": discount.get('description', ''),
                        "type": discount.get('discountType', ''),
                        "value": discount_value_float,
                        "min_order_value": min_order_float,
                        "max_discount_amount": max_discount_float,
                        "usage_limit": usage_limit_int,
                        "used_count": used_count_int,
                        "status": discount.get('status', ''),
                        "start_date": discount.get('startDate', ''),
                        "end_date": discount.get('endDate', ''),
                        "created_at": discount.get('createdAt', ''),
                        "created_by_username": discount.get('createdByUsername', ''),
                        "created_by_id": str(discount.get('createdById', '')) if discount.get('createdById') else '',
                        "is_valid": discount.get('isValid', False),
                        "is_expired": discount.get('isExpired', False),
                        "usage_limit_reached": discount.get('usageLimitReached', False),
                        "usage_percentage": usage_percentage_float,
                        "total_savings": total_savings_float,
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_discount_metadata = sanitize_metadata(discount_metadata)
                    
                    # Use business_collection directly
                    business_collection.upsert(
                        documents=[discount_content],
                        metadatas=[sanitized_discount_metadata],
                        ids=[f"discount_{discount_id}"]
                    )
                    
                    sync_results["discounts"]["success"] += 1
                    
                except Exception as e:
                    sync_results["discounts"]["errors"] += 1
                    error_msg = f"Discount {discount.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # Äá»“ng bá»™ Users (náº¿u cÃ³)
        if data.get('users'):
            sync_results["users"] = {"total": len(data['users']), "success": 0, "errors": 0}
            print(f"[Sync] Syncing {len(data['users'])} users...")
            
            for user in data['users']:
                try:
                    user_id = str(user.get('id', ''))
                    
                    user_content = f"""
User ID: {user.get('id')}
Username: {user.get('username', '')}
Email: {user.get('email', '')}
Role: {user.get('role', '')}
Status: {user.get('accountStatus', '')}
Phone: {user.get('phoneNumber', '')}
Address: {user.get('address', '')}
"""
                    
                    user_metadata = {
                        "data_type": "user",
                        "user_id": user_id,
                        "username": user.get('username', ''),
                        "email": user.get('email', ''),
                        "role": user.get('role', ''),
                        "account_status": user.get('accountStatus', ''),
                        "phone_number": user.get('phoneNumber', ''),
                        "address": user.get('address', ''),
                        "stored_at": datetime.now().isoformat()
                    }
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_user_metadata = sanitize_metadata(user_metadata)
                    
                    business_collection.upsert(
                        documents=[user_content],
                        metadatas=[sanitized_user_metadata],
                        ids=[f"user_{user_id}"]
                    )
                    
                    sync_results["users"]["success"] += 1
                    
                except Exception as e:
                    sync_results["users"]["errors"] += 1
                    error_msg = f"User {user.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # Äá»“ng bá»™ Business Documents (náº¿u cÃ³) - LÆ¯U VÃ€O COLLECTION RIÃŠNG BIá»†T
        if data.get('businessDocuments'):
            sync_results["documents"] = {"total": len(data['businessDocuments']), "success": 0, "errors": 0}
            print(f"[Sync] Syncing {len(data['businessDocuments'])} business documents...")
            
            # Táº¡o collection riÃªng cho documents náº¿u chÆ°a cÃ³
            try:
                documents_collection = chroma_client.get_or_create_collection(
                    name="business_documents",
                    metadata={"description": "Business documents for RAG analysis"}
                )
                print("[Sync] Documents collection ready")
            except Exception as e:
                print(f"[Sync] Error creating documents collection: {e}")
                sync_results["errors"].append(f"Documents collection error: {str(e)}")
                documents_collection = None
            
            for doc in data['businessDocuments']:
                try:
                    doc_id = str(doc.get('id', ''))
                    file_path = doc.get('filePath', '')
                    file_type = doc.get('fileType', '')
                    
                    # Resolve Ä‘Æ°á»ng dáº«n file tá»« Spring Service
                    resolved_file_path = resolve_spring_file_path(file_path)
                    print(f"[Sync] Original path: {file_path} -> Resolved path: {resolved_file_path}")
                    
                    # Khá»Ÿi táº¡o document processor
                    doc_processor = get_document_processor()
                    
                    # Extract text content tá»« file
                    extracted_text = ""
                    processing_metadata = {}
                    
                    if resolved_file_path and os.path.exists(resolved_file_path):
                        try:
                            extracted_text, processing_metadata = doc_processor.extract_text_from_file(
                                resolved_file_path, file_type
                            )
                            print(f"[Sync] Successfully extracted {len(extracted_text)} characters from {doc.get('fileName', '')}")
                        except Exception as extract_error:
                            print(f"[Sync] Error extracting text from {resolved_file_path}: {extract_error}")
                            # Fallback: táº¡o content tá»« metadata
                            extracted_text = f"Error extracting content from file: {str(extract_error)}"
                    else:
                        print(f"[Sync] File not found: {resolved_file_path} (original: {file_path})")
                        extracted_text = "File not found during sync process"
                    
                    # Táº¡o document content vá»›i text Ä‘Ã£ extract + metadata
                    file_size = doc.get('fileSize')
                    file_size_int = int(file_size) if file_size is not None else 0
                    
                    # Káº¿t há»£p extracted text vá»›i metadata Ä‘á»ƒ táº¡o content Ä‘áº§y Ä‘á»§
                    doc_content = f"""
DOCUMENT CONTENT:
{extracted_text}

---
METADATA:
Document ID: {doc.get('id')}
Business: {doc.get('businessUsername', '')}
File Name: {doc.get('fileName', '')}
File Type: {doc.get('fileType', '')}
Description: {doc.get('description', '')}
Size: {file_size_int} bytes
Uploaded: {doc.get('uploadedAt', '')}
Processing Status: {'Success' if processing_metadata.get('extraction_success') else 'Failed'}
Content Length: {len(extracted_text)} characters
"""
                    
                    doc_metadata = {
                        "data_type": "document",
                        "document_id": doc_id,
                        "business_id": str(doc.get('businessId', '')) if doc.get('businessId') else '',
                        "business_username": doc.get('businessUsername', ''),
                        "file_name": doc.get('fileName', ''),
                        "file_type": doc.get('fileType', ''),
                        "file_path_original": doc.get('filePath', ''),  # ÄÆ°á»ng dáº«n gá»‘c tá»« Spring
                        "file_path_resolved": resolved_file_path or '',  # ÄÆ°á»ng dáº«n Ä‘Ã£ resolve
                        "file_size": file_size_int,
                        "description": doc.get('description', ''),
                        "uploaded_at": doc.get('uploadedAt', ''),
                        "stored_at": datetime.now().isoformat(),
                        "extraction_success": processing_metadata.get('extraction_success', False),
                        "content_length": len(extracted_text),
                        "processing_timestamp": processing_metadata.get('processing_timestamp', datetime.now().isoformat())
                    }
                    
                    # ThÃªm metadata tá»« quÃ¡ trÃ¬nh processing náº¿u cÃ³
                    if "sheets" in processing_metadata:
                        doc_metadata["excel_sheets"] = json.dumps(processing_metadata["sheets"])
                    if "columns" in processing_metadata:
                        doc_metadata["csv_columns"] = processing_metadata["columns"]
                    if "rows" in processing_metadata:
                        doc_metadata["data_rows"] = processing_metadata["rows"]
                    
                    # Validate and sanitize metadata for ChromaDB compatibility
                    sanitized_doc_metadata = sanitize_metadata(doc_metadata)
                    
                    # LÆ°u vÃ o collection riÃªng biá»‡t cho documents
                    if documents_collection:
                        documents_collection.upsert(
                            documents=[doc_content],
                            metadatas=[sanitized_doc_metadata],
                            ids=[f"document_{doc_id}"]
                        )
                        print(f"[Sync] Stored document {doc_id} in separate collection")
                    else:
                        # Fallback: lÆ°u vÃ o business_collection náº¿u khÃ´ng táº¡o Ä‘Æ°á»£c collection riÃªng
                        business_collection.upsert(
                            documents=[doc_content],
                            metadatas=[sanitized_doc_metadata],
                            ids=[f"document_{doc_id}"]
                        )
                        print(f"[Sync] Fallback: Stored document {doc_id} in business collection")
                    
                    sync_results["documents"]["success"] += 1
                    
                except Exception as e:
                    sync_results["documents"]["errors"] += 1
                    error_msg = f"Document {doc.get('id', 'unknown')}: {str(e)}"
                    sync_results["errors"].append(error_msg)
        
        # ThÃªm revenue overview tá»« data gá»‘c
        sync_results["revenue_overview"] = {
            "total_revenue": safe_decimal(data.get('totalRevenue')),
            "monthly_revenue": safe_decimal(data.get('monthlyRevenue')),
            "weekly_revenue": safe_decimal(data.get('weeklyRevenue')),
            "daily_revenue": safe_decimal(data.get('dailyRevenue')),
        }
        
        # LÆ°u revenue overview vÃ o ChromaDB Ä‘á»ƒ AI cÃ³ thá»ƒ truy váº¥n
        try:
            revenue_content = f"""
Revenue Overview - System Statistics
Total Revenue: {sync_results["revenue_overview"]["total_revenue"]} VND
Monthly Revenue: {sync_results["revenue_overview"]["monthly_revenue"]} VND
Weekly Revenue: {sync_results["revenue_overview"]["weekly_revenue"]} VND
Daily Revenue: {sync_results["revenue_overview"]["daily_revenue"]} VND
Last Updated: {datetime.now().isoformat()}
"""
            
            revenue_metadata = {
                "data_type": "revenue_overview",
                "total_revenue": sync_results["revenue_overview"]["total_revenue"],
                "monthly_revenue": sync_results["revenue_overview"]["monthly_revenue"],
                "weekly_revenue": sync_results["revenue_overview"]["weekly_revenue"],
                "daily_revenue": sync_results["revenue_overview"]["daily_revenue"],
                "stored_at": datetime.now().isoformat(),
                "purpose": "analytics"
            }
            
            # Validate and sanitize metadata
            sanitized_revenue_metadata = sanitize_metadata(revenue_metadata)
            
            revenue_collection.upsert(
                documents=[revenue_content],
                metadatas=[sanitized_revenue_metadata],
                ids=["revenue_overview_system"]
            )
            
            print("[Sync] Stored revenue overview in ChromaDB")
            
        except Exception as e:
            print(f"[Sync] Error storing revenue overview: {str(e)}")
            sync_results["errors"].append(f"Revenue overview storage error: {str(e)}")
        
        # ThÃªm top selling products tá»« data gá»‘c
        if data.get('topSellingProducts'):
            sync_results["top_selling_products"] = [
                {
                    "product_id": str(p.get('productId', '')),
                    "product_name": p.get('productName', ''),
                    "total_sold": safe_int(p.get('totalSold')),
                    "revenue": safe_decimal(p.get('revenue'))
                }
                for p in data.get('topSellingProducts', [])[:10]
            ]
        
        # ThÃªm low stock products tá»« data gá»‘c
        if data.get('lowStockProducts'):
            sync_results["low_stock_products"] = [
                {
                    "product_id": str(p.get('productId', '')),
                    "product_name": p.get('productName', ''),
                    "quantity": safe_int(p.get('quantity')),
                    "category": p.get('categoryName', '')
                }
                for p in data.get('lowStockProducts', [])
            ]
        
        # Táº¡o summary
        total_success = (
            sync_results["products"]["success"] +
            sync_results["orders"]["success"] +
            sync_results["categories"]["success"] +
            sync_results["business_performance"]["success"] +
            sync_results["discounts"]["success"] +
            sync_results.get("users", {}).get("success", 0) +
            sync_results.get("documents", {}).get("success", 0)
        )
        
        total_errors = (
            sync_results["products"]["errors"] +
            sync_results["orders"]["errors"] +
            sync_results["categories"]["errors"] +
            sync_results["business_performance"]["errors"] +
            sync_results["discounts"]["errors"] +
            sync_results.get("users", {}).get("errors", 0) +
            sync_results.get("documents", {}).get("errors", 0)
        )
        
        sync_results["summary"] = {
            "total_success": total_success,
            "total_errors": total_errors,
            "success_rate": f"{(total_success / (total_success + total_errors) * 100):.2f}%" if (total_success + total_errors) > 0 else "0%",
            "total_users": safe_int(data.get('totalUsers')),
            "total_customers": safe_int(data.get('totalCustomers')),
            "total_business_users": safe_int(data.get('totalBusinessUsers')),
            "total_products": safe_int(data.get('totalProducts')),
            "active_products": safe_int(data.get('activeProducts')),
            "total_orders": safe_int(data.get('totalOrders')),
            "delivered_orders": safe_int(data.get('deliveredOrders')),
            "pending_orders": safe_int(data.get('pendingOrders'))
        }
        
        print(f"[Sync] Completed: {total_success} success, {total_errors} errors")
        
        return sync_results
        
    except requests.RequestException as e:
        raise HTTPException(status_code=500, detail=f"Error connecting to Spring Service: {str(e)}")
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Sync error: {str(e)}")
